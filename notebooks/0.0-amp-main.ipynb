{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f58e5c2",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16446b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:27:47.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Repositories\\time-series-prediction-rnn\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Adiciona a pasta raiz do projeto ao sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import src.config as config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfd6425",
   "metadata": {},
   "source": [
    "## ETL — Extract, Transform, Load of Raw Dataset\n",
    "\n",
    "This section is responsible for the Extraction phase of the ETL process, pulling historical financial data from multiple sources as defined in the configuration file [dataset.yaml](../configs/dataset.yaml).\n",
    "\n",
    "- Data Storage: Each dataset is stored locally in the data/raw/ directory, organized and saved individually as .csv files for traceability and versioning.\n",
    "- Data Cleaning:\n",
    "  - Missing values are treated using a standard cleaning strategy.\n",
    "  - Features with low variance (threshold < 0.01) are removed to reduce noise and improve modeling efficiency. In this execution, no low-variance columns were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fdcd420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:27:53.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mStarting raw data loading...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:27:53.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRequesting information between 2022-07-10 and 2025-07-09\u001b[0m\n",
      "\u001b[32m2025-07-09 13:27:53.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading BOVESPA (^BVSP) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:27:59.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading S&P500 (^GSPC) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:28:01.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading BITCOIN (BTC-USD) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:28:04.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading OURO (GC=F) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:28:06.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading PETROLEO (CL=F) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:28:09.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading ACUCAR (SB=F) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:28:11.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading SELIC (11) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:17.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading CDI (12) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:19.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading SELIC_Anual (1178) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:21.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading SELIC_Meta_Anual (432) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:24.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading IPCA_Mensal (433) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:26.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading IGP_M_Mensal (189) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:28.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading INCC_Mensal (192) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:30.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Indice_Condicoes_Econ_BR (27574) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:32.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Indice_Condicoes_Econ_BR_USD (29042) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:34.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Salario_Minimo (1619) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:36.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading IBC_BR (24363) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:39.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Populacao_BR (21774) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:41.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading PIB_Trimestral_Real (4380) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:43.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading PIB_Anual_Corrente (7326) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:45.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Deflator_Implicito_PIB (1211) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:47.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mDownloading BRL_USD (DEXBZUS) from DataReader...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:51.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mDownloading CPI_USA (CPIAUCSL) from DataReader...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:53.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_BOVESPA dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Yfinance_BOVESPA.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:53.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_S&P500 dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Yfinance_S&P500.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_BITCOIN dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Yfinance_BITCOIN.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_OURO dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Yfinance_OURO.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_PETROLEO dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Yfinance_PETROLEO.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_ACUCAR dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Yfinance_ACUCAR.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_SELIC dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_SELIC.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_CDI dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_CDI.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_SELIC_Anual dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_SELIC_Anual.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_SELIC_Meta_Anual dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_SELIC_Meta_Anual.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_IPCA_Mensal dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_IPCA_Mensal.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_IGP_M_Mensal dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_IGP_M_Mensal.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_INCC_Mensal dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_INCC_Mensal.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Indice_Condicoes_Econ_BR dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_Indice_Condicoes_Econ_BR.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Indice_Condicoes_Econ_BR_USD dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_Indice_Condicoes_Econ_BR_USD.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Salario_Minimo dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_Salario_Minimo.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_IBC_BR dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_IBC_BR.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Populacao_BR dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_Populacao_BR.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_PIB_Trimestral_Real dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_PIB_Trimestral_Real.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_PIB_Anual_Corrente dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_PIB_Anual_Corrente.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Deflator_Implicito_PIB dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\Bcb_Deflator_Implicito_PIB.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved DataReader_BRL_USD dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\DataReader_BRL_USD.csv\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved DataReader_CPI_USA dataset to C:\\Repositories\\time-series-prediction-rnn\\data\\raw\\DataReader_CPI_USA.csv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.dataset.clean_strategy:Executing CleanMissingValues...\n",
      "INFO:src.utils.dataset.clean_strategy:Executing CleanLowVariance with threshold=0.01...\n",
      "INFO:src.utils.dataset.clean_strategy:Columns removed due to low variance: Index([], dtype='object')\n",
      "c:\\Repositories\\time-series-prediction-rnn\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Repositories\\time-series-prediction-rnn\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:108: RuntimeWarning: invalid value encountered in divide\n",
      "  msw = sswn / float(dfwn)\n",
      "INFO:src.utils.dataset.clean_strategy:Columns removed by f_classif: ['INCC_Mensal']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close_^BVSP  High_^BVSP  Low_^BVSP  Open_^BVSP  Volume_^BVSP  \\\n",
      "2025-07-03     140928.0    141304.0   139051.0    139051.0     6082200.0   \n",
      "2025-07-04     141478.0    141537.0   140597.0    140928.0     2114300.0   \n",
      "2025-07-05          NaN         NaN        NaN         NaN           NaN   \n",
      "2025-07-06          NaN         NaN        NaN         NaN           NaN   \n",
      "2025-07-07     139490.0    141342.0   139295.0    141265.0     6117300.0   \n",
      "2025-07-08     139303.0    139591.0   138770.0    139491.0     6750100.0   \n",
      "2025-07-09          NaN         NaN        NaN         NaN           NaN   \n",
      "\n",
      "            Close_^GSPC   High_^GSPC    Low_^GSPC   Open_^GSPC  Volume_^GSPC  \\\n",
      "2025-07-03  6279.350098  6284.649902  6246.459961  6246.459961  3.378110e+09   \n",
      "2025-07-04          NaN          NaN          NaN          NaN           NaN   \n",
      "2025-07-05          NaN          NaN          NaN          NaN           NaN   \n",
      "2025-07-06          NaN          NaN          NaN          NaN           NaN   \n",
      "2025-07-07  6229.979980  6262.069824  6201.000000  6259.040039  5.236740e+09   \n",
      "2025-07-08  6225.520020  6242.700195  6217.750000  6234.029785  5.739030e+09   \n",
      "2025-07-09          NaN          NaN          NaN          NaN           NaN   \n",
      "\n",
      "            ...  Indice_Condicoes_Econ_BR  Indice_Condicoes_Econ_BR_USD  \\\n",
      "2025-07-03  ...                       NaN                           NaN   \n",
      "2025-07-04  ...                       NaN                           NaN   \n",
      "2025-07-05  ...                       NaN                           NaN   \n",
      "2025-07-06  ...                       NaN                           NaN   \n",
      "2025-07-07  ...                       NaN                           NaN   \n",
      "2025-07-08  ...                       NaN                           NaN   \n",
      "2025-07-09  ...                       NaN                           NaN   \n",
      "\n",
      "            Salario_Minimo  IBC_BR  Populacao_BR  PIB_Trimestral_Real  \\\n",
      "2025-07-03             NaN     NaN           NaN                  NaN   \n",
      "2025-07-04             NaN     NaN           NaN                  NaN   \n",
      "2025-07-05             NaN     NaN           NaN                  NaN   \n",
      "2025-07-06             NaN     NaN           NaN                  NaN   \n",
      "2025-07-07             NaN     NaN           NaN                  NaN   \n",
      "2025-07-08             NaN     NaN           NaN                  NaN   \n",
      "2025-07-09             NaN     NaN           NaN                  NaN   \n",
      "\n",
      "            PIB_Anual_Corrente  Deflator_Implicito_PIB  DEXBZUS  CPIAUCSL  \n",
      "2025-07-03                 NaN                     NaN   5.4178       NaN  \n",
      "2025-07-04                 NaN                     NaN      NaN       NaN  \n",
      "2025-07-05                 NaN                     NaN      NaN       NaN  \n",
      "2025-07-06                 NaN                     NaN      NaN       NaN  \n",
      "2025-07-07                 NaN                     NaN      NaN       NaN  \n",
      "2025-07-08                 NaN                     NaN      NaN       NaN  \n",
      "2025-07-09                 NaN                     NaN      NaN       NaN  \n",
      "\n",
      "[7 rows x 47 columns]\n",
      "\u001b[32m2025-07-09 13:28:54.243\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m69\u001b[0m - \u001b[32m\u001b[1mRaw data successfully loaded...\u001b[0m\n",
      "            Close_^BVSP  High_^BVSP  Low_^BVSP  Open_^BVSP  Volume_^BVSP  \\\n",
      "2025-06-30     0.014532    0.013804  -0.000286   -0.001809      0.229930   \n",
      "2025-07-01     0.004998    0.004256   0.017775    0.014540     -0.173769   \n",
      "2025-07-02    -0.003569    0.002534  -0.003392    0.005264      0.388641   \n",
      "2025-07-03     0.013499    0.008961   0.004820   -0.003833     -0.309774   \n",
      "2025-07-04     0.003903    0.001649   0.011118    0.013499     -0.652379   \n",
      "2025-07-07    -0.014052   -0.001378  -0.009261    0.002391      1.893298   \n",
      "2025-07-08    -0.001341   -0.012388  -0.003769   -0.012558      0.103444   \n",
      "\n",
      "            Close_^GSPC  High_^GSPC  Low_^GSPC  Open_^GSPC  Volume_^GSPC  ...  \\\n",
      "2025-06-30     0.005164    0.004428   0.006950    0.006936     -0.266999  ...   \n",
      "2025-07-01    -0.001119   -0.000692   0.000486   -0.000987      0.085149  ...   \n",
      "2025-07-02     0.004745    0.002708   0.001670    0.001072     -0.100330  ...   \n",
      "2025-07-03     0.008339    0.009161   0.009400    0.008489     -0.401650  ...   \n",
      "2025-07-04     0.000000    0.000000   0.000000    0.000000      0.000000  ...   \n",
      "2025-07-07    -0.007862   -0.003593  -0.007278    0.002014      0.550198  ...   \n",
      "2025-07-08    -0.000716   -0.003093   0.002701   -0.003996      0.095917  ...   \n",
      "\n",
      "            Indice_Condicoes_Econ_BR  Indice_Condicoes_Econ_BR_USD  \\\n",
      "2025-06-30                       0.0                           0.0   \n",
      "2025-07-01                       0.0                           0.0   \n",
      "2025-07-02                       0.0                           0.0   \n",
      "2025-07-03                       0.0                           0.0   \n",
      "2025-07-04                       0.0                           0.0   \n",
      "2025-07-07                       0.0                           0.0   \n",
      "2025-07-08                       0.0                           0.0   \n",
      "\n",
      "            Salario_Minimo  IBC_BR  Populacao_BR  PIB_Trimestral_Real  \\\n",
      "2025-06-30             0.0     0.0           0.0                  0.0   \n",
      "2025-07-01             0.0     0.0           0.0                  0.0   \n",
      "2025-07-02             0.0     0.0           0.0                  0.0   \n",
      "2025-07-03             0.0     0.0           0.0                  0.0   \n",
      "2025-07-04             0.0     0.0           0.0                  0.0   \n",
      "2025-07-07             0.0     0.0           0.0                  0.0   \n",
      "2025-07-08             0.0     0.0           0.0                  0.0   \n",
      "\n",
      "            PIB_Anual_Corrente  Deflator_Implicito_PIB   DEXBZUS  CPIAUCSL  \n",
      "2025-06-30                 0.0                     0.0 -0.009252       0.0  \n",
      "2025-07-01                 0.0                     0.0  0.005433       0.0  \n",
      "2025-07-02                 0.0                     0.0 -0.005551       0.0  \n",
      "2025-07-03                 0.0                     0.0 -0.001989       0.0  \n",
      "2025-07-04                 0.0                     0.0  0.000000       0.0  \n",
      "2025-07-07                 0.0                     0.0  0.000000       0.0  \n",
      "2025-07-08                 0.0                     0.0  0.000000       0.0  \n",
      "\n",
      "[7 rows x 47 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repositories\\time-series-prediction-rnn\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "INFO:src.utils.dataset.clean_strategy:Columns removed by f_regression: ['Volume_SB=F']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close_^BVSP  Volume_^BVSP  Volume_^GSPC  Volume_BTC-USD  \\\n",
      "2025-06-30     0.014532      0.229930     -0.266999       -0.072516   \n",
      "2025-07-01     0.004998     -0.173769      0.085149        0.048637   \n",
      "2025-07-02    -0.003569      0.388641     -0.100330        0.275171   \n",
      "2025-07-03     0.013499     -0.309774     -0.401650       -0.102294   \n",
      "2025-07-04     0.003903     -0.652379      0.000000       -0.156022   \n",
      "2025-07-07    -0.014052      1.893298      0.550198        0.065685   \n",
      "2025-07-08    -0.001341      0.103444      0.095917       -0.024958   \n",
      "\n",
      "            Volume_GC=F  Volume_CL=F  IPCA_Mensal  IGP_M_Mensal month_name  \\\n",
      "2025-06-30     3.373239    -0.181963          0.0           0.0       June   \n",
      "2025-07-01    -0.701288    -0.000657          0.0           0.0       July   \n",
      "2025-07-02    -0.894879     0.372941          0.0           0.0       July   \n",
      "2025-07-03    -1.000000    -1.000000          0.0           0.0       July   \n",
      "2025-07-04     0.000000     0.000000          0.0           0.0       July   \n",
      "2025-07-07     0.000000     0.000000          0.0           0.0       July   \n",
      "2025-07-08     0.000000     0.000000          0.0           0.0       July   \n",
      "\n",
      "            week_of_month day_of_week  is_weekend  is_holiday  \n",
      "2025-06-30              6      Monday           0           0  \n",
      "2025-07-01              1     Tuesday           0           0  \n",
      "2025-07-02              1   Wednesday           0           0  \n",
      "2025-07-03              1    Thursday           0           0  \n",
      "2025-07-04              1      Friday           0           0  \n",
      "2025-07-07              2      Monday           0           0  \n",
      "2025-07-08              2     Tuesday           0           0  \n",
      "            Close_^BVSP  Volume_^BVSP  Volume_^GSPC  Volume_BTC-USD  \\\n",
      "2025-06-30     0.014532      0.229930     -0.266999       -0.072516   \n",
      "2025-07-01     0.004998     -0.173769      0.085149        0.048637   \n",
      "2025-07-02    -0.003569      0.388641     -0.100330        0.275171   \n",
      "2025-07-03     0.013499     -0.309774     -0.401650       -0.102294   \n",
      "2025-07-04     0.003903     -0.652379      0.000000       -0.156022   \n",
      "2025-07-07    -0.014052      1.893298      0.550198        0.065685   \n",
      "2025-07-08    -0.001341      0.103444      0.095917       -0.024958   \n",
      "\n",
      "            Volume_GC=F  Volume_CL=F  IPCA_Mensal  IGP_M_Mensal month_name  \\\n",
      "2025-06-30     3.373239    -0.181963          0.0           0.0       June   \n",
      "2025-07-01    -0.701288    -0.000657          0.0           0.0       July   \n",
      "2025-07-02    -0.894879     0.372941          0.0           0.0       July   \n",
      "2025-07-03    -1.000000    -1.000000          0.0           0.0       July   \n",
      "2025-07-04     0.000000     0.000000          0.0           0.0       July   \n",
      "2025-07-07     0.000000     0.000000          0.0           0.0       July   \n",
      "2025-07-08     0.000000     0.000000          0.0           0.0       July   \n",
      "\n",
      "            week_of_month day_of_week  is_weekend  is_holiday  \n",
      "2025-06-30              6      Monday           0           0  \n",
      "2025-07-01              1     Tuesday           0           0  \n",
      "2025-07-02              1   Wednesday           0           0  \n",
      "2025-07-03              1    Thursday           0           0  \n",
      "2025-07-04              1      Friday           0           0  \n",
      "2025-07-07              2      Monday           0           0  \n",
      "2025-07-08              2     Tuesday           0           0  \n",
      "\u001b[32m2025-07-09 13:28:54.807\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m109\u001b[0m - \u001b[32m\u001b[1mClean data successfully loaded...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:54.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mTotal time taken: 61.26 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import dataset\n",
    "\n",
    "dataset.main(\n",
    "    # ---- REPLACE DEFAULT AS APPROPRIATE ----\n",
    "    asset = '^BVSP',\n",
    "    asset_focus = 'Close',\n",
    "    years = 3\n",
    "    # -----------------------------------------\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fce4b8",
   "metadata": {},
   "source": [
    "## Feature Engineering — Time Series Preparation\n",
    "\n",
    "This part of the pipeline is responsible for transforming the cleaned dataset into structured features suitable for training time series models. It includes the following key steps:\n",
    "- Feature Generation: Constructs relevant features based on historical market data.\n",
    "- Dataset Splitting: The dataset is split into training and testing sets using a consistent strategy to preserve temporal structure.\n",
    "- Time Series Windowing: Converts the sequential data into overlapping windows, enabling the model to learn temporal dependencies.\n",
    "- Saving Artifacts: Both training and testing sets are stored for reproducibility, along with the transformation pipelines applied during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64946194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:28:59.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mGenerating features from dataset...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:59.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.splitter_strategy\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mSplitting dataset into training and testing sets...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:59.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.generator_strategy\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mGenerating Timeseries from dataset...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:59.196\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m51\u001b[0m - \u001b[32m\u001b[1mSaving train features in C:\\Repositories\\time-series-prediction-rnn\\data\\processed...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:59.199\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m55\u001b[0m - \u001b[32m\u001b[1mSaving test features in C:\\Repositories\\time-series-prediction-rnn\\data\\processed...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:59.201\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m59\u001b[0m - \u001b[32m\u001b[1mFeatures generation complete.\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:59.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mSaving transformers...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:59.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.splitter_strategy\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mSplitting dataset into training and testing sets...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:28:59.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mTotal time taken: 0.05 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "from src import features\n",
    "\n",
    "features.main(\n",
    "    # ---- REPLACE DEFAULT PATHS AS APPROPRIATE ----\n",
    "    dataset_path = config.PROCESSED_DATA_DIR / \"dataset.csv\",\n",
    "    train_dir = config.PROCESSED_DATA_DIR,\n",
    "    test_dir = config.PROCESSED_DATA_DIR,\n",
    "    targets = [\"^BVSP\"],\n",
    "    train_size_ratio = 1,\n",
    "    batch_size = 1,\n",
    "    sequence_length = 20\n",
    "    # -----------------------------------------\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66434c",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "The modeling process begins with loading the training dataset. Next, the base model is constructed, and both the compilation and training strategies are defined. With the pipeline structure in place, the model is trained over 100 epochs using an iterative approach to adjust the weights.\n",
    "\n",
    "During training, key metrics are monitored, including accuracy, loss (error), validation accuracy and loss (on unseen data), as well as the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff11608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:29:01.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mLoading training dataset...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:29:01.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mSelecting builder strategy...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:29:01.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSelecting compile strategy...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:29:01.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mSelecting training strategy...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:29:01.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mBuilding model training pipeline template...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:29:01.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTraining model...\u001b[0m\n",
      "Epoch 1/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 229ms/step - loss: 0.4217 - mae: 0.7437 - mse: 1.0428 - r2_score: -0.0149 - rmse: 1.0166 - smape: 174.6724 - val_loss: 0.4022 - val_mae: 0.7080 - val_mse: 1.0735 - val_r2_score: -5.6455e-04 - val_rmse: 1.0338 - val_smape: 181.3863 - learning_rate: 0.0010\n",
      "Epoch 2/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.4146 - mae: 0.7362 - mse: 1.0267 - r2_score: 0.0011 - rmse: 1.0086 - smape: 182.2066 - val_loss: 0.4012 - val_mae: 0.7078 - val_mse: 1.0771 - val_r2_score: -0.0042 - val_rmse: 1.0356 - val_smape: 187.6075 - learning_rate: 0.0010\n",
      "Epoch 3/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.4134 - mae: 0.7358 - mse: 1.0221 - r2_score: 0.0048 - rmse: 1.0065 - smape: 186.0319 - val_loss: 0.3996 - val_mae: 0.7071 - val_mse: 1.0747 - val_r2_score: -0.0019 - val_rmse: 1.0344 - val_smape: 185.9657 - learning_rate: 0.0010\n",
      "Epoch 4/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.4123 - mae: 0.7347 - mse: 1.0213 - r2_score: 0.0071 - rmse: 1.0058 - smape: 182.0879 - val_loss: 0.3976 - val_mae: 0.7058 - val_mse: 1.0668 - val_r2_score: 0.0053 - val_rmse: 1.0307 - val_smape: 182.2015 - learning_rate: 0.0010\n",
      "Epoch 5/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.4099 - mae: 0.7323 - mse: 1.0146 - r2_score: 0.0117 - rmse: 1.0029 - smape: 177.5987 - val_loss: 0.3959 - val_mae: 0.7054 - val_mse: 1.0653 - val_r2_score: 0.0066 - val_rmse: 1.0300 - val_smape: 178.4518 - learning_rate: 0.0010\n",
      "Epoch 6/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.4087 - mae: 0.7309 - mse: 1.0139 - r2_score: 0.0129 - rmse: 1.0024 - smape: 174.6212 - val_loss: 0.3942 - val_mae: 0.7051 - val_mse: 1.0640 - val_r2_score: 0.0081 - val_rmse: 1.0292 - val_smape: 177.4651 - learning_rate: 0.0010\n",
      "Epoch 7/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.4102 - mae: 0.7349 - mse: 1.0176 - r2_score: 0.0099 - rmse: 1.0039 - smape: 174.1779 - val_loss: 0.3926 - val_mae: 0.7035 - val_mse: 1.0556 - val_r2_score: 0.0156 - val_rmse: 1.0253 - val_smape: 174.5867 - learning_rate: 0.0010\n",
      "Epoch 8/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.4068 - mae: 0.7295 - mse: 1.0109 - r2_score: 0.0151 - rmse: 1.0011 - smape: 171.0046 - val_loss: 0.3903 - val_mae: 0.7014 - val_mse: 1.0481 - val_r2_score: 0.0225 - val_rmse: 1.0216 - val_smape: 172.2501 - learning_rate: 0.0010\n",
      "Epoch 9/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.4015 - mae: 0.7239 - mse: 0.9969 - r2_score: 0.0306 - rmse: 0.9935 - smape: 167.2371 - val_loss: 0.3871 - val_mae: 0.6992 - val_mse: 1.0365 - val_r2_score: 0.0334 - val_rmse: 1.0160 - val_smape: 167.8322 - learning_rate: 0.0010\n",
      "Epoch 10/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.3966 - mae: 0.7170 - mse: 0.9772 - r2_score: 0.0488 - rmse: 0.9840 - smape: 163.3793 - val_loss: 0.3840 - val_mae: 0.6966 - val_mse: 1.0234 - val_r2_score: 0.0466 - val_rmse: 1.0093 - val_smape: 166.3121 - learning_rate: 0.0010\n",
      "Epoch 11/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.3904 - mae: 0.7100 - mse: 0.9582 - r2_score: 0.0681 - rmse: 0.9740 - smape: 156.7096 - val_loss: 0.3806 - val_mae: 0.6941 - val_mse: 1.0134 - val_r2_score: 0.0560 - val_rmse: 1.0043 - val_smape: 160.6699 - learning_rate: 0.0010\n",
      "Epoch 12/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.3889 - mae: 0.7079 - mse: 0.9550 - r2_score: 0.0687 - rmse: 0.9728 - smape: 153.4895 - val_loss: 0.3766 - val_mae: 0.6922 - val_mse: 0.9917 - val_r2_score: 0.0771 - val_rmse: 0.9932 - val_smape: 157.1032 - learning_rate: 0.0010\n",
      "Epoch 13/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.3904 - mae: 0.7136 - mse: 0.9500 - r2_score: 0.0736 - rmse: 0.9706 - smape: 152.8303 - val_loss: 0.3754 - val_mae: 0.6887 - val_mse: 1.0010 - val_r2_score: 0.0674 - val_rmse: 0.9982 - val_smape: 155.4367 - learning_rate: 0.0010\n",
      "Epoch 14/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.3701 - mae: 0.6790 - mse: 0.9002 - r2_score: 0.1250 - rmse: 0.9438 - smape: 144.2280 - val_loss: 0.3722 - val_mae: 0.6869 - val_mse: 0.9842 - val_r2_score: 0.0839 - val_rmse: 0.9895 - val_smape: 149.3481 - learning_rate: 0.0010\n",
      "Epoch 15/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.3639 - mae: 0.6744 - mse: 0.8783 - r2_score: 0.1447 - rmse: 0.9321 - smape: 142.0758 - val_loss: 0.3645 - val_mae: 0.6742 - val_mse: 0.9633 - val_r2_score: 0.1051 - val_rmse: 0.9784 - val_smape: 145.0334 - learning_rate: 0.0010\n",
      "Epoch 16/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.3600 - mae: 0.6721 - mse: 0.8592 - r2_score: 0.1635 - rmse: 0.9220 - smape: 140.1773 - val_loss: 0.3596 - val_mae: 0.6717 - val_mse: 0.9410 - val_r2_score: 0.1276 - val_rmse: 0.9664 - val_smape: 144.7772 - learning_rate: 0.0010\n",
      "Epoch 17/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.3626 - mae: 0.6707 - mse: 0.8702 - r2_score: 0.1563 - rmse: 0.9269 - smape: 136.8157 - val_loss: 0.3600 - val_mae: 0.6685 - val_mse: 0.9526 - val_r2_score: 0.1155 - val_rmse: 0.9728 - val_smape: 143.3086 - learning_rate: 0.0010\n",
      "Epoch 18/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.3566 - mae: 0.6609 - mse: 0.8670 - r2_score: 0.1604 - rmse: 0.9253 - smape: 136.4831 - val_loss: 0.3683 - val_mae: 0.6800 - val_mse: 0.9722 - val_r2_score: 0.0969 - val_rmse: 0.9829 - val_smape: 138.3642 - learning_rate: 0.0010\n",
      "Epoch 19/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.3566 - mae: 0.6641 - mse: 0.8554 - r2_score: 0.1709 - rmse: 0.9188 - smape: 133.7153 - val_loss: 0.3595 - val_mae: 0.6709 - val_mse: 0.9325 - val_r2_score: 0.1377 - val_rmse: 0.9612 - val_smape: 144.0074 - learning_rate: 0.0010\n",
      "Epoch 20/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.3468 - mae: 0.6572 - mse: 0.8222 - r2_score: 0.2016 - rmse: 0.9015 - smape: 137.5006 - val_loss: 0.3607 - val_mae: 0.6727 - val_mse: 0.9411 - val_r2_score: 0.1289 - val_rmse: 0.9660 - val_smape: 140.8334 - learning_rate: 0.0010\n",
      "Epoch 21/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.3472 - mae: 0.6544 - mse: 0.8231 - r2_score: 0.1992 - rmse: 0.9017 - smape: 134.0968 - val_loss: 0.3616 - val_mae: 0.6776 - val_mse: 0.9281 - val_r2_score: 0.1430 - val_rmse: 0.9584 - val_smape: 141.8897 - learning_rate: 0.0010\n",
      "Epoch 22/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.3436 - mae: 0.6488 - mse: 0.8161 - r2_score: 0.2097 - rmse: 0.8977 - smape: 131.8581 - val_loss: 0.3642 - val_mae: 0.6769 - val_mse: 0.9507 - val_r2_score: 0.1196 - val_rmse: 0.9711 - val_smape: 140.3455 - learning_rate: 0.0010\n",
      "Epoch 23/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.3462 - mae: 0.6504 - mse: 0.8090 - r2_score: 0.2141 - rmse: 0.8936 - smape: 129.0853 - val_loss: 0.3592 - val_mae: 0.6697 - val_mse: 0.9271 - val_r2_score: 0.1430 - val_rmse: 0.9583 - val_smape: 139.7614 - learning_rate: 0.0010\n",
      "Epoch 24/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.3293 - mae: 0.6305 - mse: 0.7589 - r2_score: 0.2636 - rmse: 0.8654 - smape: 128.9870 - val_loss: 0.3637 - val_mae: 0.6678 - val_mse: 0.9538 - val_r2_score: 0.1160 - val_rmse: 0.9729 - val_smape: 135.4067 - learning_rate: 0.0010\n",
      "Epoch 25/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.3245 - mae: 0.6255 - mse: 0.7658 - r2_score: 0.2563 - rmse: 0.8695 - smape: 129.0406 - val_loss: 0.3650 - val_mae: 0.6754 - val_mse: 0.9379 - val_r2_score: 0.1335 - val_rmse: 0.9637 - val_smape: 135.2619 - learning_rate: 0.0010\n",
      "Epoch 26/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.3354 - mae: 0.6426 - mse: 0.7832 - r2_score: 0.2378 - rmse: 0.8797 - smape: 128.7442 - val_loss: 0.3579 - val_mae: 0.6636 - val_mse: 0.9340 - val_r2_score: 0.1347 - val_rmse: 0.9626 - val_smape: 138.2723 - learning_rate: 0.0010\n",
      "Epoch 27/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.3263 - mae: 0.6276 - mse: 0.7514 - r2_score: 0.2642 - rmse: 0.8629 - smape: 129.0754 - val_loss: 0.3575 - val_mae: 0.6646 - val_mse: 0.9290 - val_r2_score: 0.1396 - val_rmse: 0.9599 - val_smape: 137.3577 - learning_rate: 0.0010\n",
      "Epoch 28/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.3184 - mae: 0.6141 - mse: 0.7368 - r2_score: 0.2890 - rmse: 0.8506 - smape: 123.1890 - val_loss: 0.3620 - val_mae: 0.6731 - val_mse: 0.9367 - val_r2_score: 0.1321 - val_rmse: 0.9640 - val_smape: 134.1115 - learning_rate: 0.0010\n",
      "Epoch 29/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.3203 - mae: 0.6141 - mse: 0.7312 - r2_score: 0.2864 - rmse: 0.8517 - smape: 121.2174 - val_loss: 0.3596 - val_mae: 0.6705 - val_mse: 0.9331 - val_r2_score: 0.1359 - val_rmse: 0.9620 - val_smape: 134.4848 - learning_rate: 0.0010\n",
      "Epoch 30/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.3195 - mae: 0.6200 - mse: 0.7391 - r2_score: 0.2802 - rmse: 0.8545 - smape: 124.6505 - val_loss: 0.3588 - val_mae: 0.6674 - val_mse: 0.9305 - val_r2_score: 0.1409 - val_rmse: 0.9596 - val_smape: 135.0700 - learning_rate: 0.0010\n",
      "Epoch 31/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.3160 - mae: 0.6090 - mse: 0.7265 - r2_score: 0.2968 - rmse: 0.8465 - smape: 123.9651 - val_loss: 0.3647 - val_mae: 0.6702 - val_mse: 0.9525 - val_r2_score: 0.1195 - val_rmse: 0.9713 - val_smape: 131.4293 - learning_rate: 0.0010\n",
      "Epoch 32/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.3088 - mae: 0.5971 - mse: 0.7108 - r2_score: 0.3146 - rmse: 0.8358 - smape: 119.4307 - val_loss: 0.3658 - val_mae: 0.6783 - val_mse: 0.9459 - val_r2_score: 0.1244 - val_rmse: 0.9684 - val_smape: 132.4896 - learning_rate: 0.0010\n",
      "Epoch 33/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.3122 - mae: 0.6003 - mse: 0.7125 - r2_score: 0.3082 - rmse: 0.8387 - smape: 118.1934 - val_loss: 0.3729 - val_mae: 0.6798 - val_mse: 0.9868 - val_r2_score: 0.0824 - val_rmse: 0.9906 - val_smape: 133.2645 - learning_rate: 0.0010\n",
      "Epoch 34/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.3060 - mae: 0.5999 - mse: 0.6919 - r2_score: 0.3313 - rmse: 0.8256 - smape: 119.5034 - val_loss: 0.3641 - val_mae: 0.6758 - val_mse: 0.9483 - val_r2_score: 0.1221 - val_rmse: 0.9697 - val_smape: 134.0087 - learning_rate: 0.0010\n",
      "Epoch 35/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.2975 - mae: 0.5830 - mse: 0.6776 - r2_score: 0.3435 - rmse: 0.8170 - smape: 116.7074 - val_loss: 0.3667 - val_mae: 0.6805 - val_mse: 0.9518 - val_r2_score: 0.1198 - val_rmse: 0.9712 - val_smape: 136.5333 - learning_rate: 0.0010\n",
      "Epoch 36/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.3055 - mae: 0.6047 - mse: 0.6832 - r2_score: 0.3372 - rmse: 0.8210 - smape: 122.1876 - val_loss: 0.3655 - val_mae: 0.6767 - val_mse: 0.9475 - val_r2_score: 0.1228 - val_rmse: 0.9693 - val_smape: 137.4003 - learning_rate: 0.0010\n",
      "Epoch 37/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.2795 - mae: 0.5588 - mse: 0.6245 - r2_score: 0.3950 - rmse: 0.7838 - smape: 112.1037 - val_loss: 0.3721 - val_mae: 0.6888 - val_mse: 0.9596 - val_r2_score: 0.1118 - val_rmse: 0.9754 - val_smape: 136.4818 - learning_rate: 0.0010\n",
      "Epoch 38/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.2780 - mae: 0.5605 - mse: 0.6267 - r2_score: 0.3986 - rmse: 0.7823 - smape: 111.7036 - val_loss: 0.3726 - val_mae: 0.6885 - val_mse: 0.9714 - val_r2_score: 0.1016 - val_rmse: 0.9811 - val_smape: 137.5625 - learning_rate: 0.0010\n",
      "Epoch 39/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.2821 - mae: 0.5641 - mse: 0.6369 - r2_score: 0.3779 - rmse: 0.7931 - smape: 114.5782 - val_loss: 0.3685 - val_mae: 0.6860 - val_mse: 0.9549 - val_r2_score: 0.1176 - val_rmse: 0.9724 - val_smape: 137.0769 - learning_rate: 0.0010\n",
      "Epoch 40/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.2800 - mae: 0.5673 - mse: 0.6223 - r2_score: 0.3976 - rmse: 0.7833 - smape: 114.6561 - val_loss: 0.3689 - val_mae: 0.6864 - val_mse: 0.9511 - val_r2_score: 0.1208 - val_rmse: 0.9706 - val_smape: 138.1605 - learning_rate: 0.0010\n",
      "Epoch 41/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.2764 - mae: 0.5586 - mse: 0.6044 - r2_score: 0.4126 - rmse: 0.7718 - smape: 112.5691 - val_loss: 0.3659 - val_mae: 0.6809 - val_mse: 0.9435 - val_r2_score: 0.1259 - val_rmse: 0.9675 - val_smape: 136.1906 - learning_rate: 0.0010\n",
      "Epoch 42/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.2759 - mae: 0.5616 - mse: 0.5894 - r2_score: 0.4266 - rmse: 0.7626 - smape: 112.4130 - val_loss: 0.3631 - val_mae: 0.6770 - val_mse: 0.9358 - val_r2_score: 0.1306 - val_rmse: 0.9644 - val_smape: 135.0853 - learning_rate: 0.0010\n",
      "Epoch 43/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.2707 - mae: 0.5446 - mse: 0.6104 - r2_score: 0.4095 - rmse: 0.7747 - smape: 109.5020 - val_loss: 0.3662 - val_mae: 0.6813 - val_mse: 0.9447 - val_r2_score: 0.1231 - val_rmse: 0.9687 - val_smape: 136.1102 - learning_rate: 0.0010\n",
      "Epoch 44/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.2666 - mae: 0.5448 - mse: 0.5953 - r2_score: 0.4229 - rmse: 0.7661 - smape: 107.9041 - val_loss: 0.3661 - val_mae: 0.6805 - val_mse: 0.9458 - val_r2_score: 0.1236 - val_rmse: 0.9687 - val_smape: 136.0101 - learning_rate: 5.0000e-04\n",
      "Epoch 45/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.2714 - mae: 0.5530 - mse: 0.5900 - r2_score: 0.4271 - rmse: 0.7628 - smape: 112.3731 - val_loss: 0.3628 - val_mae: 0.6773 - val_mse: 0.9340 - val_r2_score: 0.1356 - val_rmse: 0.9623 - val_smape: 135.3790 - learning_rate: 5.0000e-04\n",
      "Epoch 46/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.2668 - mae: 0.5464 - mse: 0.5902 - r2_score: 0.4291 - rmse: 0.7624 - smape: 111.7676 - val_loss: 0.3607 - val_mae: 0.6687 - val_mse: 0.9338 - val_r2_score: 0.1368 - val_rmse: 0.9617 - val_smape: 133.4561 - learning_rate: 5.0000e-04\n",
      "Epoch 47/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.2508 - mae: 0.5281 - mse: 0.5409 - r2_score: 0.4731 - rmse: 0.7306 - smape: 109.1775 - val_loss: 0.3645 - val_mae: 0.6765 - val_mse: 0.9371 - val_r2_score: 0.1338 - val_rmse: 0.9634 - val_smape: 133.7180 - learning_rate: 5.0000e-04\n",
      "Epoch 48/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.2507 - mae: 0.5230 - mse: 0.5456 - r2_score: 0.4696 - rmse: 0.7341 - smape: 107.3463 - val_loss: 0.3671 - val_mae: 0.6842 - val_mse: 0.9393 - val_r2_score: 0.1305 - val_rmse: 0.9651 - val_smape: 136.0199 - learning_rate: 5.0000e-04\n",
      "Epoch 49/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.2536 - mae: 0.5205 - mse: 0.5484 - r2_score: 0.4697 - rmse: 0.7332 - smape: 104.5697 - val_loss: 0.3729 - val_mae: 0.6939 - val_mse: 0.9521 - val_r2_score: 0.1175 - val_rmse: 0.9720 - val_smape: 134.5781 - learning_rate: 5.0000e-04\n",
      "Epoch 50/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.2618 - mae: 0.5472 - mse: 0.5637 - r2_score: 0.4507 - rmse: 0.7457 - smape: 111.1488 - val_loss: 0.3697 - val_mae: 0.6854 - val_mse: 0.9493 - val_r2_score: 0.1206 - val_rmse: 0.9704 - val_smape: 134.1068 - learning_rate: 5.0000e-04\n",
      "Epoch 51/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.2539 - mae: 0.5301 - mse: 0.5502 - r2_score: 0.4683 - rmse: 0.7349 - smape: 107.3363 - val_loss: 0.3635 - val_mae: 0.6766 - val_mse: 0.9294 - val_r2_score: 0.1392 - val_rmse: 0.9601 - val_smape: 134.7659 - learning_rate: 5.0000e-04\n",
      "Epoch 52/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.2502 - mae: 0.5270 - mse: 0.5250 - r2_score: 0.4886 - rmse: 0.7200 - smape: 107.6822 - val_loss: 0.3668 - val_mae: 0.6809 - val_mse: 0.9384 - val_r2_score: 0.1302 - val_rmse: 0.9650 - val_smape: 131.8491 - learning_rate: 5.0000e-04\n",
      "Epoch 53/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.2365 - mae: 0.5008 - mse: 0.5017 - r2_score: 0.5104 - rmse: 0.7031 - smape: 102.2601 - val_loss: 0.3659 - val_mae: 0.6786 - val_mse: 0.9372 - val_r2_score: 0.1315 - val_rmse: 0.9643 - val_smape: 131.6704 - learning_rate: 5.0000e-04\n",
      "Epoch 54/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2477 - mae: 0.5198 - mse: 0.5398 - r2_score: 0.4775 - rmse: 0.7289 - smape: 105.0296 - val_loss: 0.3624 - val_mae: 0.6720 - val_mse: 0.9314 - val_r2_score: 0.1376 - val_rmse: 0.9611 - val_smape: 133.3264 - learning_rate: 5.0000e-04\n",
      "Epoch 55/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.2435 - mae: 0.5117 - mse: 0.5181 - r2_score: 0.4962 - rmse: 0.7141 - smape: 103.9984 - val_loss: 0.3620 - val_mae: 0.6732 - val_mse: 0.9316 - val_r2_score: 0.1366 - val_rmse: 0.9615 - val_smape: 133.4127 - learning_rate: 5.0000e-04\n",
      "Epoch 56/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.2407 - mae: 0.5130 - mse: 0.5106 - r2_score: 0.5047 - rmse: 0.7093 - smape: 106.0348 - val_loss: 0.3608 - val_mae: 0.6742 - val_mse: 0.9215 - val_r2_score: 0.1461 - val_rmse: 0.9562 - val_smape: 135.1020 - learning_rate: 5.0000e-04\n",
      "Epoch 57/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.2513 - mae: 0.5271 - mse: 0.5559 - r2_score: 0.4626 - rmse: 0.7386 - smape: 106.6123 - val_loss: 0.3674 - val_mae: 0.6817 - val_mse: 0.9460 - val_r2_score: 0.1229 - val_rmse: 0.9690 - val_smape: 132.7117 - learning_rate: 5.0000e-04\n",
      "Epoch 58/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2453 - mae: 0.5152 - mse: 0.5380 - r2_score: 0.4790 - rmse: 0.7269 - smape: 104.6141 - val_loss: 0.3681 - val_mae: 0.6811 - val_mse: 0.9506 - val_r2_score: 0.1187 - val_rmse: 0.9713 - val_smape: 134.2580 - learning_rate: 5.0000e-04\n",
      "Epoch 59/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.2418 - mae: 0.5150 - mse: 0.5187 - r2_score: 0.4973 - rmse: 0.7148 - smape: 105.1189 - val_loss: 0.3657 - val_mae: 0.6793 - val_mse: 0.9445 - val_r2_score: 0.1244 - val_rmse: 0.9682 - val_smape: 136.6318 - learning_rate: 5.0000e-04\n",
      "Epoch 60/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.2389 - mae: 0.5065 - mse: 0.5107 - r2_score: 0.5006 - rmse: 0.7103 - smape: 103.6854 - val_loss: 0.3621 - val_mae: 0.6750 - val_mse: 0.9313 - val_r2_score: 0.1361 - val_rmse: 0.9616 - val_smape: 135.0950 - learning_rate: 2.5000e-04\n",
      "Epoch 61/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.2351 - mae: 0.4937 - mse: 0.5137 - r2_score: 0.5029 - rmse: 0.7112 - smape: 100.2602 - val_loss: 0.3592 - val_mae: 0.6714 - val_mse: 0.9201 - val_r2_score: 0.1459 - val_rmse: 0.9560 - val_smape: 133.7628 - learning_rate: 2.5000e-04\n",
      "Epoch 62/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.2404 - mae: 0.5076 - mse: 0.5253 - r2_score: 0.4923 - rmse: 0.7169 - smape: 102.7269 - val_loss: 0.3595 - val_mae: 0.6708 - val_mse: 0.9244 - val_r2_score: 0.1420 - val_rmse: 0.9582 - val_smape: 134.6494 - learning_rate: 2.5000e-04\n",
      "Epoch 63/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.2263 - mae: 0.4903 - mse: 0.4757 - r2_score: 0.5358 - rmse: 0.6843 - smape: 102.5711 - val_loss: 0.3614 - val_mae: 0.6737 - val_mse: 0.9338 - val_r2_score: 0.1335 - val_rmse: 0.9630 - val_smape: 135.2822 - learning_rate: 2.5000e-04\n",
      "Epoch 64/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.2331 - mae: 0.4978 - mse: 0.5219 - r2_score: 0.4936 - rmse: 0.7171 - smape: 102.6578 - val_loss: 0.3612 - val_mae: 0.6719 - val_mse: 0.9323 - val_r2_score: 0.1358 - val_rmse: 0.9619 - val_smape: 134.8133 - learning_rate: 2.5000e-04\n",
      "Epoch 65/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2246 - mae: 0.4927 - mse: 0.4831 - r2_score: 0.5278 - rmse: 0.6904 - smape: 106.8769 - val_loss: 0.3614 - val_mae: 0.6731 - val_mse: 0.9322 - val_r2_score: 0.1358 - val_rmse: 0.9619 - val_smape: 135.5105 - learning_rate: 2.5000e-04\n",
      "Epoch 66/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.2290 - mae: 0.4984 - mse: 0.4746 - r2_score: 0.5359 - rmse: 0.6844 - smape: 103.5253 - val_loss: 0.3592 - val_mae: 0.6696 - val_mse: 0.9225 - val_r2_score: 0.1449 - val_rmse: 0.9568 - val_smape: 135.4591 - learning_rate: 2.5000e-04\n",
      "Epoch 67/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.2278 - mae: 0.4965 - mse: 0.4833 - r2_score: 0.5323 - rmse: 0.6889 - smape: 103.4396 - val_loss: 0.3597 - val_mae: 0.6697 - val_mse: 0.9257 - val_r2_score: 0.1422 - val_rmse: 0.9584 - val_smape: 134.5786 - learning_rate: 2.5000e-04\n",
      "Epoch 68/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2350 - mae: 0.5046 - mse: 0.5026 - r2_score: 0.5136 - rmse: 0.7029 - smape: 105.2737 - val_loss: 0.3606 - val_mae: 0.6707 - val_mse: 0.9338 - val_r2_score: 0.1347 - val_rmse: 0.9626 - val_smape: 135.0887 - learning_rate: 2.5000e-04\n",
      "Epoch 69/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.2241 - mae: 0.4907 - mse: 0.4723 - r2_score: 0.5370 - rmse: 0.6832 - smape: 103.3193 - val_loss: 0.3617 - val_mae: 0.6725 - val_mse: 0.9366 - val_r2_score: 0.1318 - val_rmse: 0.9641 - val_smape: 134.0176 - learning_rate: 2.5000e-04\n",
      "Epoch 70/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2287 - mae: 0.4856 - mse: 0.5029 - r2_score: 0.5154 - rmse: 0.7026 - smape: 100.0590 - val_loss: 0.3628 - val_mae: 0.6751 - val_mse: 0.9354 - val_r2_score: 0.1329 - val_rmse: 0.9635 - val_smape: 134.1693 - learning_rate: 2.5000e-04\n",
      "Epoch 71/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.2340 - mae: 0.5072 - mse: 0.4875 - r2_score: 0.5262 - rmse: 0.6907 - smape: 104.9339 - val_loss: 0.3645 - val_mae: 0.6775 - val_mse: 0.9394 - val_r2_score: 0.1292 - val_rmse: 0.9656 - val_smape: 134.7213 - learning_rate: 2.5000e-04\n",
      "Epoch 72/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.2137 - mae: 0.4701 - mse: 0.4437 - r2_score: 0.5660 - rmse: 0.6618 - smape: 99.5352 - val_loss: 0.3656 - val_mae: 0.6786 - val_mse: 0.9432 - val_r2_score: 0.1255 - val_rmse: 0.9676 - val_smape: 134.1070 - learning_rate: 2.5000e-04\n",
      "Epoch 73/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.2359 - mae: 0.5049 - mse: 0.5190 - r2_score: 0.4994 - rmse: 0.7135 - smape: 103.8967 - val_loss: 0.3639 - val_mae: 0.6750 - val_mse: 0.9397 - val_r2_score: 0.1285 - val_rmse: 0.9659 - val_smape: 132.8025 - learning_rate: 2.5000e-04\n",
      "Epoch 74/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.2236 - mae: 0.4893 - mse: 0.4819 - r2_score: 0.5318 - rmse: 0.6891 - smape: 103.1729 - val_loss: 0.3608 - val_mae: 0.6701 - val_mse: 0.9298 - val_r2_score: 0.1378 - val_rmse: 0.9607 - val_smape: 134.9125 - learning_rate: 2.5000e-04\n",
      "Epoch 75/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2244 - mae: 0.4909 - mse: 0.4660 - r2_score: 0.5474 - rmse: 0.6778 - smape: 102.2223 - val_loss: 0.3602 - val_mae: 0.6681 - val_mse: 0.9302 - val_r2_score: 0.1376 - val_rmse: 0.9609 - val_smape: 135.2028 - learning_rate: 2.5000e-04\n",
      "Epoch 76/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.2217 - mae: 0.4797 - mse: 0.4691 - r2_score: 0.5430 - rmse: 0.6799 - smape: 99.3208 - val_loss: 0.3607 - val_mae: 0.6681 - val_mse: 0.9350 - val_r2_score: 0.1331 - val_rmse: 0.9634 - val_smape: 134.6381 - learning_rate: 1.2500e-04\n",
      "Epoch 77/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.2191 - mae: 0.4836 - mse: 0.4533 - r2_score: 0.5581 - rmse: 0.6699 - smape: 100.8931 - val_loss: 0.3599 - val_mae: 0.6667 - val_mse: 0.9328 - val_r2_score: 0.1353 - val_rmse: 0.9622 - val_smape: 133.7627 - learning_rate: 1.2500e-04\n",
      "Epoch 78/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.2292 - mae: 0.4920 - mse: 0.4863 - r2_score: 0.5271 - rmse: 0.6921 - smape: 105.0877 - val_loss: 0.3593 - val_mae: 0.6664 - val_mse: 0.9303 - val_r2_score: 0.1376 - val_rmse: 0.9609 - val_smape: 133.6415 - learning_rate: 1.2500e-04\n",
      "Epoch 79/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2316 - mae: 0.5018 - mse: 0.4956 - r2_score: 0.5219 - rmse: 0.6972 - smape: 104.6834 - val_loss: 0.3587 - val_mae: 0.6660 - val_mse: 0.9279 - val_r2_score: 0.1397 - val_rmse: 0.9597 - val_smape: 133.5329 - learning_rate: 1.2500e-04\n",
      "Epoch 80/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2194 - mae: 0.4771 - mse: 0.4806 - r2_score: 0.5381 - rmse: 0.6856 - smape: 97.8803 - val_loss: 0.3578 - val_mae: 0.6645 - val_mse: 0.9258 - val_r2_score: 0.1416 - val_rmse: 0.9586 - val_smape: 132.9404 - learning_rate: 1.2500e-04\n",
      "Epoch 81/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2253 - mae: 0.4814 - mse: 0.4944 - r2_score: 0.5193 - rmse: 0.6963 - smape: 98.5478 - val_loss: 0.3579 - val_mae: 0.6648 - val_mse: 0.9256 - val_r2_score: 0.1417 - val_rmse: 0.9585 - val_smape: 132.9798 - learning_rate: 1.2500e-04\n",
      "Epoch 82/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2276 - mae: 0.4954 - mse: 0.4734 - r2_score: 0.5356 - rmse: 0.6842 - smape: 102.3491 - val_loss: 0.3582 - val_mae: 0.6652 - val_mse: 0.9256 - val_r2_score: 0.1418 - val_rmse: 0.9585 - val_smape: 132.7302 - learning_rate: 1.2500e-04\n",
      "Epoch 83/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.2266 - mae: 0.4948 - mse: 0.4727 - r2_score: 0.5397 - rmse: 0.6824 - smape: 101.0209 - val_loss: 0.3584 - val_mae: 0.6656 - val_mse: 0.9262 - val_r2_score: 0.1413 - val_rmse: 0.9588 - val_smape: 133.1331 - learning_rate: 1.2500e-04\n",
      "Epoch 84/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.2176 - mae: 0.4812 - mse: 0.4513 - r2_score: 0.5597 - rmse: 0.6673 - smape: 101.5060 - val_loss: 0.3580 - val_mae: 0.6659 - val_mse: 0.9243 - val_r2_score: 0.1430 - val_rmse: 0.9578 - val_smape: 134.2655 - learning_rate: 1.2500e-04\n",
      "Epoch 85/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2164 - mae: 0.4753 - mse: 0.4464 - r2_score: 0.5657 - rmse: 0.6639 - smape: 98.6125 - val_loss: 0.3590 - val_mae: 0.6672 - val_mse: 0.9274 - val_r2_score: 0.1399 - val_rmse: 0.9595 - val_smape: 134.4017 - learning_rate: 1.2500e-04\n",
      "Epoch 86/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2319 - mae: 0.5072 - mse: 0.4802 - r2_score: 0.5304 - rmse: 0.6884 - smape: 105.3688 - val_loss: 0.3598 - val_mae: 0.6682 - val_mse: 0.9310 - val_r2_score: 0.1367 - val_rmse: 0.9613 - val_smape: 133.6738 - learning_rate: 1.2500e-04\n",
      "Epoch 87/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2084 - mae: 0.4737 - mse: 0.4285 - r2_score: 0.5842 - rmse: 0.6489 - smape: 98.9545 - val_loss: 0.3599 - val_mae: 0.6678 - val_mse: 0.9336 - val_r2_score: 0.1341 - val_rmse: 0.9627 - val_smape: 133.4877 - learning_rate: 1.2500e-04\n",
      "Epoch 88/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2202 - mae: 0.4891 - mse: 0.4712 - r2_score: 0.5447 - rmse: 0.6797 - smape: 102.1945 - val_loss: 0.3602 - val_mae: 0.6672 - val_mse: 0.9372 - val_r2_score: 0.1305 - val_rmse: 0.9647 - val_smape: 133.0536 - learning_rate: 1.2500e-04\n",
      "Epoch 89/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.2200 - mae: 0.4829 - mse: 0.4500 - r2_score: 0.5618 - rmse: 0.6665 - smape: 100.8384 - val_loss: 0.3604 - val_mae: 0.6666 - val_mse: 0.9380 - val_r2_score: 0.1297 - val_rmse: 0.9651 - val_smape: 133.1658 - learning_rate: 1.2500e-04\n",
      "Epoch 90/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.2218 - mae: 0.4880 - mse: 0.4624 - r2_score: 0.5501 - rmse: 0.6742 - smape: 102.5796 - val_loss: 0.3603 - val_mae: 0.6663 - val_mse: 0.9364 - val_r2_score: 0.1313 - val_rmse: 0.9642 - val_smape: 132.5921 - learning_rate: 1.2500e-04\n",
      "Epoch 91/256\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2254 - mae: 0.4939 - mse: 0.4750 - r2_score: 0.5436 - rmse: 0.6819 - smape: 103.4067 - val_loss: 0.3597 - val_mae: 0.6657 - val_mse: 0.9334 - val_r2_score: 0.1343 - val_rmse: 0.9626 - val_smape: 133.9718 - learning_rate: 1.2500e-04\n",
      "\u001b[32m2025-07-09 13:30:10.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mSaving 'default_model.keras' in 'C:\\Repositories\\time-series-prediction-rnn\\models'...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:30:10.685\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m93\u001b[0m - \u001b[32m\u001b[1mModeling training complete.\u001b[0m\n",
      "\u001b[32m2025-07-09 13:30:10.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mElapsed time: 69.05 seconds\u001b[0m\n",
      "\u001b[32m2025-07-09 13:30:10.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mLogging experiment into mlflow.\u001b[0m\n",
      "\u001b[32m2025-07-09 13:30:10.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mStarting MLflow run 'Sequential' in experiment '0.0-amp-main-notebook'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/09 13:30:11 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:30:11.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mlog_environment\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mLogging environment details...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:30:11.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mLogging Keras model...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/09 13:30:24 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\SAMSUNG\\AppData\\Local\\Temp\\tmp9yuk5e5a\\model, flavor: keras). Fall back to return ['keras==3.9.2']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/07/09 13:30:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model '2025-amp-rnn' already exists. Creating a new version of this model...\n",
      "Created version '2' of model '2025-amp-rnn'.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:30:24.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mLogging final and aggregate metrics...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:30:28.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m141\u001b[0m - \u001b[1mLogging artifacts...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:30:28.580\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m162\u001b[0m - \u001b[32m\u001b[1mMLflow logging complete.\u001b[0m\n",
      "\u001b[32m2025-07-09 13:30:28.585\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m113\u001b[0m - \u001b[32m\u001b[1mExperiment logged successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "from src.modeling import train\n",
    "\n",
    "train.main(\n",
    "    # ---- REPLACE DEFAULT PATHS AS APPROPRIATE ----\n",
    "    X_path = config.PROCESSED_DATA_DIR / \"X_train.npy\",\n",
    "    y_path = config.PROCESSED_DATA_DIR / \"y_train.npy\",\n",
    "    # -----------------------------------------\n",
    "    optimizer =  None,  # Use default optimizer\n",
    "    loss = None,  # Use default loss\n",
    "    metrics = None,  # Use default metrics\n",
    "    # -----------------------------------------\n",
    "    epochs = 2**8,    \n",
    "    validation_len = 2**7,\n",
    "    batch_size = 2**6,    \n",
    "    # -----------------------------------------\n",
    "    experiment_name = \"0.0-amp-main-notebook\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6162b6",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "In the prediction stage, the trained model is loaded along with the input data. The model then performs inference, generating predictions based on the provided data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f922aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 13:30:28.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.predict\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mPerforming inference for model...\u001b[0m\n",
      "\u001b[32m2025-07-09 13:30:28.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.predict\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mInput data shape: (20, 13)\u001b[0m\n",
      "\u001b[32m2025-07-09 13:30:28.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.generator_strategy\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mGenerating Timeseries from dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repositories\\time-series-prediction-rnn\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "            Close_^BVSP  Volume_^BVSP       type\n",
      "2025-07-07    -0.014052      1.893298       True\n",
      "2025-07-08    -0.001341      0.103444       True\n",
      "2025-07-09     0.003176     -0.114994  Predicted\n",
      "\u001b[32m2025-07-09 13:30:31.394\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.modeling.predict\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m78\u001b[0m - \u001b[32m\u001b[1mInference complete.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "from src.modeling import predict\n",
    "\n",
    "predict.main(\n",
    "    # ---- REPLACE DEFAULT PATHS AS APPROPRIATE ----\n",
    "    input_path = config.PROCESSED_DATA_DIR / \"dataset.csv\"\n",
    "    ,preprocessor_path = config.PROCESSED_DATA_DIR / \"preprocessor.pkl\"\n",
    "    ,postprocessor_path = config.PROCESSED_DATA_DIR / \"postprocessor.pkl\"\n",
    "    ,output_path = config.PROCESSED_DATA_DIR / \"dataset_report.csv\"\n",
    "    ,model_path = config.MODELS_DIR / \"default_model.keras\"  # Select the best model  \n",
    "    # -----------------------------------------\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ef876",
   "metadata": {},
   "source": [
    "## Plot\n",
    "\n",
    "Open the [Power BI Report]((../reports/pbi/amp-fynance.pbip)) and refresh data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
