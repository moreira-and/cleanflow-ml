{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f58e5c2",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42021f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:05:20.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Repositories\\ds-lstm-ibov\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import src.config as config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfd6425",
   "metadata": {},
   "source": [
    "## ETL — Extract, Transform, Load of Raw Dataset\n",
    "\n",
    "This section is responsible for the Extraction phase of the ETL process, pulling historical financial data from multiple sources as defined in the configuration file [dataset.yaml](../configs/dataset.yaml).\n",
    "\n",
    "- Data Storage: Each dataset is stored locally in the data/raw/ directory, organized and saved individually as .csv files for traceability and versioning.\n",
    "- Data Cleaning:\n",
    "  - Missing values are treated using a standard cleaning strategy.\n",
    "  - Features with low variance (threshold < 0.01) are removed to reduce noise and improve modeling efficiency. In this execution, no low-variance columns were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fdcd420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:06:02.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mStarting raw data loading...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:06:02.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRequesting information between 2015-07-01 and 2025-06-28\u001b[0m\n",
      "\u001b[32m2025-06-28 07:06:02.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading BOVESPA (^BVSP) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:06:10.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading S&P500 (^GSPC) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:06:12.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading BITCOIN (BTC-USD) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:06:15.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading OURO (GC=F) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:06:17.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading PETROLEO (CL=F) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:06:20.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading ACUCAR (SB=F) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:06:23.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading SELIC (11) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:06:45.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading CDI (12) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:07:07.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading SELIC_Anual (1178) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:07:29.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading SELIC_Meta_Anual (432) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:07:59.203\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_request_bcb_series\u001b[0m:\u001b[36m118\u001b[0m - \u001b[33m\u001b[1mErro ao conectar à API do BCB: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "\u001b[32m2025-06-28 07:07:59.203\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_single_ticker\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mNo data returned for SELIC_Meta_Anual (432)\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:01.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading IPCA_Mensal (433) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:03.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading IGP_M_Mensal (189) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:06.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading INCC_Mensal (192) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:09.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Indice_Condicoes_Econ_BR (27574) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:11.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Indice_Condicoes_Econ_BR_USD (29042) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:14.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Salario_Minimo (1619) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:17.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading IBC_BR (24363) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:19.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Populacao_BR (21774) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:22.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading PIB_Trimestral_Real (4380) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:24.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading PIB_Anual_Corrente (7326) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:27.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Deflator_Implicito_PIB (1211) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:29.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mDownloading BRL_USD (DEXBZUS) from DataReader...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:32.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mDownloading CPI_USA (CPIAUCSL) from DataReader...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_BOVESPA dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_BOVESPA.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_S&P500 dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_S&P500.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_BITCOIN dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_BITCOIN.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_OURO dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_OURO.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_PETROLEO dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_PETROLEO.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_ACUCAR dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_ACUCAR.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_SELIC dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_SELIC.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_CDI dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_CDI.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_SELIC_Anual dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_SELIC_Anual.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_IPCA_Mensal dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_IPCA_Mensal.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_IGP_M_Mensal dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_IGP_M_Mensal.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_INCC_Mensal dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_INCC_Mensal.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Indice_Condicoes_Econ_BR dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_Indice_Condicoes_Econ_BR.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Indice_Condicoes_Econ_BR_USD dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_Indice_Condicoes_Econ_BR_USD.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Salario_Minimo dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_Salario_Minimo.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_IBC_BR dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_IBC_BR.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Populacao_BR dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_Populacao_BR.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_PIB_Trimestral_Real dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_PIB_Trimestral_Real.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_PIB_Anual_Corrente dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_PIB_Anual_Corrente.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Deflator_Implicito_PIB dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_Deflator_Implicito_PIB.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved DataReader_BRL_USD dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\DataReader_BRL_USD.csv\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:35.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved DataReader_CPI_USA dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\DataReader_CPI_USA.csv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.dataset.clean_strategy:Executing CleanMissingValues...\n",
      "INFO:src.utils.dataset.clean_strategy:Executing CleanLowVariance with threshold=0.01...\n",
      "INFO:src.utils.dataset.clean_strategy:Columns removed due to low variance: Index([], dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close_^BVSP  High_^BVSP  Low_^BVSP  Open_^BVSP  Volume_^BVSP  \\\n",
      "2025-06-21          NaN         NaN        NaN         NaN           NaN   \n",
      "2025-06-22          NaN         NaN        NaN         NaN           NaN   \n",
      "2025-06-23     136551.0    137130.0   135835.0    137116.0     7727800.0   \n",
      "2025-06-24     137165.0    138156.0   136254.0    136552.0     8083700.0   \n",
      "2025-06-25     135767.0    137163.0   135565.0    137163.0     7705700.0   \n",
      "2025-06-26     137114.0    137353.0   135756.0    135767.0     8023300.0   \n",
      "2025-06-27     136866.0    137209.0   136469.0    137113.0     6244500.0   \n",
      "\n",
      "            Close_^GSPC   High_^GSPC    Low_^GSPC   Open_^GSPC  Volume_^GSPC  \\\n",
      "2025-06-21          NaN          NaN          NaN          NaN           NaN   \n",
      "2025-06-22          NaN          NaN          NaN          NaN           NaN   \n",
      "2025-06-23  6025.169922  6028.770020  5943.229980  5969.669922  5.597000e+09   \n",
      "2025-06-24  6092.180176  6101.759766  6059.250000  6061.209961  5.443690e+09   \n",
      "2025-06-25  6092.160156  6108.509766  6080.089844  6104.229980  5.171110e+09   \n",
      "2025-06-26  6141.020020  6146.520020  6107.270020  6112.089844  5.308140e+09   \n",
      "2025-06-27  6173.069824  6187.680176  6132.350098  6150.700195  7.889350e+09   \n",
      "\n",
      "            ...  Indice_Condicoes_Econ_BR  Indice_Condicoes_Econ_BR_USD  \\\n",
      "2025-06-21  ...                       NaN                           NaN   \n",
      "2025-06-22  ...                       NaN                           NaN   \n",
      "2025-06-23  ...                       NaN                           NaN   \n",
      "2025-06-24  ...                       NaN                           NaN   \n",
      "2025-06-25  ...                       NaN                           NaN   \n",
      "2025-06-26  ...                       NaN                           NaN   \n",
      "2025-06-27  ...                       NaN                           NaN   \n",
      "\n",
      "            Salario_Minimo  IBC_BR  Populacao_BR  PIB_Trimestral_Real  \\\n",
      "2025-06-21             NaN     NaN           NaN                  NaN   \n",
      "2025-06-22             NaN     NaN           NaN                  NaN   \n",
      "2025-06-23             NaN     NaN           NaN                  NaN   \n",
      "2025-06-24             NaN     NaN           NaN                  NaN   \n",
      "2025-06-25             NaN     NaN           NaN                  NaN   \n",
      "2025-06-26             NaN     NaN           NaN                  NaN   \n",
      "2025-06-27             NaN     NaN           NaN                  NaN   \n",
      "\n",
      "            PIB_Anual_Corrente  Deflator_Implicito_PIB  DEXBZUS  CPIAUCSL  \n",
      "2025-06-21                 NaN                     NaN      NaN       NaN  \n",
      "2025-06-22                 NaN                     NaN      NaN       NaN  \n",
      "2025-06-23                 NaN                     NaN      NaN       NaN  \n",
      "2025-06-24                 NaN                     NaN      NaN       NaN  \n",
      "2025-06-25                 NaN                     NaN      NaN       NaN  \n",
      "2025-06-26                 NaN                     NaN      NaN       NaN  \n",
      "2025-06-27                 NaN                     NaN      NaN       NaN  \n",
      "\n",
      "[7 rows x 46 columns]\n",
      "\u001b[32m2025-06-28 07:08:35.824\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m69\u001b[0m - \u001b[32m\u001b[1mRaw data successfully loaded...\u001b[0m\n",
      "            Close_^BVSP  High_^BVSP  Low_^BVSP  Open_^BVSP  Volume_^BVSP  \\\n",
      "2025-06-18    -0.000886   -0.002409   0.001085   -0.002959     -0.006398   \n",
      "2025-06-20    -0.011541   -0.003176  -0.011759   -0.000929      0.356333   \n",
      "2025-06-23    -0.004121   -0.011455  -0.007163   -0.011527     -0.315476   \n",
      "2025-06-24     0.004496    0.007482   0.003085   -0.004113      0.046055   \n",
      "2025-06-25    -0.010192   -0.007188  -0.005057    0.004474     -0.046761   \n",
      "2025-06-26     0.009921    0.001385   0.001409   -0.010178      0.041216   \n",
      "2025-06-27    -0.001809   -0.001048   0.005252    0.009914     -0.221704   \n",
      "\n",
      "            Close_^GSPC  High_^GSPC  Low_^GSPC  Open_^GSPC  Volume_^GSPC  ...  \\\n",
      "2025-06-18    -0.000309   -0.000830  -0.000487   -0.004028      0.030424  ...   \n",
      "2025-06-20    -0.002179   -0.000008  -0.003237    0.001961      0.459227  ...   \n",
      "2025-06-23     0.009607    0.001756  -0.001567   -0.005000     -0.248876  ...   \n",
      "2025-06-24     0.011122    0.012107   0.019521    0.015334     -0.027391  ...   \n",
      "2025-06-25    -0.000003    0.001106   0.003439    0.007098     -0.050073  ...   \n",
      "2025-06-26     0.008020    0.006223   0.004470    0.001288      0.026499  ...   \n",
      "2025-06-27     0.005219    0.006696   0.004107    0.006317      0.486274  ...   \n",
      "\n",
      "            Indice_Condicoes_Econ_BR  Indice_Condicoes_Econ_BR_USD  \\\n",
      "2025-06-18                       0.0                           0.0   \n",
      "2025-06-20                       0.0                           0.0   \n",
      "2025-06-23                       0.0                           0.0   \n",
      "2025-06-24                       0.0                           0.0   \n",
      "2025-06-25                       0.0                           0.0   \n",
      "2025-06-26                       0.0                           0.0   \n",
      "2025-06-27                       0.0                           0.0   \n",
      "\n",
      "            Salario_Minimo  IBC_BR  Populacao_BR  PIB_Trimestral_Real  \\\n",
      "2025-06-18             0.0     0.0           0.0                  0.0   \n",
      "2025-06-20             0.0     0.0           0.0                  0.0   \n",
      "2025-06-23             0.0     0.0           0.0                  0.0   \n",
      "2025-06-24             0.0     0.0           0.0                  0.0   \n",
      "2025-06-25             0.0     0.0           0.0                  0.0   \n",
      "2025-06-26             0.0     0.0           0.0                  0.0   \n",
      "2025-06-27             0.0     0.0           0.0                  0.0   \n",
      "\n",
      "            PIB_Anual_Corrente  Deflator_Implicito_PIB   DEXBZUS  CPIAUCSL  \n",
      "2025-06-18                 0.0                     0.0  0.002720       0.0  \n",
      "2025-06-20                 0.0                     0.0  0.002076       0.0  \n",
      "2025-06-23                 0.0                     0.0  0.000000       0.0  \n",
      "2025-06-24                 0.0                     0.0  0.000000       0.0  \n",
      "2025-06-25                 0.0                     0.0  0.000000       0.0  \n",
      "2025-06-26                 0.0                     0.0  0.000000       0.0  \n",
      "2025-06-27                 0.0                     0.0  0.000000       0.0  \n",
      "\n",
      "[7 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repositories\\ds-lstm-ibov\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Repositories\\ds-lstm-ibov\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n",
      "INFO:src.utils.dataset.clean_strategy:Columns removed by f_classif: ['Volume_^GSPC']\n",
      "c:\\Repositories\\ds-lstm-ibov\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "INFO:src.utils.dataset.clean_strategy:Columns removed by f_regression: ['IGP_M_Mensal']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close_^BVSP  Volume_^GSPC  Volume_BTC-USD  Volume_GC=F  \\\n",
      "2025-06-16     0.014889     -0.027991       -0.275826    -0.038076   \n",
      "2025-06-17    -0.002987     -0.030520        0.111134     2.077083   \n",
      "2025-06-18    -0.000886      0.030424       -0.154492    -1.000000   \n",
      "2025-06-20    -0.011541      0.459227        0.076795     0.000000   \n",
      "2025-06-23    -0.004121     -0.248876        0.280380    -0.957687   \n",
      "2025-06-24     0.004496     -0.027391       -0.251615    16.933333   \n",
      "2025-06-25    -0.010192     -0.027391        0.057373     0.000000   \n",
      "\n",
      "            Volume_CL=F  Volume_SB=F  IPCA_Mensal  IGP_M_Mensal month_name  \\\n",
      "2025-06-16    -0.486745     0.504464          0.0           0.0       June   \n",
      "2025-06-17    -0.580019    -0.489217          0.0           0.0       June   \n",
      "2025-06-18    -1.000000    -1.000000          0.0           0.0       June   \n",
      "2025-06-20     0.000000     0.000000          0.0           0.0       June   \n",
      "2025-06-23     0.074429     0.622250          0.0           0.0       June   \n",
      "2025-06-24    -0.257101     0.033832          0.0           0.0       June   \n",
      "2025-06-25     0.000000     0.000000          0.0           0.0       June   \n",
      "\n",
      "            week_of_month day_of_week  is_weekend  is_holiday  Volume_^BVSP  \\\n",
      "2025-06-16              4      Monday           0           0     -0.116802   \n",
      "2025-06-17              4     Tuesday           0           0      0.099272   \n",
      "2025-06-18              4   Wednesday           0           0     -0.006398   \n",
      "2025-06-20              4      Friday           0           0      0.356333   \n",
      "2025-06-23              5      Monday           0           0     -0.315476   \n",
      "2025-06-24              5     Tuesday           0           0      0.046055   \n",
      "2025-06-25              5   Wednesday           0           0     -0.046761   \n",
      "\n",
      "            INCC_Mensal  \n",
      "2025-06-16          0.0  \n",
      "2025-06-17          0.0  \n",
      "2025-06-18          0.0  \n",
      "2025-06-20          0.0  \n",
      "2025-06-23          0.0  \n",
      "2025-06-24          0.0  \n",
      "2025-06-25          0.0  \n",
      "            Close_^BVSP  Volume_^GSPC  Volume_BTC-USD  Volume_GC=F  \\\n",
      "2025-06-18    -0.000886      0.030424       -0.154492    -1.000000   \n",
      "2025-06-20    -0.011541      0.459227        0.076795     0.000000   \n",
      "2025-06-23    -0.004121     -0.248876        0.280380    -0.957687   \n",
      "2025-06-24     0.004496     -0.027391       -0.251615    16.933333   \n",
      "2025-06-25    -0.010192     -0.027391        0.057373    -0.306691   \n",
      "2025-06-26     0.009921     -0.027391       -0.149777     4.517426   \n",
      "2025-06-27    -0.001809     -0.027391        0.033302     0.000000   \n",
      "\n",
      "            Volume_CL=F  Volume_SB=F  IPCA_Mensal  IGP_M_Mensal month_name  \\\n",
      "2025-06-18    -1.000000    -1.000000          0.0           0.0       June   \n",
      "2025-06-20     0.000000     0.000000          0.0           0.0       June   \n",
      "2025-06-23     0.074429     0.622250          0.0           0.0       June   \n",
      "2025-06-24    -0.257101     0.033832          0.0           0.0       June   \n",
      "2025-06-25    -0.485657    -0.048779          0.0           0.0       June   \n",
      "2025-06-26    -0.160619    -0.267251          0.0           0.0       June   \n",
      "2025-06-27     0.000000     0.000000          0.0           0.0       June   \n",
      "\n",
      "            week_of_month day_of_week  is_weekend  is_holiday  Volume_^BVSP  \\\n",
      "2025-06-18              4   Wednesday           0           0     -0.006398   \n",
      "2025-06-20              4      Friday           0           0      0.356333   \n",
      "2025-06-23              5      Monday           0           0     -0.315476   \n",
      "2025-06-24              5     Tuesday           0           0      0.046055   \n",
      "2025-06-25              5   Wednesday           0           0     -0.046761   \n",
      "2025-06-26              5    Thursday           0           0      0.041216   \n",
      "2025-06-27              5      Friday           0           0     -0.221704   \n",
      "\n",
      "            INCC_Mensal  \n",
      "2025-06-18          0.0  \n",
      "2025-06-20          0.0  \n",
      "2025-06-23          0.0  \n",
      "2025-06-24          0.0  \n",
      "2025-06-25          0.0  \n",
      "2025-06-26          0.0  \n",
      "2025-06-27          0.0  \n",
      "\u001b[32m2025-06-28 07:08:38.473\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m109\u001b[0m - \u001b[32m\u001b[1mClean data successfully loaded...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:08:38.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mTotal time taken: 155.94 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import dataset\n",
    "\n",
    "dataset.main(\n",
    "    # ---- REPLACE DEFAULT AS APPROPRIATE ----\n",
    "    asset = '^BVSP',\n",
    "    asset_focus = 'Close',\n",
    "    years = 10\n",
    "    # -----------------------------------------\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fce4b8",
   "metadata": {},
   "source": [
    "## Feature Engineering — Time Series Preparation\n",
    "\n",
    "This part of the pipeline is responsible for transforming the cleaned dataset into structured features suitable for training time series models. It includes the following key steps:\n",
    "- Feature Generation: Constructs relevant features based on historical market data.\n",
    "- Dataset Splitting: The dataset is split into training and testing sets using a consistent strategy to preserve temporal structure.\n",
    "- Time Series Windowing: Converts the sequential data into overlapping windows, enabling the model to learn temporal dependencies.\n",
    "- Saving Artifacts: Both training and testing sets are stored for reproducibility, along with the transformation pipelines applied during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64946194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:09:09.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mGenerating features from dataset...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:09.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.splitter_strategy\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mSplitting dataset into training and testing sets...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:09.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.generator_strategy\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mGenerating Timeseries from dataset...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:09.662\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m51\u001b[0m - \u001b[32m\u001b[1mSaving train features in C:\\Repositories\\ds-lstm-ibov\\data\\processed...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:09.779\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m55\u001b[0m - \u001b[32m\u001b[1mSaving test features in C:\\Repositories\\ds-lstm-ibov\\data\\processed...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:09.779\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m59\u001b[0m - \u001b[32m\u001b[1mFeatures generation complete.\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:09.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mSaving transformers...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:09.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.splitter_strategy\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mSplitting dataset into training and testing sets...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:09.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mTotal time taken: 0.25 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "from src import features\n",
    "\n",
    "features.main(\n",
    "    # ---- REPLACE DEFAULT PATHS AS APPROPRIATE ----\n",
    "    dataset_path = config.PROCESSED_DATA_DIR / \"dataset.csv\",\n",
    "    train_dir = config.PROCESSED_DATA_DIR,\n",
    "    test_dir = config.PROCESSED_DATA_DIR,\n",
    "    targets = [\"^BVSP\"],\n",
    "    train_size_ratio = 1,\n",
    "    batch_size = 1,\n",
    "    sequence_length = 50\n",
    "    # -----------------------------------------\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66434c",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "The modeling process begins with loading the training dataset. Next, the base model is constructed, and both the compilation and training strategies are defined. With the pipeline structure in place, the model is trained over 100 epochs using an iterative approach to adjust the weights.\n",
    "\n",
    "During training, key metrics are monitored, including accuracy, loss (error), validation accuracy and loss (on unseen data), as well as the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff11608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:09:17.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mLoading training dataset...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:17.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mSelecting builder strategy...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:17.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mSelecting compile strategy...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:17.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mSelecting training strategy...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:17.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mBuilding model training pipeline template...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:09:17.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mTraining model...\u001b[0m\n",
      "Epoch 1/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 140ms/step - loss: 0.4984 - mae: 0.8181 - mse: 19.8600 - r2_score: -0.0250 - rmse: 1.7104 - smape: 171.0782 - val_loss: 0.2841 - val_mae: 0.5644 - val_mse: 0.6483 - val_r2_score: -0.0049 - val_rmse: 0.8052 - val_smape: 180.8404 - learning_rate: 0.0010\n",
      "Epoch 2/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.4908 - mae: 0.8087 - mse: 19.8376 - r2_score: -0.0015 - rmse: 1.6983 - smape: 177.8193 - val_loss: 0.2806 - val_mae: 0.5615 - val_mse: 0.6442 - val_r2_score: 0.0015 - val_rmse: 0.8026 - val_smape: 182.1920 - learning_rate: 0.0010\n",
      "Epoch 3/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.4895 - mae: 0.8100 - mse: 19.8393 - r2_score: -0.0054 - rmse: 1.7002 - smape: 179.0421 - val_loss: 0.2789 - val_mae: 0.5608 - val_mse: 0.6412 - val_r2_score: 0.0062 - val_rmse: 0.8007 - val_smape: 183.5083 - learning_rate: 0.0010\n",
      "Epoch 4/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.4854 - mae: 0.8056 - mse: 19.8296 - r2_score: 0.0039 - rmse: 1.6954 - smape: 178.1768 - val_loss: 0.2746 - val_mae: 0.5583 - val_mse: 0.6301 - val_r2_score: 0.0233 - val_rmse: 0.7938 - val_smape: 180.3026 - learning_rate: 0.0010\n",
      "Epoch 5/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - loss: 0.4800 - mae: 0.7987 - mse: 19.7873 - r2_score: 0.0154 - rmse: 1.6894 - smape: 168.9980 - val_loss: 0.2674 - val_mae: 0.5462 - val_mse: 0.5981 - val_r2_score: 0.0730 - val_rmse: 0.7734 - val_smape: 164.3609 - learning_rate: 0.0010\n",
      "Epoch 6/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 0.4750 - mae: 0.7953 - mse: 19.7569 - r2_score: 0.0318 - rmse: 1.6800 - smape: 161.5225 - val_loss: 0.2583 - val_mae: 0.5347 - val_mse: 0.5729 - val_r2_score: 0.1120 - val_rmse: 0.7569 - val_smape: 148.7660 - learning_rate: 0.0010\n",
      "Epoch 7/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.4626 - mae: 0.7798 - mse: 19.7411 - r2_score: 0.0620 - rmse: 1.6622 - smape: 152.5615 - val_loss: 0.2520 - val_mae: 0.5233 - val_mse: 0.5621 - val_r2_score: 0.1288 - val_rmse: 0.7497 - val_smape: 149.3328 - learning_rate: 0.0010\n",
      "Epoch 8/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - loss: 0.4609 - mae: 0.7802 - mse: 19.7196 - r2_score: 0.0698 - rmse: 1.6589 - smape: 154.0977 - val_loss: 0.2481 - val_mae: 0.5171 - val_mse: 0.5467 - val_r2_score: 0.1527 - val_rmse: 0.7394 - val_smape: 145.7567 - learning_rate: 0.0010\n",
      "Epoch 9/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 353ms/step - loss: 0.4495 - mae: 0.7649 - mse: 19.7103 - r2_score: 0.0938 - rmse: 1.6461 - smape: 147.3042 - val_loss: 0.2425 - val_mae: 0.5097 - val_mse: 0.5360 - val_r2_score: 0.1692 - val_rmse: 0.7321 - val_smape: 146.4409 - learning_rate: 0.0010\n",
      "Epoch 10/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 185ms/step - loss: 0.4497 - mae: 0.7652 - mse: 19.6702 - r2_score: 0.0897 - rmse: 1.6469 - smape: 149.0620 - val_loss: 0.2487 - val_mae: 0.5263 - val_mse: 0.5367 - val_r2_score: 0.1681 - val_rmse: 0.7326 - val_smape: 146.3676 - learning_rate: 0.0010\n",
      "Epoch 11/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - loss: 0.4442 - mae: 0.7607 - mse: 19.6645 - r2_score: 0.1071 - rmse: 1.6376 - smape: 148.6913 - val_loss: 0.2357 - val_mae: 0.5057 - val_mse: 0.5100 - val_r2_score: 0.2095 - val_rmse: 0.7141 - val_smape: 145.0437 - learning_rate: 0.0010\n",
      "Epoch 12/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.4402 - mae: 0.7534 - mse: 19.6171 - r2_score: 0.1266 - rmse: 1.6244 - smape: 146.1789 - val_loss: 0.2452 - val_mae: 0.5210 - val_mse: 0.5255 - val_r2_score: 0.1855 - val_rmse: 0.7249 - val_smape: 148.2629 - learning_rate: 0.0010\n",
      "Epoch 13/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 122ms/step - loss: 0.4378 - mae: 0.7530 - mse: 19.6051 - r2_score: 0.1334 - rmse: 1.6216 - smape: 147.5665 - val_loss: 0.2440 - val_mae: 0.5103 - val_mse: 0.5327 - val_r2_score: 0.1743 - val_rmse: 0.7299 - val_smape: 138.2216 - learning_rate: 0.0010\n",
      "Epoch 14/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - loss: 0.4302 - mae: 0.7404 - mse: 19.6534 - r2_score: 0.1382 - rmse: 1.6201 - smape: 141.9754 - val_loss: 0.2463 - val_mae: 0.5168 - val_mse: 0.5286 - val_r2_score: 0.1807 - val_rmse: 0.7271 - val_smape: 140.7104 - learning_rate: 0.0010\n",
      "Epoch 15/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - loss: 0.4266 - mae: 0.7359 - mse: 19.6129 - r2_score: 0.1459 - rmse: 1.6138 - smape: 142.5796 - val_loss: 0.2407 - val_mae: 0.5226 - val_mse: 0.5046 - val_r2_score: 0.2178 - val_rmse: 0.7104 - val_smape: 146.5557 - learning_rate: 0.0010\n",
      "Epoch 16/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - loss: 0.4198 - mae: 0.7268 - mse: 19.5566 - r2_score: 0.1816 - rmse: 1.5933 - smape: 139.7870 - val_loss: 0.2335 - val_mae: 0.5055 - val_mse: 0.4904 - val_r2_score: 0.2399 - val_rmse: 0.7003 - val_smape: 141.6049 - learning_rate: 0.0010\n",
      "Epoch 17/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.4241 - mae: 0.7342 - mse: 19.5964 - r2_score: 0.1738 - rmse: 1.5989 - smape: 142.9161 - val_loss: 0.2354 - val_mae: 0.5064 - val_mse: 0.4948 - val_r2_score: 0.2331 - val_rmse: 0.7034 - val_smape: 138.7419 - learning_rate: 0.0010\n",
      "Epoch 18/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - loss: 0.4160 - mae: 0.7199 - mse: 19.5972 - r2_score: 0.1750 - rmse: 1.5976 - smape: 136.7081 - val_loss: 0.2306 - val_mae: 0.5036 - val_mse: 0.4790 - val_r2_score: 0.2576 - val_rmse: 0.6921 - val_smape: 141.9606 - learning_rate: 0.0010\n",
      "Epoch 19/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 0.4056 - mae: 0.7091 - mse: 19.5220 - r2_score: 0.2134 - rmse: 1.5713 - smape: 137.2771 - val_loss: 0.2276 - val_mae: 0.4965 - val_mse: 0.4691 - val_r2_score: 0.2729 - val_rmse: 0.6849 - val_smape: 137.8155 - learning_rate: 0.0010\n",
      "Epoch 20/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - loss: 0.4095 - mae: 0.7180 - mse: 19.5654 - r2_score: 0.2048 - rmse: 1.5802 - smape: 138.7227 - val_loss: 0.2401 - val_mae: 0.5161 - val_mse: 0.5035 - val_r2_score: 0.2197 - val_rmse: 0.7096 - val_smape: 139.6840 - learning_rate: 0.0010\n",
      "Epoch 21/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 0.4079 - mae: 0.7155 - mse: 19.5631 - r2_score: 0.2016 - rmse: 1.5813 - smape: 138.6258 - val_loss: 0.2317 - val_mae: 0.5093 - val_mse: 0.4817 - val_r2_score: 0.2534 - val_rmse: 0.6940 - val_smape: 138.2045 - learning_rate: 0.0010\n",
      "Epoch 22/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - loss: 0.3919 - mae: 0.6895 - mse: 19.4814 - r2_score: 0.2512 - rmse: 1.5497 - smape: 131.9706 - val_loss: 0.2368 - val_mae: 0.5161 - val_mse: 0.4913 - val_r2_score: 0.2385 - val_rmse: 0.7009 - val_smape: 141.0914 - learning_rate: 0.0010\n",
      "Epoch 23/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.4013 - mae: 0.7013 - mse: 19.4625 - r2_score: 0.2203 - rmse: 1.5666 - smape: 133.1217 - val_loss: 0.2416 - val_mae: 0.5161 - val_mse: 0.5148 - val_r2_score: 0.2021 - val_rmse: 0.7175 - val_smape: 140.5552 - learning_rate: 0.0010\n",
      "Epoch 24/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - loss: 0.3977 - mae: 0.7024 - mse: 19.4395 - r2_score: 0.2428 - rmse: 1.5518 - smape: 135.3020 - val_loss: 0.2321 - val_mae: 0.5014 - val_mse: 0.4771 - val_r2_score: 0.2606 - val_rmse: 0.6907 - val_smape: 133.0424 - learning_rate: 0.0010\n",
      "Epoch 25/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.3962 - mae: 0.6941 - mse: 19.4091 - r2_score: 0.2349 - rmse: 1.5567 - smape: 132.1517 - val_loss: 0.2348 - val_mae: 0.5132 - val_mse: 0.4863 - val_r2_score: 0.2463 - val_rmse: 0.6974 - val_smape: 138.8142 - learning_rate: 0.0010\n",
      "Epoch 26/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.3939 - mae: 0.6938 - mse: 19.4252 - r2_score: 0.2565 - rmse: 1.5473 - smape: 130.4286 - val_loss: 0.2413 - val_mae: 0.5202 - val_mse: 0.5144 - val_r2_score: 0.2028 - val_rmse: 0.7172 - val_smape: 135.4239 - learning_rate: 0.0010\n",
      "Epoch 27/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.3877 - mae: 0.6881 - mse: 19.4006 - r2_score: 0.2553 - rmse: 1.5432 - smape: 129.3459 - val_loss: 0.2438 - val_mae: 0.5302 - val_mse: 0.5171 - val_r2_score: 0.1986 - val_rmse: 0.7191 - val_smape: 140.2893 - learning_rate: 0.0010\n",
      "Epoch 28/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.3849 - mae: 0.6836 - mse: 19.3849 - r2_score: 0.2646 - rmse: 1.5410 - smape: 129.4960 - val_loss: 0.2525 - val_mae: 0.5446 - val_mse: 0.5308 - val_r2_score: 0.1774 - val_rmse: 0.7285 - val_smape: 140.5834 - learning_rate: 0.0010\n",
      "Epoch 29/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.3787 - mae: 0.6724 - mse: 19.4228 - r2_score: 0.2734 - rmse: 1.5331 - smape: 125.2507 - val_loss: 0.2548 - val_mae: 0.5388 - val_mse: 0.5387 - val_r2_score: 0.1650 - val_rmse: 0.7340 - val_smape: 138.9937 - learning_rate: 0.0010\n",
      "Epoch 30/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 0.3769 - mae: 0.6691 - mse: 19.2436 - r2_score: 0.2831 - rmse: 1.5232 - smape: 125.1552 - val_loss: 0.2486 - val_mae: 0.5283 - val_mse: 0.5201 - val_r2_score: 0.1940 - val_rmse: 0.7212 - val_smape: 134.5839 - learning_rate: 0.0010\n",
      "Epoch 31/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - loss: 0.3660 - mae: 0.6588 - mse: 19.2819 - r2_score: 0.3153 - rmse: 1.5004 - smape: 123.8305 - val_loss: 0.2638 - val_mae: 0.5446 - val_mse: 0.5674 - val_r2_score: 0.1206 - val_rmse: 0.7533 - val_smape: 133.6626 - learning_rate: 0.0010\n",
      "Epoch 32/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.3744 - mae: 0.6681 - mse: 19.3094 - r2_score: 0.3031 - rmse: 1.5090 - smape: 123.3734 - val_loss: 0.2685 - val_mae: 0.5502 - val_mse: 0.5744 - val_r2_score: 0.1097 - val_rmse: 0.7579 - val_smape: 132.0985 - learning_rate: 0.0010\n",
      "Epoch 33/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.3667 - mae: 0.6588 - mse: 19.2356 - r2_score: 0.3281 - rmse: 1.4916 - smape: 121.9693 - val_loss: 0.2508 - val_mae: 0.5329 - val_mse: 0.5409 - val_r2_score: 0.1616 - val_rmse: 0.7355 - val_smape: 135.9189 - learning_rate: 0.0010\n",
      "Epoch 34/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - loss: 0.3626 - mae: 0.6511 - mse: 19.1830 - r2_score: 0.3309 - rmse: 1.4874 - smape: 119.5083 - val_loss: 0.2604 - val_mae: 0.5432 - val_mse: 0.5620 - val_r2_score: 0.1290 - val_rmse: 0.7497 - val_smape: 136.4244 - learning_rate: 0.0010\n",
      "Epoch 35/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - loss: 0.3608 - mae: 0.6500 - mse: 19.0672 - r2_score: 0.3356 - rmse: 1.4866 - smape: 120.2860 - val_loss: 0.2539 - val_mae: 0.5317 - val_mse: 0.5453 - val_r2_score: 0.1548 - val_rmse: 0.7385 - val_smape: 128.7645 - learning_rate: 0.0010\n",
      "Epoch 36/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - loss: 0.3561 - mae: 0.6456 - mse: 19.2108 - r2_score: 0.3302 - rmse: 1.4900 - smape: 118.9163 - val_loss: 0.2556 - val_mae: 0.5379 - val_mse: 0.5466 - val_r2_score: 0.1527 - val_rmse: 0.7394 - val_smape: 130.0785 - learning_rate: 5.0000e-04\n",
      "Epoch 37/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - loss: 0.3525 - mae: 0.6374 - mse: 19.1311 - r2_score: 0.3509 - rmse: 1.4769 - smape: 116.7425 - val_loss: 0.2592 - val_mae: 0.5483 - val_mse: 0.5616 - val_r2_score: 0.1296 - val_rmse: 0.7494 - val_smape: 133.0930 - learning_rate: 5.0000e-04\n",
      "Epoch 38/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.3584 - mae: 0.6472 - mse: 19.2675 - r2_score: 0.3344 - rmse: 1.4895 - smape: 120.1340 - val_loss: 0.2547 - val_mae: 0.5392 - val_mse: 0.5465 - val_r2_score: 0.1530 - val_rmse: 0.7392 - val_smape: 132.4984 - learning_rate: 5.0000e-04\n",
      "Epoch 39/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 0.3503 - mae: 0.6385 - mse: 19.1452 - r2_score: 0.3510 - rmse: 1.4778 - smape: 117.2448 - val_loss: 0.2535 - val_mae: 0.5426 - val_mse: 0.5411 - val_r2_score: 0.1613 - val_rmse: 0.7356 - val_smape: 133.9343 - learning_rate: 5.0000e-04\n",
      "Epoch 40/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.3467 - mae: 0.6331 - mse: 19.0797 - r2_score: 0.3644 - rmse: 1.4655 - smape: 115.0148 - val_loss: 0.2572 - val_mae: 0.5449 - val_mse: 0.5482 - val_r2_score: 0.1503 - val_rmse: 0.7404 - val_smape: 131.3078 - learning_rate: 5.0000e-04\n",
      "Epoch 41/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - loss: 0.3374 - mae: 0.6214 - mse: 19.1197 - r2_score: 0.3917 - rmse: 1.4449 - smape: 113.8577 - val_loss: 0.2570 - val_mae: 0.5397 - val_mse: 0.5545 - val_r2_score: 0.1406 - val_rmse: 0.7446 - val_smape: 129.9613 - learning_rate: 5.0000e-04\n",
      "Epoch 42/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.3436 - mae: 0.6329 - mse: 19.0950 - r2_score: 0.3746 - rmse: 1.4619 - smape: 116.4932 - val_loss: 0.2611 - val_mae: 0.5544 - val_mse: 0.5622 - val_r2_score: 0.1287 - val_rmse: 0.7498 - val_smape: 133.5129 - learning_rate: 5.0000e-04\n",
      "Epoch 43/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 0.3405 - mae: 0.6245 - mse: 19.0584 - r2_score: 0.3925 - rmse: 1.4441 - smape: 114.9596 - val_loss: 0.2569 - val_mae: 0.5383 - val_mse: 0.5563 - val_r2_score: 0.1377 - val_rmse: 0.7459 - val_smape: 131.0839 - learning_rate: 5.0000e-04\n",
      "Epoch 44/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.3353 - mae: 0.6189 - mse: 19.0724 - r2_score: 0.3975 - rmse: 1.4372 - smape: 113.8552 - val_loss: 0.2608 - val_mae: 0.5501 - val_mse: 0.5640 - val_r2_score: 0.1259 - val_rmse: 0.7510 - val_smape: 129.4936 - learning_rate: 5.0000e-04\n",
      "Epoch 45/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.3325 - mae: 0.6108 - mse: 19.1278 - r2_score: 0.3995 - rmse: 1.4382 - smape: 110.5522 - val_loss: 0.2631 - val_mae: 0.5505 - val_mse: 0.5670 - val_r2_score: 0.1212 - val_rmse: 0.7530 - val_smape: 132.5628 - learning_rate: 5.0000e-04\n",
      "Epoch 46/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.3324 - mae: 0.6142 - mse: 19.1373 - r2_score: 0.3953 - rmse: 1.4417 - smape: 113.0920 - val_loss: 0.2727 - val_mae: 0.5695 - val_mse: 0.5919 - val_r2_score: 0.0826 - val_rmse: 0.7694 - val_smape: 134.8002 - learning_rate: 5.0000e-04\n",
      "Epoch 47/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.3296 - mae: 0.6117 - mse: 19.0290 - r2_score: 0.4007 - rmse: 1.4375 - smape: 111.8593 - val_loss: 0.2710 - val_mae: 0.5651 - val_mse: 0.5887 - val_r2_score: 0.0876 - val_rmse: 0.7672 - val_smape: 132.2818 - learning_rate: 5.0000e-04\n",
      "Epoch 48/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 0.3327 - mae: 0.6142 - mse: 19.0786 - r2_score: 0.3946 - rmse: 1.4432 - smape: 111.0820 - val_loss: 0.2600 - val_mae: 0.5523 - val_mse: 0.5660 - val_r2_score: 0.1228 - val_rmse: 0.7523 - val_smape: 130.6123 - learning_rate: 5.0000e-04\n",
      "Epoch 49/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.3344 - mae: 0.6168 - mse: 19.0670 - r2_score: 0.4056 - rmse: 1.4387 - smape: 111.6577 - val_loss: 0.2703 - val_mae: 0.5683 - val_mse: 0.5854 - val_r2_score: 0.0927 - val_rmse: 0.7651 - val_smape: 132.3159 - learning_rate: 5.0000e-04\n",
      "Epoch 50/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - loss: 0.3286 - mae: 0.6060 - mse: 19.1046 - r2_score: 0.4180 - rmse: 1.4286 - smape: 109.4095 - val_loss: 0.2661 - val_mae: 0.5630 - val_mse: 0.5750 - val_r2_score: 0.1088 - val_rmse: 0.7583 - val_smape: 133.2539 - learning_rate: 5.0000e-04\n",
      "Epoch 51/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.3289 - mae: 0.6082 - mse: 19.1552 - r2_score: 0.4054 - rmse: 1.4403 - smape: 110.0243 - val_loss: 0.2658 - val_mae: 0.5637 - val_mse: 0.5692 - val_r2_score: 0.1178 - val_rmse: 0.7544 - val_smape: 132.7453 - learning_rate: 5.0000e-04\n",
      "Epoch 52/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - loss: 0.3241 - mae: 0.6044 - mse: 19.1178 - r2_score: 0.4231 - rmse: 1.4234 - smape: 110.6349 - val_loss: 0.2618 - val_mae: 0.5598 - val_mse: 0.5626 - val_r2_score: 0.1280 - val_rmse: 0.7501 - val_smape: 132.1228 - learning_rate: 2.5000e-04\n",
      "Epoch 53/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 121ms/step - loss: 0.3203 - mae: 0.5978 - mse: 18.9509 - r2_score: 0.4361 - rmse: 1.4088 - smape: 109.4992 - val_loss: 0.2638 - val_mae: 0.5641 - val_mse: 0.5696 - val_r2_score: 0.1172 - val_rmse: 0.7547 - val_smape: 132.5433 - learning_rate: 2.5000e-04\n",
      "Epoch 54/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.3227 - mae: 0.6020 - mse: 19.0440 - r2_score: 0.4242 - rmse: 1.4198 - smape: 110.8657 - val_loss: 0.2656 - val_mae: 0.5675 - val_mse: 0.5733 - val_r2_score: 0.1115 - val_rmse: 0.7571 - val_smape: 132.3203 - learning_rate: 2.5000e-04\n",
      "Epoch 55/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 179ms/step - loss: 0.3164 - mae: 0.5958 - mse: 19.0138 - r2_score: 0.4448 - rmse: 1.4025 - smape: 109.4608 - val_loss: 0.2635 - val_mae: 0.5594 - val_mse: 0.5727 - val_r2_score: 0.1123 - val_rmse: 0.7568 - val_smape: 131.6636 - learning_rate: 2.5000e-04\n",
      "Epoch 56/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - loss: 0.3217 - mae: 0.5999 - mse: 19.2053 - r2_score: 0.4300 - rmse: 1.4193 - smape: 110.3796 - val_loss: 0.2648 - val_mae: 0.5646 - val_mse: 0.5733 - val_r2_score: 0.1115 - val_rmse: 0.7571 - val_smape: 132.2750 - learning_rate: 2.5000e-04\n",
      "Epoch 57/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.3214 - mae: 0.6000 - mse: 18.9920 - r2_score: 0.4263 - rmse: 1.4191 - smape: 109.4044 - val_loss: 0.2690 - val_mae: 0.5755 - val_mse: 0.5808 - val_r2_score: 0.0998 - val_rmse: 0.7621 - val_smape: 133.4318 - learning_rate: 2.5000e-04\n",
      "Epoch 58/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 0.3233 - mae: 0.5988 - mse: 19.1317 - r2_score: 0.4200 - rmse: 1.4316 - smape: 108.5614 - val_loss: 0.2672 - val_mae: 0.5760 - val_mse: 0.5737 - val_r2_score: 0.1108 - val_rmse: 0.7574 - val_smape: 134.9079 - learning_rate: 2.5000e-04\n",
      "Epoch 59/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.3174 - mae: 0.5942 - mse: 18.8055 - r2_score: 0.4397 - rmse: 1.4063 - smape: 109.2747 - val_loss: 0.2702 - val_mae: 0.5815 - val_mse: 0.5809 - val_r2_score: 0.0997 - val_rmse: 0.7622 - val_smape: 133.9921 - learning_rate: 2.5000e-04\n",
      "Epoch 60/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - loss: 0.3186 - mae: 0.5937 - mse: 19.2151 - r2_score: 0.4310 - rmse: 1.4212 - smape: 106.9328 - val_loss: 0.2728 - val_mae: 0.5867 - val_mse: 0.5875 - val_r2_score: 0.0894 - val_rmse: 0.7665 - val_smape: 134.4850 - learning_rate: 2.5000e-04\n",
      "Epoch 61/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.3200 - mae: 0.5946 - mse: 19.0074 - r2_score: 0.4475 - rmse: 1.4018 - smape: 108.8887 - val_loss: 0.2715 - val_mae: 0.5834 - val_mse: 0.5844 - val_r2_score: 0.0943 - val_rmse: 0.7644 - val_smape: 135.3843 - learning_rate: 2.5000e-04\n",
      "Epoch 62/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - loss: 0.3083 - mae: 0.5813 - mse: 18.9805 - r2_score: 0.4642 - rmse: 1.3914 - smape: 106.8650 - val_loss: 0.2733 - val_mae: 0.5872 - val_mse: 0.5876 - val_r2_score: 0.0893 - val_rmse: 0.7665 - val_smape: 134.9342 - learning_rate: 2.5000e-04\n",
      "Epoch 63/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.3095 - mae: 0.5839 - mse: 18.9982 - r2_score: 0.4511 - rmse: 1.3978 - smape: 106.3491 - val_loss: 0.2693 - val_mae: 0.5780 - val_mse: 0.5845 - val_r2_score: 0.0940 - val_rmse: 0.7646 - val_smape: 133.4970 - learning_rate: 2.5000e-04\n",
      "Epoch 64/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - loss: 0.3181 - mae: 0.5915 - mse: 18.9042 - r2_score: 0.4384 - rmse: 1.4083 - smape: 106.7680 - val_loss: 0.2685 - val_mae: 0.5794 - val_mse: 0.5805 - val_r2_score: 0.1003 - val_rmse: 0.7619 - val_smape: 133.8324 - learning_rate: 2.5000e-04\n",
      "Epoch 65/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - loss: 0.3159 - mae: 0.5933 - mse: 18.9291 - r2_score: 0.4572 - rmse: 1.3901 - smape: 109.5137 - val_loss: 0.2729 - val_mae: 0.5857 - val_mse: 0.5927 - val_r2_score: 0.0814 - val_rmse: 0.7699 - val_smape: 134.7516 - learning_rate: 2.5000e-04\n",
      "Epoch 66/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.3129 - mae: 0.5915 - mse: 19.0218 - r2_score: 0.4513 - rmse: 1.4010 - smape: 107.3088 - val_loss: 0.2641 - val_mae: 0.5707 - val_mse: 0.5720 - val_r2_score: 0.1135 - val_rmse: 0.7563 - val_smape: 134.3373 - learning_rate: 2.5000e-04\n",
      "Epoch 67/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - loss: 0.3112 - mae: 0.5867 - mse: 18.8428 - r2_score: 0.4505 - rmse: 1.3996 - smape: 107.1678 - val_loss: 0.2707 - val_mae: 0.5806 - val_mse: 0.5866 - val_r2_score: 0.0908 - val_rmse: 0.7659 - val_smape: 135.2118 - learning_rate: 2.5000e-04\n",
      "Epoch 68/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.3111 - mae: 0.5850 - mse: 18.9685 - r2_score: 0.4485 - rmse: 1.4038 - smape: 106.0615 - val_loss: 0.2704 - val_mae: 0.5799 - val_mse: 0.5865 - val_r2_score: 0.0909 - val_rmse: 0.7659 - val_smape: 134.8420 - learning_rate: 1.2500e-04\n",
      "Epoch 69/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.3103 - mae: 0.5868 - mse: 18.9320 - r2_score: 0.4628 - rmse: 1.3895 - smape: 107.3797 - val_loss: 0.2757 - val_mae: 0.5915 - val_mse: 0.5959 - val_r2_score: 0.0764 - val_rmse: 0.7719 - val_smape: 134.6638 - learning_rate: 1.2500e-04\n",
      "Epoch 70/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - loss: 0.3079 - mae: 0.5826 - mse: 18.7881 - r2_score: 0.4671 - rmse: 1.3817 - smape: 107.0553 - val_loss: 0.2731 - val_mae: 0.5842 - val_mse: 0.5921 - val_r2_score: 0.0823 - val_rmse: 0.7695 - val_smape: 133.8235 - learning_rate: 1.2500e-04\n",
      "Epoch 71/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.3023 - mae: 0.5720 - mse: 18.8916 - r2_score: 0.4813 - rmse: 1.3726 - smape: 102.9621 - val_loss: 0.2731 - val_mae: 0.5848 - val_mse: 0.5923 - val_r2_score: 0.0820 - val_rmse: 0.7696 - val_smape: 134.6510 - learning_rate: 1.2500e-04\n",
      "Epoch 72/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.3076 - mae: 0.5845 - mse: 18.9604 - r2_score: 0.4705 - rmse: 1.3783 - smape: 106.3352 - val_loss: 0.2691 - val_mae: 0.5805 - val_mse: 0.5828 - val_r2_score: 0.0968 - val_rmse: 0.7634 - val_smape: 134.9271 - learning_rate: 1.2500e-04\n",
      "Epoch 73/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.3076 - mae: 0.5846 - mse: 18.8722 - r2_score: 0.4763 - rmse: 1.3794 - smape: 107.5153 - val_loss: 0.2678 - val_mae: 0.5782 - val_mse: 0.5813 - val_r2_score: 0.0991 - val_rmse: 0.7624 - val_smape: 134.5226 - learning_rate: 1.2500e-04\n",
      "Epoch 74/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.3028 - mae: 0.5735 - mse: 18.9561 - r2_score: 0.4760 - rmse: 1.3802 - smape: 104.8977 - val_loss: 0.2658 - val_mae: 0.5757 - val_mse: 0.5740 - val_r2_score: 0.1104 - val_rmse: 0.7576 - val_smape: 135.3102 - learning_rate: 1.2500e-04\n",
      "Epoch 75/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - loss: 0.3101 - mae: 0.5838 - mse: 18.9204 - r2_score: 0.4547 - rmse: 1.3962 - smape: 105.6765 - val_loss: 0.2650 - val_mae: 0.5729 - val_mse: 0.5730 - val_r2_score: 0.1119 - val_rmse: 0.7570 - val_smape: 135.3144 - learning_rate: 1.2500e-04\n",
      "Epoch 76/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 98ms/step - loss: 0.3100 - mae: 0.5862 - mse: 18.9096 - r2_score: 0.4603 - rmse: 1.3916 - smape: 107.8065 - val_loss: 0.2683 - val_mae: 0.5779 - val_mse: 0.5800 - val_r2_score: 0.1011 - val_rmse: 0.7616 - val_smape: 135.5848 - learning_rate: 1.2500e-04\n",
      "Epoch 77/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.3033 - mae: 0.5771 - mse: 18.8982 - r2_score: 0.4725 - rmse: 1.3810 - smape: 107.1280 - val_loss: 0.2705 - val_mae: 0.5801 - val_mse: 0.5875 - val_r2_score: 0.0894 - val_rmse: 0.7665 - val_smape: 135.0586 - learning_rate: 1.2500e-04\n",
      "Epoch 78/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.3050 - mae: 0.5792 - mse: 19.1335 - r2_score: 0.4802 - rmse: 1.3777 - smape: 106.3481 - val_loss: 0.2723 - val_mae: 0.5846 - val_mse: 0.5916 - val_r2_score: 0.0831 - val_rmse: 0.7691 - val_smape: 135.4048 - learning_rate: 1.2500e-04\n",
      "Epoch 79/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.3064 - mae: 0.5764 - mse: 19.0920 - r2_score: 0.4594 - rmse: 1.3931 - smape: 105.7588 - val_loss: 0.2724 - val_mae: 0.5857 - val_mse: 0.5897 - val_r2_score: 0.0860 - val_rmse: 0.7679 - val_smape: 135.4166 - learning_rate: 1.2500e-04\n",
      "Epoch 80/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - loss: 0.3011 - mae: 0.5727 - mse: 18.9615 - r2_score: 0.4860 - rmse: 1.3716 - smape: 105.2130 - val_loss: 0.2696 - val_mae: 0.5784 - val_mse: 0.5854 - val_r2_score: 0.0927 - val_rmse: 0.7651 - val_smape: 134.3709 - learning_rate: 1.2500e-04\n",
      "Epoch 81/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.3025 - mae: 0.5789 - mse: 18.9245 - r2_score: 0.4746 - rmse: 1.3799 - smape: 105.4989 - val_loss: 0.2710 - val_mae: 0.5820 - val_mse: 0.5876 - val_r2_score: 0.0893 - val_rmse: 0.7665 - val_smape: 135.2139 - learning_rate: 1.2500e-04\n",
      "Epoch 82/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 198ms/step - loss: 0.3004 - mae: 0.5721 - mse: 18.8000 - r2_score: 0.4759 - rmse: 1.3800 - smape: 104.6676 - val_loss: 0.2723 - val_mae: 0.5833 - val_mse: 0.5897 - val_r2_score: 0.0860 - val_rmse: 0.7679 - val_smape: 135.3813 - learning_rate: 1.2500e-04\n",
      "Epoch 83/256\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - loss: 0.3021 - mae: 0.5766 - mse: 18.8505 - r2_score: 0.4750 - rmse: 1.3832 - smape: 106.3912 - val_loss: 0.2762 - val_mae: 0.5898 - val_mse: 0.5984 - val_r2_score: 0.0725 - val_rmse: 0.7736 - val_smape: 135.9595 - learning_rate: 1.2500e-04\n",
      "\u001b[32m2025-06-28 07:16:38.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mSaving 'Sequential_epoch82_loss0.3165.keras' in 'C:\\Repositories\\ds-lstm-ibov\\models'...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:16:38.529\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m96\u001b[0m - \u001b[32m\u001b[1mModeling training complete.\u001b[0m\n",
      "\u001b[32m2025-06-28 07:16:38.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mElapsed time: 441.37 seconds\u001b[0m\n",
      "\u001b[32m2025-06-28 07:16:38.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mLogging experiment into mlflow.\u001b[0m\n",
      "\u001b[32m2025-06-28 07:16:38.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mStarting MLflow run 'Sequential' in experiment 'default_experiment'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/28 07:16:40 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:16:40.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mlog_environment\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mLogging environment details...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:16:40.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mLogging Keras model...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/28 07:17:01 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\SAMSUNG\\AppData\\Local\\Temp\\tmp6tjrs9mx\\model, flavor: keras). Fall back to return ['keras==3.9.2']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/06/28 07:17:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model '2025-amp-rnn' already exists. Creating a new version of this model...\n",
      "Created version '5' of model '2025-amp-rnn'.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:17:02.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mLogging final and aggregate metrics...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:17:07.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m141\u001b[0m - \u001b[1mLogging artifacts...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:17:07.745\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.utils.log.log_strategy\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m162\u001b[0m - \u001b[32m\u001b[1mMLflow logging complete.\u001b[0m\n",
      "\u001b[32m2025-06-28 07:17:07.749\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m116\u001b[0m - \u001b[32m\u001b[1mExperiment logged successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "from src.modeling import train\n",
    "\n",
    "train.main(\n",
    "    # ---- REPLACE DEFAULT PATHS AS APPROPRIATE ----\n",
    "    X_path = config.PROCESSED_DATA_DIR / \"X_train.npy\",\n",
    "    y_path = config.PROCESSED_DATA_DIR / \"y_train.npy\",\n",
    "    # -----------------------------------------\n",
    "    optimizer =  None,  # Use default optimizer\n",
    "    loss = None,  # Use default loss\n",
    "    metrics = None,  # Use default metrics\n",
    "    # -----------------------------------------\n",
    "    epochs = 2**8,    \n",
    "    validation_len = 2**7,\n",
    "    batch_size = 2**6,    \n",
    "    # -----------------------------------------\n",
    "    experiment_name = \"0.0-amp-main-notebook\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6162b6",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "In the prediction stage, the trained model is loaded along with the input data. The model then performs inference, generating predictions based on the provided data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f922aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-28 07:17:53.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.predict\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mPerforming inference for model...\u001b[0m\n",
      "\u001b[32m2025-06-28 07:17:53.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.predict\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mInput data shape: (51, 15)\u001b[0m\n",
      "\u001b[32m2025-06-28 07:17:53.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.generator_strategy\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mGenerating Timeseries from dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repositories\\ds-lstm-ibov\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "            Close_^BVSP  Volume_^BVSP       type\n",
      "2025-06-26     0.009921      0.041216       True\n",
      "2025-06-27    -0.001809     -0.221704       True\n",
      "2025-06-28     0.000646      0.017280  Predicted\n",
      "\u001b[32m2025-06-28 07:17:56.168\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.modeling.predict\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m76\u001b[0m - \u001b[32m\u001b[1mInference complete.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "from src.modeling import predict\n",
    "\n",
    "predict.main(\n",
    "    # ---- REPLACE DEFAULT PATHS AS APPROPRIATE ----\n",
    "    input_path = config.PROCESSED_DATA_DIR / \"dataset.csv\",\n",
    "    preprocessor_path = config.PROCESSED_DATA_DIR / \"preprocessor.pkl\",\n",
    "    model_path = config.MODELS_DIR / \"Sequential_epoch82_loss0.3165.keras\",  # Select the best model  \n",
    "    postprocessor_path = config.PROCESSED_DATA_DIR / \"postprocessor.pkl\",\n",
    "    output_path = config.PROCESSED_DATA_DIR / \"dataset_report.csv\",\n",
    "    length = 50\n",
    "    # -----------------------------------------\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ef876",
   "metadata": {},
   "source": [
    "## Plot\n",
    "\n",
    "Open the [Power BI Report]((../reports/pbi/amp-fynance.pbip)) and refresh data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
