{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f58e5c2",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42021f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 13:08:08.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Repositories\\ds-lstm-ibov\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import src.config as config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfd6425",
   "metadata": {},
   "source": [
    "## ETL — Extract, Transform, Load of Raw Dataset\n",
    "\n",
    "This section is responsible for the Extraction phase of the ETL process, pulling historical financial data from multiple sources as defined in the configuration file [dataset.yaml](../configs/dataset.yaml).\n",
    "\n",
    "- Data Storage: Each dataset is stored locally in the data/raw/ directory, organized and saved individually as .csv files for traceability and versioning.\n",
    "- Data Cleaning:\n",
    "  - Missing values are treated using a standard cleaning strategy.\n",
    "  - Features with low variance (threshold < 0.01) are removed to reduce noise and improve modeling efficiency. In this execution, no low-variance columns were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fdcd420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 13:08:12.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mStarting raw data loading...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:08:12.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mRequesting information between 2016-06-27 and 2025-06-25\u001b[0m\n",
      "\u001b[32m2025-06-25 13:08:12.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading BOVESPA (^BVSP) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 13:08:15.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading S&P500 (^GSPC) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 13:08:18.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading BITCOIN (BTC-USD) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 13:08:21.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading OURO (GC=F) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 13:08:24.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading PETROLEO (CL=F) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 13:08:26.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_from_yfinance\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mDownloading ACUCAR (SB=F) from yfinance...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 13:08:29.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading SELIC (11) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:08:48.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading CDI (12) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:08:50.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading SELIC_Anual (1178) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:09:10.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading SELIC_Meta_Anual (432) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:09:40.755\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_request_bcb_series\u001b[0m:\u001b[36m118\u001b[0m - \u001b[33m\u001b[1mErro ao conectar à API do BCB: Expecting value: line 1 column 1 (char 0)\u001b[0m\n",
      "\u001b[32m2025-06-25 13:09:40.758\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_single_ticker\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mNo data returned for SELIC_Meta_Anual (432)\u001b[0m\n",
      "\u001b[32m2025-06-25 13:09:42.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading IPCA_Mensal (433) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:09:47.597\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_request_bcb_series\u001b[0m:\u001b[36m118\u001b[0m - \u001b[33m\u001b[1mErro ao conectar à API do BCB: 502 Server Error: Bad Gateway for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.433/dados?formato=json&dataInicial=27%2F06%2F2016&dataFinal=25%2F06%2F2025\u001b[0m\n",
      "\u001b[32m2025-06-25 13:09:47.600\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36m_load_single_ticker\u001b[0m:\u001b[36m94\u001b[0m - \u001b[33m\u001b[1mNo data returned for IPCA_Mensal (433)\u001b[0m\n",
      "\u001b[32m2025-06-25 13:09:49.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading IGP_M_Mensal (189) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:09:52.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading INCC_Mensal (192) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:09:54.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Indice_Condicoes_Econ_BR (27574) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:09:57.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Indice_Condicoes_Econ_BR_USD (29042) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:00.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Salario_Minimo (1619) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:02.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading IBC_BR (24363) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:05.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Populacao_BR (21774) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:11.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading PIB_Trimestral_Real (4380) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:13.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading PIB_Anual_Corrente (7326) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:16.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mDownloading Deflator_Implicito_PIB (1211) from the Central Bank of Brazil API...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:18.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mDownloading BRL_USD (DEXBZUS) from DataReader...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:23.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.dataset.dataset_loading_strategy\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mDownloading CPI_USA (CPIAUCSL) from DataReader...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_BOVESPA dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_BOVESPA.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_S&P500 dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_S&P500.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_BITCOIN dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_BITCOIN.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_OURO dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_OURO.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_PETROLEO dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_PETROLEO.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Yfinance_ACUCAR dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Yfinance_ACUCAR.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_SELIC dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_SELIC.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_CDI dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_CDI.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_SELIC_Anual dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_SELIC_Anual.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_IGP_M_Mensal dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_IGP_M_Mensal.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_INCC_Mensal dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_INCC_Mensal.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Indice_Condicoes_Econ_BR dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_Indice_Condicoes_Econ_BR.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Indice_Condicoes_Econ_BR_USD dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_Indice_Condicoes_Econ_BR_USD.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Salario_Minimo dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_Salario_Minimo.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_IBC_BR dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_IBC_BR.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Populacao_BR dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_Populacao_BR.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_PIB_Trimestral_Real dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_PIB_Trimestral_Real.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_PIB_Anual_Corrente dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_PIB_Anual_Corrente.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved Bcb_Deflator_Implicito_PIB dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\Bcb_Deflator_Implicito_PIB.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved DataReader_BRL_USD dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\DataReader_BRL_USD.csv\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:25.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mSaved DataReader_CPI_USA dataset to C:\\Repositories\\ds-lstm-ibov\\data\\raw\\DataReader_CPI_USA.csv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.dataset.clean_strategy:Executing CleanMissingValues...\n",
      "INFO:src.utils.dataset.clean_strategy:Executing CleanLowVariance with threshold=0.01...\n",
      "INFO:src.utils.dataset.clean_strategy:Columns removed due to low variance: Index([], dtype='object')\n",
      "c:\\Repositories\\ds-lstm-ibov\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Repositories\\ds-lstm-ibov\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n",
      "INFO:src.utils.dataset.clean_strategy:Columns removed by f_classif: ['Volume_^GSPC']\n",
      "c:\\Repositories\\ds-lstm-ibov\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "INFO:src.utils.dataset.clean_strategy:Columns removed by f_regression: ['IGP_M_Mensal']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close_^BVSP  High_^BVSP  Low_^BVSP  Open_^BVSP  Volume_^BVSP  \\\n",
      "2025-06-18     138717.0    139161.0   138443.0    138844.0     8323400.0   \n",
      "2025-06-19          NaN         NaN        NaN         NaN           NaN   \n",
      "2025-06-20     137116.0    138719.0   136815.0    138715.0    11289300.0   \n",
      "2025-06-21          NaN         NaN        NaN         NaN           NaN   \n",
      "2025-06-22          NaN         NaN        NaN         NaN           NaN   \n",
      "2025-06-23     136551.0    137130.0   135835.0    137116.0     7727800.0   \n",
      "2025-06-24     137165.0    138156.0   136254.0    136552.0     8083700.0   \n",
      "\n",
      "            Close_^GSPC   High_^GSPC    Low_^GSPC   Open_^GSPC  Volume_^GSPC  \\\n",
      "2025-06-18  5980.870117  6018.250000  5971.890137  5987.930176  5.106470e+09   \n",
      "2025-06-19          NaN          NaN          NaN          NaN           NaN   \n",
      "2025-06-20  5967.839844  6018.200195  5952.560059  5999.669922  7.451500e+09   \n",
      "2025-06-21          NaN          NaN          NaN          NaN           NaN   \n",
      "2025-06-22          NaN          NaN          NaN          NaN           NaN   \n",
      "2025-06-23  6025.169922  6028.770020  5943.229980  5969.669922  5.597000e+09   \n",
      "2025-06-24  6092.180176  6101.759766  6059.250000  6061.209961  5.443690e+09   \n",
      "\n",
      "            ...  Indice_Condicoes_Econ_BR  Indice_Condicoes_Econ_BR_USD  \\\n",
      "2025-06-18  ...                       NaN                           NaN   \n",
      "2025-06-19  ...                       NaN                           NaN   \n",
      "2025-06-20  ...                       NaN                           NaN   \n",
      "2025-06-21  ...                       NaN                           NaN   \n",
      "2025-06-22  ...                       NaN                           NaN   \n",
      "2025-06-23  ...                       NaN                           NaN   \n",
      "2025-06-24  ...                       NaN                           NaN   \n",
      "\n",
      "            Salario_Minimo  IBC_BR  Populacao_BR  PIB_Trimestral_Real  \\\n",
      "2025-06-18             NaN     NaN           NaN                  NaN   \n",
      "2025-06-19             NaN     NaN           NaN                  NaN   \n",
      "2025-06-20             NaN     NaN           NaN                  NaN   \n",
      "2025-06-21             NaN     NaN           NaN                  NaN   \n",
      "2025-06-22             NaN     NaN           NaN                  NaN   \n",
      "2025-06-23             NaN     NaN           NaN                  NaN   \n",
      "2025-06-24             NaN     NaN           NaN                  NaN   \n",
      "\n",
      "            PIB_Anual_Corrente  Deflator_Implicito_PIB  DEXBZUS  CPIAUCSL  \n",
      "2025-06-18                 NaN                     NaN   5.4921       NaN  \n",
      "2025-06-19                 NaN                     NaN      NaN       NaN  \n",
      "2025-06-20                 NaN                     NaN   5.5035       NaN  \n",
      "2025-06-21                 NaN                     NaN      NaN       NaN  \n",
      "2025-06-22                 NaN                     NaN      NaN       NaN  \n",
      "2025-06-23                 NaN                     NaN      NaN       NaN  \n",
      "2025-06-24                 NaN                     NaN      NaN       NaN  \n",
      "\n",
      "[7 rows x 45 columns]\n",
      "\u001b[32m2025-06-25 13:10:26.022\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m69\u001b[0m - \u001b[32m\u001b[1mRaw data successfully loaded...\u001b[0m\n",
      "            Close_^BVSP  High_^BVSP  Low_^BVSP  Open_^BVSP  Volume_^BVSP  \\\n",
      "2025-06-13    -0.004260   -0.000950   0.003018    0.004908      0.211057   \n",
      "2025-06-16     0.014889    0.015878   0.004583   -0.004267     -0.116802   \n",
      "2025-06-17    -0.002987   -0.003507   0.007878    0.014897      0.099272   \n",
      "2025-06-18    -0.000886   -0.002409   0.001085   -0.002959     -0.006398   \n",
      "2025-06-20    -0.011541   -0.003176  -0.011759   -0.000929      0.356333   \n",
      "2025-06-23    -0.004121   -0.011455  -0.007163   -0.011527     -0.315476   \n",
      "2025-06-24     0.004496    0.007482   0.003085   -0.004113      0.046055   \n",
      "\n",
      "            Close_^GSPC  High_^GSPC  Low_^GSPC  Open_^GSPC  Volume_^GSPC  ...  \\\n",
      "2025-06-13    -0.011296   -0.003188  -0.006774   -0.001554      0.126226  ...   \n",
      "2025-06-16     0.009393    0.004094   0.006840    0.000573     -0.027991  ...   \n",
      "2025-06-17    -0.008352   -0.004558  -0.004863    0.001357     -0.030520  ...   \n",
      "2025-06-18    -0.000309   -0.000830  -0.000487   -0.004028      0.030424  ...   \n",
      "2025-06-20    -0.002179   -0.000008  -0.003237    0.001961      0.459227  ...   \n",
      "2025-06-23     0.009607    0.001756  -0.001567   -0.005000     -0.248876  ...   \n",
      "2025-06-24     0.011122    0.012107   0.019521    0.015334     -0.027391  ...   \n",
      "\n",
      "            Indice_Condicoes_Econ_BR  Indice_Condicoes_Econ_BR_USD  \\\n",
      "2025-06-13                       0.0                           0.0   \n",
      "2025-06-16                       0.0                           0.0   \n",
      "2025-06-17                       0.0                           0.0   \n",
      "2025-06-18                       0.0                           0.0   \n",
      "2025-06-20                       0.0                           0.0   \n",
      "2025-06-23                       0.0                           0.0   \n",
      "2025-06-24                       0.0                           0.0   \n",
      "\n",
      "            Salario_Minimo  IBC_BR  Populacao_BR  PIB_Trimestral_Real  \\\n",
      "2025-06-13             0.0     0.0           0.0                  0.0   \n",
      "2025-06-16             0.0     0.0           0.0                  0.0   \n",
      "2025-06-17             0.0     0.0           0.0                  0.0   \n",
      "2025-06-18             0.0     0.0           0.0                  0.0   \n",
      "2025-06-20             0.0     0.0           0.0                  0.0   \n",
      "2025-06-23             0.0     0.0           0.0                  0.0   \n",
      "2025-06-24             0.0     0.0           0.0                  0.0   \n",
      "\n",
      "            PIB_Anual_Corrente  Deflator_Implicito_PIB   DEXBZUS  CPIAUCSL  \n",
      "2025-06-13                 0.0                     0.0 -0.000108       0.0  \n",
      "2025-06-16                 0.0                     0.0 -0.005140       0.0  \n",
      "2025-06-17                 0.0                     0.0 -0.007124       0.0  \n",
      "2025-06-18                 0.0                     0.0  0.002720       0.0  \n",
      "2025-06-20                 0.0                     0.0  0.002076       0.0  \n",
      "2025-06-23                 0.0                     0.0  0.000000       0.0  \n",
      "2025-06-24                 0.0                     0.0  0.000000       0.0  \n",
      "\n",
      "[7 rows x 45 columns]\n",
      "            Close_^BVSP  Volume_^GSPC  Volume_BTC-USD  Volume_GC=F  \\\n",
      "2025-06-13    -0.004260      0.126226        0.268153    -0.725523   \n",
      "2025-06-16     0.014889     -0.027991       -0.275826    -0.038076   \n",
      "2025-06-17    -0.002987     -0.030520        0.111134     2.077083   \n",
      "2025-06-18    -0.000886      0.030424       -0.154492    -1.000000   \n",
      "2025-06-20    -0.011541      0.459227        0.076795     0.000000   \n",
      "2025-06-23    -0.004121     -0.248876        0.280380    -0.957687   \n",
      "2025-06-24     0.004496     -0.027391       -0.251615     0.000000   \n",
      "\n",
      "            Volume_CL=F  Volume_SB=F  IPCA_Mensal  IGP_M_Mensal month_name  \\\n",
      "2025-06-13     0.886303    -0.052937          0.0           0.0       June   \n",
      "2025-06-16    -0.486745     0.504464          0.0           0.0       June   \n",
      "2025-06-17    -0.580019    -0.489217          0.0           0.0       June   \n",
      "2025-06-18    -1.000000    -1.000000          0.0           0.0       June   \n",
      "2025-06-20     0.000000     0.000000          0.0           0.0       June   \n",
      "2025-06-23     0.074429     0.622250          0.0           0.0       June   \n",
      "2025-06-24     0.000000     0.000000          0.0           0.0       June   \n",
      "\n",
      "            week_of_month day_of_week  is_weekend  is_holiday  \n",
      "2025-06-13              3      Friday           0           0  \n",
      "2025-06-16              4      Monday           0           0  \n",
      "2025-06-17              4     Tuesday           0           0  \n",
      "2025-06-18              4   Wednesday           0           0  \n",
      "2025-06-20              4      Friday           0           0  \n",
      "2025-06-23              5      Monday           0           0  \n",
      "2025-06-24              5     Tuesday           0           0  \n",
      "            Close_^BVSP  Volume_^GSPC  Volume_BTC-USD  Volume_GC=F  \\\n",
      "2025-06-13    -0.004260      0.126226        0.268153    -0.725523   \n",
      "2025-06-16     0.014889     -0.027991       -0.275826    -0.038076   \n",
      "2025-06-17    -0.002987     -0.030520        0.111134     2.077083   \n",
      "2025-06-18    -0.000886      0.030424       -0.154492    -1.000000   \n",
      "2025-06-20    -0.011541      0.459227        0.076795     0.000000   \n",
      "2025-06-23    -0.004121     -0.248876        0.280380    -0.957687   \n",
      "2025-06-24     0.004496     -0.027391       -0.251615     0.000000   \n",
      "\n",
      "            Volume_CL=F  Volume_SB=F  IPCA_Mensal  IGP_M_Mensal month_name  \\\n",
      "2025-06-13     0.886303    -0.052937          0.0           0.0       June   \n",
      "2025-06-16    -0.486745     0.504464          0.0           0.0       June   \n",
      "2025-06-17    -0.580019    -0.489217          0.0           0.0       June   \n",
      "2025-06-18    -1.000000    -1.000000          0.0           0.0       June   \n",
      "2025-06-20     0.000000     0.000000          0.0           0.0       June   \n",
      "2025-06-23     0.074429     0.622250          0.0           0.0       June   \n",
      "2025-06-24     0.000000     0.000000          0.0           0.0       June   \n",
      "\n",
      "            week_of_month day_of_week  is_weekend  is_holiday  Volume_^BVSP  \\\n",
      "2025-06-13              3      Friday           0           0      0.085695   \n",
      "2025-06-16              4      Monday           0           0      0.085695   \n",
      "2025-06-17              4     Tuesday           0           0      0.085695   \n",
      "2025-06-18              4   Wednesday           0           0      0.085695   \n",
      "2025-06-20              4      Friday           0           0      0.085695   \n",
      "2025-06-23              5      Monday           0           0      0.085695   \n",
      "2025-06-24              5     Tuesday           0           0      0.085695   \n",
      "\n",
      "            INCC_Mensal  \n",
      "2025-06-13          0.0  \n",
      "2025-06-16          0.0  \n",
      "2025-06-17          0.0  \n",
      "2025-06-18          0.0  \n",
      "2025-06-20          0.0  \n",
      "2025-06-23          0.0  \n",
      "2025-06-24          0.0  \n",
      "\u001b[32m2025-06-25 13:10:26.455\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m109\u001b[0m - \u001b[32m\u001b[1mClean data successfully loaded...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:10:26.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.dataset\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mTotal time taken: 134.00 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import dataset\n",
    "\n",
    "dataset.main(\n",
    "    # ---- REPLACE DEFAULT AS APPROPRIATE ----\n",
    "    asset = '^BVSP',\n",
    "    asset_focus = 'Close',\n",
    "    years = 9\n",
    "    # -----------------------------------------\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fce4b8",
   "metadata": {},
   "source": [
    "## Feature Engineering — Time Series Preparation\n",
    "\n",
    "This part of the pipeline is responsible for transforming the cleaned dataset into structured features suitable for training time series models. It includes the following key steps:\n",
    "- Feature Generation: Constructs relevant features based on historical market data.\n",
    "- Dataset Splitting: The dataset is split into training and testing sets using a consistent strategy to preserve temporal structure.\n",
    "- Time Series Windowing: Converts the sequential data into overlapping windows, enabling the model to learn temporal dependencies.\n",
    "- Saving Artifacts: Both training and testing sets are stored for reproducibility, along with the transformation pipelines applied during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64946194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 22:40:47.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Repositories\\ds-lstm-ibov\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 22:40:56.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mGenerating features from dataset...\u001b[0m\n",
      "\u001b[32m2025-06-25 22:40:56.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.splitter_strategy\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mSplitting dataset into training and testing sets...\u001b[0m\n",
      "\u001b[32m2025-06-25 22:40:56.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.generator_strategy\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mGenerating Timeseries from dataset...\u001b[0m\n",
      "\u001b[32m2025-06-25 22:40:56.457\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m51\u001b[0m - \u001b[32m\u001b[1mSaving train features in C:\\Repositories\\ds-lstm-ibov\\data\\processed...\u001b[0m\n",
      "\u001b[32m2025-06-25 22:40:56.528\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m55\u001b[0m - \u001b[32m\u001b[1mSaving test features in C:\\Repositories\\ds-lstm-ibov\\data\\processed...\u001b[0m\n",
      "\u001b[32m2025-06-25 22:40:56.530\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m59\u001b[0m - \u001b[32m\u001b[1mFeatures generation complete.\u001b[0m\n",
      "\u001b[32m2025-06-25 22:40:56.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mSaving transformers...\u001b[0m\n",
      "\u001b[32m2025-06-25 22:40:56.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.splitter_strategy\u001b[0m:\u001b[36msplit\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mSplitting dataset into training and testing sets...\u001b[0m\n",
      "\u001b[32m2025-06-25 22:40:56.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.features\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mTotal time taken: 0.22 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "from src import features\n",
    "\n",
    "features.main(\n",
    "    # ---- REPLACE DEFAULT PATHS AS APPROPRIATE ----\n",
    "    dataset_path = config.PROCESSED_DATA_DIR / \"dataset.csv\",\n",
    "    train_dir = config.PROCESSED_DATA_DIR,\n",
    "    test_dir = config.PROCESSED_DATA_DIR,\n",
    "    targets = [\"^BVSP\"],\n",
    "    train_size_ratio = 1,\n",
    "    batch_size = 1,\n",
    "    sequence_length = 50\n",
    "    # -----------------------------------------\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66434c",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "The modeling process begins with loading the training dataset. Next, the base model is constructed, and both the compilation and training strategies are defined. With the pipeline structure in place, the model is trained over 100 epochs using an iterative approach to adjust the weights.\n",
    "\n",
    "During training, key metrics are monitored, including accuracy, loss (error), validation accuracy and loss (on unseen data), as well as the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff11608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 23:06:18.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Repositories\\ds-lstm-ibov\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 23:06:29.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mLoading training dataset...\u001b[0m\n",
      "\u001b[32m2025-06-25 23:06:29.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mBuilding model...\u001b[0m\n",
      "\u001b[32m2025-06-25 23:06:29.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mSelecting compile strategy...\u001b[0m\n",
      "\u001b[32m2025-06-25 23:06:29.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mSelecting training strategy...\u001b[0m\n",
      "\u001b[32m2025-06-25 23:06:29.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mBuilding model training pipeline template...\u001b[0m\n",
      "\u001b[32m2025-06-25 23:06:29.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.train\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mTraining model...\u001b[0m\n",
      "Epoch 1/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 123ms/step - loss: 0.6882 - mae: 1.0274 - mse: 53.7448 - r2_score: -0.0128 - rmse: 2.1740 - smape: 158.9926 - val_loss: 0.0838 - val_mae: 0.2135 - val_mse: 0.1173 - val_r2_score: -0.0053 - val_rmse: 0.3425 - val_smape: 118.7145\n",
      "Epoch 2/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.6990 - mae: 1.0449 - mse: 53.7642 - r2_score: -0.0287 - rmse: 2.1843 - smape: 179.7507 - val_loss: 0.0879 - val_mae: 0.2717 - val_mse: 0.1278 - val_r2_score: -0.0951 - val_rmse: 0.3575 - val_smape: 196.7790\n",
      "Epoch 3/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 0.6850 - mae: 1.0284 - mse: 53.7582 - r2_score: -0.0060 - rmse: 2.1722 - smape: 172.8859 - val_loss: 0.0812 - val_mae: 0.2100 - val_mse: 0.1171 - val_r2_score: -0.0030 - val_rmse: 0.3422 - val_smape: 115.4383\n",
      "Epoch 4/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.6852 - mae: 1.0317 - mse: 53.7205 - r2_score: -0.0077 - rmse: 2.1717 - smape: 171.8311 - val_loss: 0.0878 - val_mae: 0.2812 - val_mse: 0.1316 - val_r2_score: -0.1274 - val_rmse: 0.3627 - val_smape: 193.2374\n",
      "Epoch 5/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - loss: 0.6734 - mae: 1.0165 - mse: 53.7169 - r2_score: 0.0081 - rmse: 2.1627 - smape: 170.9991 - val_loss: 0.0840 - val_mae: 0.2647 - val_mse: 0.1255 - val_r2_score: -0.0754 - val_rmse: 0.3543 - val_smape: 196.2640\n",
      "Epoch 6/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.6748 - mae: 1.0195 - mse: 53.7492 - r2_score: 0.0069 - rmse: 2.1645 - smape: 173.0788 - val_loss: 0.0875 - val_mae: 0.2773 - val_mse: 0.1339 - val_r2_score: -0.1473 - val_rmse: 0.3659 - val_smape: 192.0372\n",
      "Epoch 7/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.6646 - mae: 1.0083 - mse: 53.7118 - r2_score: 0.0209 - rmse: 2.1541 - smape: 168.9276 - val_loss: 0.0843 - val_mae: 0.2593 - val_mse: 0.1287 - val_r2_score: -0.1030 - val_rmse: 0.3588 - val_smape: 189.3703\n",
      "Epoch 8/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.6640 - mae: 1.0096 - mse: 53.6600 - r2_score: 0.0293 - rmse: 2.1489 - smape: 169.4975 - val_loss: 0.0857 - val_mae: 0.2465 - val_mse: 0.1329 - val_r2_score: -0.1387 - val_rmse: 0.3646 - val_smape: 131.0412\n",
      "Epoch 9/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.6539 - mae: 0.9992 - mse: 53.6363 - r2_score: 0.0496 - rmse: 2.1331 - smape: 163.1380 - val_loss: 0.0811 - val_mae: 0.2407 - val_mse: 0.1243 - val_r2_score: -0.0647 - val_rmse: 0.3525 - val_smape: 143.7964\n",
      "Epoch 10/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - loss: 0.6507 - mae: 0.9944 - mse: 53.5677 - r2_score: 0.0566 - rmse: 2.1293 - smape: 162.9424 - val_loss: 0.0822 - val_mae: 0.2493 - val_mse: 0.1271 - val_r2_score: -0.0892 - val_rmse: 0.3565 - val_smape: 144.2959\n",
      "Epoch 11/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - loss: 0.6401 - mae: 0.9822 - mse: 53.5677 - r2_score: 0.0739 - rmse: 2.1179 - smape: 159.8960 - val_loss: 0.0820 - val_mae: 0.2553 - val_mse: 0.1274 - val_r2_score: -0.0913 - val_rmse: 0.3569 - val_smape: 140.0826\n",
      "Epoch 12/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - loss: 0.6392 - mae: 0.9825 - mse: 53.5313 - r2_score: 0.0757 - rmse: 2.1144 - smape: 159.2302 - val_loss: 0.0858 - val_mae: 0.2646 - val_mse: 0.1353 - val_r2_score: -0.1589 - val_rmse: 0.3678 - val_smape: 152.8259\n",
      "Epoch 13/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.6307 - mae: 0.9733 - mse: 53.4839 - r2_score: 0.1027 - rmse: 2.0969 - smape: 157.4807 - val_loss: 0.0858 - val_mae: 0.2694 - val_mse: 0.1352 - val_r2_score: -0.1581 - val_rmse: 0.3676 - val_smape: 154.8920\n",
      "Epoch 14/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 0.6237 - mae: 0.9607 - mse: 53.4374 - r2_score: 0.1188 - rmse: 2.0863 - smape: 153.2355 - val_loss: 0.0806 - val_mae: 0.2465 - val_mse: 0.1246 - val_r2_score: -0.0675 - val_rmse: 0.3530 - val_smape: 150.3997\n",
      "Epoch 15/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - loss: 0.6159 - mae: 0.9548 - mse: 53.4428 - r2_score: 0.1343 - rmse: 2.0774 - smape: 152.0674 - val_loss: 0.0764 - val_mae: 0.2247 - val_mse: 0.1159 - val_r2_score: 0.0071 - val_rmse: 0.3404 - val_smape: 143.7659\n",
      "Epoch 16/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 0.6052 - mae: 0.9398 - mse: 53.3715 - r2_score: 0.1572 - rmse: 2.0594 - smape: 147.5684 - val_loss: 0.0778 - val_mae: 0.2325 - val_mse: 0.1187 - val_r2_score: -0.0170 - val_rmse: 0.3445 - val_smape: 152.0259\n",
      "Epoch 17/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 0.5927 - mae: 0.9225 - mse: 53.3189 - r2_score: 0.1844 - rmse: 2.0384 - smape: 144.8167 - val_loss: 0.0759 - val_mae: 0.2167 - val_mse: 0.1147 - val_r2_score: 0.0171 - val_rmse: 0.3387 - val_smape: 136.9362\n",
      "Epoch 18/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - loss: 0.5954 - mae: 0.9268 - mse: 53.3675 - r2_score: 0.1758 - rmse: 2.0459 - smape: 144.1978 - val_loss: 0.0765 - val_mae: 0.2185 - val_mse: 0.1155 - val_r2_score: 0.0102 - val_rmse: 0.3399 - val_smape: 138.6344\n",
      "Epoch 19/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 100ms/step - loss: 0.5804 - mae: 0.9093 - mse: 53.3033 - r2_score: 0.2078 - rmse: 2.0213 - smape: 140.4433 - val_loss: 0.0766 - val_mae: 0.2080 - val_mse: 0.1154 - val_r2_score: 0.0114 - val_rmse: 0.3397 - val_smape: 116.6681\n",
      "Epoch 20/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.5762 - mae: 0.9047 - mse: 53.2382 - r2_score: 0.2216 - rmse: 2.0102 - smape: 139.6900 - val_loss: 0.0767 - val_mae: 0.2028 - val_mse: 0.1150 - val_r2_score: 0.0145 - val_rmse: 0.3392 - val_smape: 108.2866\n",
      "Epoch 21/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - loss: 0.5753 - mae: 0.9063 - mse: 53.2512 - r2_score: 0.2130 - rmse: 2.0147 - smape: 139.1233 - val_loss: 0.0790 - val_mae: 0.2181 - val_mse: 0.1193 - val_r2_score: -0.0218 - val_rmse: 0.3453 - val_smape: 119.5864\n",
      "Epoch 22/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - loss: 0.5646 - mae: 0.8898 - mse: 53.1756 - r2_score: 0.2519 - rmse: 1.9835 - smape: 137.8632 - val_loss: 0.0765 - val_mae: 0.2012 - val_mse: 0.1138 - val_r2_score: 0.0248 - val_rmse: 0.3374 - val_smape: 104.5102\n",
      "Epoch 23/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.5579 - mae: 0.8822 - mse: 53.1527 - r2_score: 0.2629 - rmse: 1.9759 - smape: 135.3613 - val_loss: 0.0767 - val_mae: 0.2004 - val_mse: 0.1138 - val_r2_score: 0.0247 - val_rmse: 0.3374 - val_smape: 108.0890\n",
      "Epoch 24/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.5532 - mae: 0.8782 - mse: 53.1170 - r2_score: 0.2694 - rmse: 1.9693 - smape: 135.9437 - val_loss: 0.0768 - val_mae: 0.2019 - val_mse: 0.1135 - val_r2_score: 0.0272 - val_rmse: 0.3370 - val_smape: 107.7542\n",
      "Epoch 25/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.5529 - mae: 0.8792 - mse: 53.0270 - r2_score: 0.2581 - rmse: 1.9782 - smape: 134.2382 - val_loss: 0.0768 - val_mae: 0.1990 - val_mse: 0.1131 - val_r2_score: 0.0313 - val_rmse: 0.3362 - val_smape: 100.7150\n",
      "Epoch 26/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - loss: 0.5474 - mae: 0.8686 - mse: 53.0841 - r2_score: 0.2836 - rmse: 1.9557 - smape: 133.3468 - val_loss: 0.0775 - val_mae: 0.2024 - val_mse: 0.1141 - val_r2_score: 0.0225 - val_rmse: 0.3378 - val_smape: 108.7314\n",
      "Epoch 27/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.5317 - mae: 0.8487 - mse: 53.0506 - r2_score: 0.3175 - rmse: 1.9315 - smape: 130.0852 - val_loss: 0.0779 - val_mae: 0.2061 - val_mse: 0.1145 - val_r2_score: 0.0186 - val_rmse: 0.3384 - val_smape: 115.9370\n",
      "Epoch 28/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.5304 - mae: 0.8477 - mse: 53.0536 - r2_score: 0.3200 - rmse: 1.9279 - smape: 128.2532 - val_loss: 0.0778 - val_mae: 0.2060 - val_mse: 0.1142 - val_r2_score: 0.0216 - val_rmse: 0.3379 - val_smape: 114.6371\n",
      "Epoch 29/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - loss: 0.5236 - mae: 0.8408 - mse: 52.9562 - r2_score: 0.3273 - rmse: 1.9143 - smape: 129.0164 - val_loss: 0.0778 - val_mae: 0.2051 - val_mse: 0.1136 - val_r2_score: 0.0269 - val_rmse: 0.3370 - val_smape: 110.8841\n",
      "Epoch 30/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.5213 - mae: 0.8363 - mse: 52.9969 - r2_score: 0.3345 - rmse: 1.9091 - smape: 125.8874 - val_loss: 0.0786 - val_mae: 0.2040 - val_mse: 0.1150 - val_r2_score: 0.0149 - val_rmse: 0.3391 - val_smape: 110.5868\n",
      "Epoch 31/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.5238 - mae: 0.8399 - mse: 52.9196 - r2_score: 0.3356 - rmse: 1.9074 - smape: 127.9667 - val_loss: 0.0783 - val_mae: 0.2049 - val_mse: 0.1142 - val_r2_score: 0.0219 - val_rmse: 0.3379 - val_smape: 114.9569\n",
      "Epoch 32/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 0.5156 - mae: 0.8287 - mse: 52.8619 - r2_score: 0.3445 - rmse: 1.8965 - smape: 126.4750 - val_loss: 0.0785 - val_mae: 0.2052 - val_mse: 0.1143 - val_r2_score: 0.0204 - val_rmse: 0.3381 - val_smape: 116.6736\n",
      "Epoch 33/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 0.5082 - mae: 0.8212 - mse: 52.7474 - r2_score: 0.3580 - rmse: 1.8863 - smape: 124.0701 - val_loss: 0.0787 - val_mae: 0.2055 - val_mse: 0.1142 - val_r2_score: 0.0215 - val_rmse: 0.3379 - val_smape: 116.1503\n",
      "Epoch 34/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.5021 - mae: 0.8132 - mse: 52.7889 - r2_score: 0.3688 - rmse: 1.8784 - smape: 123.3098 - val_loss: 0.0786 - val_mae: 0.2044 - val_mse: 0.1139 - val_r2_score: 0.0241 - val_rmse: 0.3375 - val_smape: 117.0649\n",
      "Epoch 35/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.5020 - mae: 0.8141 - mse: 52.5116 - r2_score: 0.3775 - rmse: 1.8624 - smape: 122.3935 - val_loss: 0.0789 - val_mae: 0.2064 - val_mse: 0.1141 - val_r2_score: 0.0226 - val_rmse: 0.3378 - val_smape: 114.6895\n",
      "Epoch 36/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.5021 - mae: 0.8140 - mse: 52.6396 - r2_score: 0.3747 - rmse: 1.8647 - smape: 123.0848 - val_loss: 0.0788 - val_mae: 0.2047 - val_mse: 0.1135 - val_r2_score: 0.0276 - val_rmse: 0.3369 - val_smape: 116.7694\n",
      "Epoch 37/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - loss: 0.5051 - mae: 0.8147 - mse: 52.8077 - r2_score: 0.3737 - rmse: 1.8714 - smape: 121.3088 - val_loss: 0.0788 - val_mae: 0.2038 - val_mse: 0.1132 - val_r2_score: 0.0302 - val_rmse: 0.3364 - val_smape: 112.4228\n",
      "Epoch 38/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.4968 - mae: 0.8063 - mse: 52.7557 - r2_score: 0.3768 - rmse: 1.8769 - smape: 120.3084 - val_loss: 0.0794 - val_mae: 0.2067 - val_mse: 0.1144 - val_r2_score: 0.0199 - val_rmse: 0.3382 - val_smape: 119.9205\n",
      "Epoch 39/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.4996 - mae: 0.8121 - mse: 52.7911 - r2_score: 0.3808 - rmse: 1.8720 - smape: 121.0581 - val_loss: 0.0802 - val_mae: 0.2101 - val_mse: 0.1155 - val_r2_score: 0.0108 - val_rmse: 0.3398 - val_smape: 120.6245\n",
      "Epoch 40/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.4863 - mae: 0.7907 - mse: 52.5940 - r2_score: 0.4109 - rmse: 1.8328 - smape: 118.5682 - val_loss: 0.0801 - val_mae: 0.2127 - val_mse: 0.1152 - val_r2_score: 0.0128 - val_rmse: 0.3394 - val_smape: 127.2654\n",
      "Epoch 41/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.4870 - mae: 0.7995 - mse: 52.6608 - r2_score: 0.4041 - rmse: 1.8412 - smape: 121.0504 - val_loss: 0.0800 - val_mae: 0.2114 - val_mse: 0.1148 - val_r2_score: 0.0168 - val_rmse: 0.3388 - val_smape: 123.1338\n",
      "Epoch 42/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.4937 - mae: 0.8026 - mse: 52.7078 - r2_score: 0.3995 - rmse: 1.8460 - smape: 118.2640 - val_loss: 0.0799 - val_mae: 0.2085 - val_mse: 0.1142 - val_r2_score: 0.0219 - val_rmse: 0.3379 - val_smape: 117.1577\n",
      "Epoch 43/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - loss: 0.4831 - mae: 0.7869 - mse: 52.4483 - r2_score: 0.4121 - rmse: 1.8323 - smape: 117.0676 - val_loss: 0.0807 - val_mae: 0.2089 - val_mse: 0.1156 - val_r2_score: 0.0100 - val_rmse: 0.3399 - val_smape: 113.8689\n",
      "Epoch 44/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - loss: 0.4927 - mae: 0.8015 - mse: 52.4753 - r2_score: 0.3971 - rmse: 1.8476 - smape: 118.6717 - val_loss: 0.0804 - val_mae: 0.2081 - val_mse: 0.1148 - val_r2_score: 0.0162 - val_rmse: 0.3389 - val_smape: 116.1619\n",
      "Epoch 45/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.4895 - mae: 0.8001 - mse: 52.5674 - r2_score: 0.4033 - rmse: 1.8390 - smape: 118.2528 - val_loss: 0.0808 - val_mae: 0.2135 - val_mse: 0.1155 - val_r2_score: 0.0105 - val_rmse: 0.3398 - val_smape: 128.7083\n",
      "Epoch 46/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.4818 - mae: 0.7851 - mse: 52.4712 - r2_score: 0.4134 - rmse: 1.8305 - smape: 114.5990 - val_loss: 0.0809 - val_mae: 0.2093 - val_mse: 0.1155 - val_r2_score: 0.0102 - val_rmse: 0.3399 - val_smape: 118.0033\n",
      "Epoch 47/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.4827 - mae: 0.7906 - mse: 52.6552 - r2_score: 0.4176 - rmse: 1.8318 - smape: 116.8223 - val_loss: 0.0801 - val_mae: 0.2077 - val_mse: 0.1137 - val_r2_score: 0.0259 - val_rmse: 0.3372 - val_smape: 119.7124\n",
      "Epoch 48/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.4753 - mae: 0.7815 - mse: 52.3328 - r2_score: 0.4312 - rmse: 1.8103 - smape: 114.7320 - val_loss: 0.0805 - val_mae: 0.2142 - val_mse: 0.1140 - val_r2_score: 0.0231 - val_rmse: 0.3377 - val_smape: 135.2886\n",
      "Epoch 49/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.4760 - mae: 0.7772 - mse: 52.6019 - r2_score: 0.4268 - rmse: 1.8229 - smape: 114.3437 - val_loss: 0.0795 - val_mae: 0.2007 - val_mse: 0.1119 - val_r2_score: 0.0413 - val_rmse: 0.3345 - val_smape: 109.1320\n",
      "Epoch 50/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.4717 - mae: 0.7737 - mse: 52.3322 - r2_score: 0.4283 - rmse: 1.8064 - smape: 114.6441 - val_loss: 0.0799 - val_mae: 0.2038 - val_mse: 0.1127 - val_r2_score: 0.0346 - val_rmse: 0.3357 - val_smape: 115.5922\n",
      "Epoch 51/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.4753 - mae: 0.7798 - mse: 52.6017 - r2_score: 0.4422 - rmse: 1.8064 - smape: 115.4800 - val_loss: 0.0801 - val_mae: 0.2054 - val_mse: 0.1128 - val_r2_score: 0.0339 - val_rmse: 0.3358 - val_smape: 115.4549\n",
      "Epoch 52/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - loss: 0.4654 - mae: 0.7639 - mse: 52.4619 - r2_score: 0.4485 - rmse: 1.7951 - smape: 112.2835 - val_loss: 0.0808 - val_mae: 0.2079 - val_mse: 0.1139 - val_r2_score: 0.0238 - val_rmse: 0.3375 - val_smape: 118.9443\n",
      "Epoch 53/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.4674 - mae: 0.7670 - mse: 52.5099 - r2_score: 0.4503 - rmse: 1.8001 - smape: 111.1424 - val_loss: 0.0815 - val_mae: 0.2106 - val_mse: 0.1151 - val_r2_score: 0.0139 - val_rmse: 0.3393 - val_smape: 120.0384\n",
      "Epoch 54/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.4611 - mae: 0.7583 - mse: 52.2568 - r2_score: 0.4664 - rmse: 1.7827 - smape: 110.8124 - val_loss: 0.0803 - val_mae: 0.2011 - val_mse: 0.1125 - val_r2_score: 0.0358 - val_rmse: 0.3355 - val_smape: 107.1259\n",
      "Epoch 55/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - loss: 0.4658 - mae: 0.7677 - mse: 52.1340 - r2_score: 0.4498 - rmse: 1.7964 - smape: 112.1377 - val_loss: 0.0819 - val_mae: 0.2124 - val_mse: 0.1156 - val_r2_score: 0.0097 - val_rmse: 0.3400 - val_smape: 124.0359\n",
      "Epoch 56/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.4648 - mae: 0.7659 - mse: 52.0048 - r2_score: 0.4572 - rmse: 1.7808 - smape: 111.2623 - val_loss: 0.0800 - val_mae: 0.2007 - val_mse: 0.1114 - val_r2_score: 0.0455 - val_rmse: 0.3338 - val_smape: 104.7108\n",
      "Epoch 57/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 0.4599 - mae: 0.7604 - mse: 52.2514 - r2_score: 0.4639 - rmse: 1.7811 - smape: 112.6184 - val_loss: 0.0802 - val_mae: 0.1998 - val_mse: 0.1117 - val_r2_score: 0.0426 - val_rmse: 0.3343 - val_smape: 104.2781\n",
      "Epoch 58/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 0.4593 - mae: 0.7583 - mse: 52.1429 - r2_score: 0.4605 - rmse: 1.7948 - smape: 110.9446 - val_loss: 0.0805 - val_mae: 0.2026 - val_mse: 0.1119 - val_r2_score: 0.0410 - val_rmse: 0.3346 - val_smape: 108.2099\n",
      "Epoch 59/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - loss: 0.4592 - mae: 0.7574 - mse: 52.0210 - r2_score: 0.4568 - rmse: 1.7809 - smape: 110.2587 - val_loss: 0.0807 - val_mae: 0.2057 - val_mse: 0.1123 - val_r2_score: 0.0376 - val_rmse: 0.3352 - val_smape: 116.2040\n",
      "Epoch 60/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 0.4516 - mae: 0.7480 - mse: 52.1252 - r2_score: 0.4848 - rmse: 1.7680 - smape: 109.4008 - val_loss: 0.0810 - val_mae: 0.2080 - val_mse: 0.1127 - val_r2_score: 0.0347 - val_rmse: 0.3357 - val_smape: 121.5450\n",
      "Epoch 61/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.4664 - mae: 0.7679 - mse: 52.1347 - r2_score: 0.4647 - rmse: 1.7780 - smape: 113.0234 - val_loss: 0.0819 - val_mae: 0.2084 - val_mse: 0.1142 - val_r2_score: 0.0216 - val_rmse: 0.3379 - val_smape: 115.6502\n",
      "Epoch 62/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.4446 - mae: 0.7371 - mse: 52.1878 - r2_score: 0.4857 - rmse: 1.7564 - smape: 107.6103 - val_loss: 0.0807 - val_mae: 0.2057 - val_mse: 0.1117 - val_r2_score: 0.0430 - val_rmse: 0.3342 - val_smape: 116.8784\n",
      "Epoch 63/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.4503 - mae: 0.7531 - mse: 51.9542 - r2_score: 0.4789 - rmse: 1.7645 - smape: 109.3016 - val_loss: 0.0815 - val_mae: 0.2072 - val_mse: 0.1132 - val_r2_score: 0.0305 - val_rmse: 0.3364 - val_smape: 115.7800\n",
      "Epoch 64/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - loss: 0.4566 - mae: 0.7523 - mse: 51.9958 - r2_score: 0.4646 - rmse: 1.7751 - smape: 108.5246 - val_loss: 0.0810 - val_mae: 0.2025 - val_mse: 0.1119 - val_r2_score: 0.0411 - val_rmse: 0.3345 - val_smape: 108.6146\n",
      "Epoch 65/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.4518 - mae: 0.7441 - mse: 52.2991 - r2_score: 0.4752 - rmse: 1.7738 - smape: 107.3346 - val_loss: 0.0806 - val_mae: 0.2033 - val_mse: 0.1111 - val_r2_score: 0.0483 - val_rmse: 0.3333 - val_smape: 110.5069\n",
      "Epoch 66/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.4519 - mae: 0.7489 - mse: 52.2029 - r2_score: 0.4840 - rmse: 1.7535 - smape: 108.4567 - val_loss: 0.0809 - val_mae: 0.2024 - val_mse: 0.1116 - val_r2_score: 0.0439 - val_rmse: 0.3341 - val_smape: 108.8865\n",
      "Epoch 67/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.4366 - mae: 0.7237 - mse: 52.1748 - r2_score: 0.4982 - rmse: 1.7559 - smape: 105.1299 - val_loss: 0.0807 - val_mae: 0.2024 - val_mse: 0.1110 - val_r2_score: 0.0491 - val_rmse: 0.3331 - val_smape: 107.5531\n",
      "Epoch 68/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 0.4414 - mae: 0.7338 - mse: 52.3694 - r2_score: 0.4954 - rmse: 1.7535 - smape: 107.4368 - val_loss: 0.0812 - val_mae: 0.2044 - val_mse: 0.1118 - val_r2_score: 0.0418 - val_rmse: 0.3344 - val_smape: 113.1486\n",
      "Epoch 69/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - loss: 0.4399 - mae: 0.7333 - mse: 52.0481 - r2_score: 0.5025 - rmse: 1.7420 - smape: 106.3443 - val_loss: 0.0807 - val_mae: 0.2055 - val_mse: 0.1107 - val_r2_score: 0.0519 - val_rmse: 0.3327 - val_smape: 118.1897\n",
      "Epoch 70/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - loss: 0.4341 - mae: 0.7218 - mse: 52.0518 - r2_score: 0.4988 - rmse: 1.7500 - smape: 106.9864 - val_loss: 0.0815 - val_mae: 0.2061 - val_mse: 0.1120 - val_r2_score: 0.0402 - val_rmse: 0.3347 - val_smape: 118.4062\n",
      "Epoch 71/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 100ms/step - loss: 0.4384 - mae: 0.7278 - mse: 51.9111 - r2_score: 0.5032 - rmse: 1.7379 - smape: 106.2610 - val_loss: 0.0811 - val_mae: 0.2014 - val_mse: 0.1111 - val_r2_score: 0.0478 - val_rmse: 0.3334 - val_smape: 109.1967\n",
      "Epoch 72/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - loss: 0.4401 - mae: 0.7304 - mse: 51.6815 - r2_score: 0.5089 - rmse: 1.7348 - smape: 105.1607 - val_loss: 0.0816 - val_mae: 0.2051 - val_mse: 0.1119 - val_r2_score: 0.0410 - val_rmse: 0.3346 - val_smape: 115.0859\n",
      "Epoch 73/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - loss: 0.4329 - mae: 0.7194 - mse: 51.9270 - r2_score: 0.5131 - rmse: 1.7304 - smape: 104.0603 - val_loss: 0.0813 - val_mae: 0.2001 - val_mse: 0.1113 - val_r2_score: 0.0466 - val_rmse: 0.3336 - val_smape: 104.5530\n",
      "Epoch 74/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.4317 - mae: 0.7231 - mse: 51.6729 - r2_score: 0.5207 - rmse: 1.7226 - smape: 105.1970 - val_loss: 0.0821 - val_mae: 0.2027 - val_mse: 0.1126 - val_r2_score: 0.0349 - val_rmse: 0.3356 - val_smape: 108.3507\n",
      "Epoch 75/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 103ms/step - loss: 0.4303 - mae: 0.7203 - mse: 51.8587 - r2_score: 0.5249 - rmse: 1.7160 - smape: 104.0036 - val_loss: 0.0813 - val_mae: 0.1990 - val_mse: 0.1111 - val_r2_score: 0.0483 - val_rmse: 0.3333 - val_smape: 101.2828\n",
      "Epoch 76/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.4292 - mae: 0.7195 - mse: 51.7477 - r2_score: 0.5285 - rmse: 1.6993 - smape: 105.9128 - val_loss: 0.0828 - val_mae: 0.2071 - val_mse: 0.1137 - val_r2_score: 0.0261 - val_rmse: 0.3372 - val_smape: 119.0400\n",
      "Epoch 77/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - loss: 0.4332 - mae: 0.7226 - mse: 51.9766 - r2_score: 0.5209 - rmse: 1.7080 - smape: 104.7837 - val_loss: 0.0819 - val_mae: 0.1988 - val_mse: 0.1120 - val_r2_score: 0.0402 - val_rmse: 0.3347 - val_smape: 101.2968\n",
      "Epoch 78/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.4399 - mae: 0.7286 - mse: 51.8039 - r2_score: 0.4998 - rmse: 1.7484 - smape: 105.4507 - val_loss: 0.0816 - val_mae: 0.2009 - val_mse: 0.1112 - val_r2_score: 0.0471 - val_rmse: 0.3335 - val_smape: 108.5277\n",
      "Epoch 79/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 99ms/step - loss: 0.4242 - mae: 0.7124 - mse: 52.0522 - r2_score: 0.5278 - rmse: 1.7140 - smape: 104.2573 - val_loss: 0.0820 - val_mae: 0.2014 - val_mse: 0.1117 - val_r2_score: 0.0425 - val_rmse: 0.3343 - val_smape: 107.3328\n",
      "Epoch 80/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 102ms/step - loss: 0.4349 - mae: 0.7259 - mse: 51.9820 - r2_score: 0.5072 - rmse: 1.7242 - smape: 103.5910 - val_loss: 0.0817 - val_mae: 0.2013 - val_mse: 0.1112 - val_r2_score: 0.0470 - val_rmse: 0.3335 - val_smape: 106.8474\n",
      "Epoch 81/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - loss: 0.4213 - mae: 0.7067 - mse: 51.5092 - r2_score: 0.5179 - rmse: 1.7188 - smape: 102.8094 - val_loss: 0.0814 - val_mae: 0.1984 - val_mse: 0.1104 - val_r2_score: 0.0537 - val_rmse: 0.3323 - val_smape: 103.0000\n",
      "Epoch 82/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.4295 - mae: 0.7185 - mse: 51.9118 - r2_score: 0.5177 - rmse: 1.7203 - smape: 103.7751 - val_loss: 0.0828 - val_mae: 0.2061 - val_mse: 0.1130 - val_r2_score: 0.0319 - val_rmse: 0.3361 - val_smape: 101.3304\n",
      "Epoch 83/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.4298 - mae: 0.7172 - mse: 52.1164 - r2_score: 0.5054 - rmse: 1.7360 - smape: 104.3609 - val_loss: 0.0813 - val_mae: 0.2040 - val_mse: 0.1101 - val_r2_score: 0.0570 - val_rmse: 0.3317 - val_smape: 114.6871\n",
      "Epoch 84/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 0.4288 - mae: 0.7158 - mse: 52.3332 - r2_score: 0.5219 - rmse: 1.7343 - smape: 104.1488 - val_loss: 0.0817 - val_mae: 0.1990 - val_mse: 0.1107 - val_r2_score: 0.0515 - val_rmse: 0.3327 - val_smape: 104.8847\n",
      "Epoch 85/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 0.4258 - mae: 0.7157 - mse: 51.6446 - r2_score: 0.5274 - rmse: 1.7123 - smape: 103.6147 - val_loss: 0.0819 - val_mae: 0.2009 - val_mse: 0.1110 - val_r2_score: 0.0491 - val_rmse: 0.3331 - val_smape: 109.7808\n",
      "Epoch 86/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 103ms/step - loss: 0.4116 - mae: 0.6958 - mse: 52.0592 - r2_score: 0.5507 - rmse: 1.6878 - smape: 100.5863 - val_loss: 0.0819 - val_mae: 0.2005 - val_mse: 0.1106 - val_r2_score: 0.0523 - val_rmse: 0.3326 - val_smape: 109.3079\n",
      "Epoch 87/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - loss: 0.4290 - mae: 0.7195 - mse: 51.3985 - r2_score: 0.5300 - rmse: 1.6952 - smape: 105.5856 - val_loss: 0.0824 - val_mae: 0.1996 - val_mse: 0.1113 - val_r2_score: 0.0463 - val_rmse: 0.3336 - val_smape: 103.6393\n",
      "Epoch 88/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 108ms/step - loss: 0.4356 - mae: 0.7252 - mse: 51.8490 - r2_score: 0.5180 - rmse: 1.7164 - smape: 105.2110 - val_loss: 0.0817 - val_mae: 0.1979 - val_mse: 0.1102 - val_r2_score: 0.0562 - val_rmse: 0.3319 - val_smape: 104.3660\n",
      "Epoch 89/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.4233 - mae: 0.7096 - mse: 51.3213 - r2_score: 0.5306 - rmse: 1.7072 - smape: 102.3175 - val_loss: 0.0816 - val_mae: 0.1984 - val_mse: 0.1096 - val_r2_score: 0.0612 - val_rmse: 0.3310 - val_smape: 104.1953\n",
      "Epoch 90/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 0.4195 - mae: 0.7060 - mse: 51.4014 - r2_score: 0.5382 - rmse: 1.6832 - smape: 103.8756 - val_loss: 0.0828 - val_mae: 0.2002 - val_mse: 0.1120 - val_r2_score: 0.0407 - val_rmse: 0.3346 - val_smape: 108.1276\n",
      "Epoch 91/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - loss: 0.4245 - mae: 0.7076 - mse: 52.0873 - r2_score: 0.5208 - rmse: 1.7270 - smape: 102.2136 - val_loss: 0.0826 - val_mae: 0.2022 - val_mse: 0.1114 - val_r2_score: 0.0459 - val_rmse: 0.3337 - val_smape: 112.1463\n",
      "Epoch 92/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - loss: 0.4218 - mae: 0.7042 - mse: 52.1201 - r2_score: 0.5248 - rmse: 1.7245 - smape: 100.9987 - val_loss: 0.0832 - val_mae: 0.2036 - val_mse: 0.1124 - val_r2_score: 0.0367 - val_rmse: 0.3353 - val_smape: 114.3234\n",
      "Epoch 93/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - loss: 0.4212 - mae: 0.7072 - mse: 51.7307 - r2_score: 0.5385 - rmse: 1.7083 - smape: 102.9721 - val_loss: 0.0830 - val_mae: 0.2061 - val_mse: 0.1118 - val_r2_score: 0.0423 - val_rmse: 0.3343 - val_smape: 122.4693\n",
      "Epoch 94/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.4255 - mae: 0.7114 - mse: 51.7032 - r2_score: 0.5264 - rmse: 1.7003 - smape: 101.4550 - val_loss: 0.0823 - val_mae: 0.2020 - val_mse: 0.1106 - val_r2_score: 0.0526 - val_rmse: 0.3325 - val_smape: 115.2070\n",
      "Epoch 95/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.4268 - mae: 0.7164 - mse: 51.7806 - r2_score: 0.5244 - rmse: 1.7121 - smape: 102.9501 - val_loss: 0.0825 - val_mae: 0.1996 - val_mse: 0.1105 - val_r2_score: 0.0529 - val_rmse: 0.3325 - val_smape: 107.5303\n",
      "Epoch 96/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - loss: 0.4196 - mae: 0.7048 - mse: 51.8661 - r2_score: 0.5338 - rmse: 1.7035 - smape: 102.2105 - val_loss: 0.0827 - val_mae: 0.1986 - val_mse: 0.1111 - val_r2_score: 0.0485 - val_rmse: 0.3332 - val_smape: 105.4490\n",
      "Epoch 97/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - loss: 0.4128 - mae: 0.6976 - mse: 51.3840 - r2_score: 0.5551 - rmse: 1.6817 - smape: 101.6426 - val_loss: 0.0831 - val_mae: 0.2001 - val_mse: 0.1117 - val_r2_score: 0.0434 - val_rmse: 0.3341 - val_smape: 108.6917\n",
      "Epoch 98/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.4206 - mae: 0.7060 - mse: 51.8970 - r2_score: 0.5335 - rmse: 1.7071 - smape: 103.6585 - val_loss: 0.0826 - val_mae: 0.1979 - val_mse: 0.1107 - val_r2_score: 0.0511 - val_rmse: 0.3328 - val_smape: 106.1003\n",
      "Epoch 99/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.4146 - mae: 0.6955 - mse: 51.9774 - r2_score: 0.5473 - rmse: 1.6859 - smape: 101.2125 - val_loss: 0.0828 - val_mae: 0.2021 - val_mse: 0.1110 - val_r2_score: 0.0487 - val_rmse: 0.3332 - val_smape: 112.3693\n",
      "Epoch 100/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 0.4199 - mae: 0.7068 - mse: 52.0027 - r2_score: 0.5353 - rmse: 1.7042 - smape: 100.2816 - val_loss: 0.0826 - val_mae: 0.2010 - val_mse: 0.1103 - val_r2_score: 0.0548 - val_rmse: 0.3321 - val_smape: 110.9049\n",
      "Epoch 101/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 0.4184 - mae: 0.7026 - mse: 51.7541 - r2_score: 0.5447 - rmse: 1.7008 - smape: 98.6756 - val_loss: 0.0836 - val_mae: 0.2004 - val_mse: 0.1124 - val_r2_score: 0.0371 - val_rmse: 0.3352 - val_smape: 108.7799\n",
      "Epoch 102/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 0.4108 - mae: 0.6932 - mse: 51.5946 - r2_score: 0.5540 - rmse: 1.6805 - smape: 100.1270 - val_loss: 0.0824 - val_mae: 0.1981 - val_mse: 0.1096 - val_r2_score: 0.0608 - val_rmse: 0.3311 - val_smape: 104.8960\n",
      "Epoch 103/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - loss: 0.4107 - mae: 0.6902 - mse: 51.8944 - r2_score: 0.5639 - rmse: 1.6695 - smape: 98.5064 - val_loss: 0.0834 - val_mae: 0.2031 - val_mse: 0.1117 - val_r2_score: 0.0427 - val_rmse: 0.3343 - val_smape: 116.7628\n",
      "Epoch 104/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - loss: 0.4078 - mae: 0.6922 - mse: 51.8081 - r2_score: 0.5655 - rmse: 1.6684 - smape: 102.8775 - val_loss: 0.0828 - val_mae: 0.1994 - val_mse: 0.1103 - val_r2_score: 0.0549 - val_rmse: 0.3321 - val_smape: 104.2996\n",
      "Epoch 105/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.4205 - mae: 0.7046 - mse: 51.7912 - r2_score: 0.5323 - rmse: 1.6991 - smape: 100.7354 - val_loss: 0.0833 - val_mae: 0.1983 - val_mse: 0.1113 - val_r2_score: 0.0462 - val_rmse: 0.3337 - val_smape: 104.9493\n",
      "Epoch 106/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 0.4173 - mae: 0.7037 - mse: 51.6416 - r2_score: 0.5450 - rmse: 1.6905 - smape: 102.2948 - val_loss: 0.0837 - val_mae: 0.2000 - val_mse: 0.1118 - val_r2_score: 0.0419 - val_rmse: 0.3344 - val_smape: 109.3769\n",
      "Epoch 107/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 0.4020 - mae: 0.6816 - mse: 51.7273 - r2_score: 0.5737 - rmse: 1.6628 - smape: 97.7890 - val_loss: 0.0837 - val_mae: 0.2037 - val_mse: 0.1120 - val_r2_score: 0.0404 - val_rmse: 0.3347 - val_smape: 117.1061\n",
      "Epoch 108/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.4079 - mae: 0.6842 - mse: 51.7128 - r2_score: 0.5595 - rmse: 1.6730 - smape: 98.1532 - val_loss: 0.0842 - val_mae: 0.2021 - val_mse: 0.1130 - val_r2_score: 0.0321 - val_rmse: 0.3361 - val_smape: 111.0022\n",
      "Epoch 109/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 0.4129 - mae: 0.6949 - mse: 51.9149 - r2_score: 0.5611 - rmse: 1.6791 - smape: 100.4844 - val_loss: 0.0844 - val_mae: 0.2039 - val_mse: 0.1130 - val_r2_score: 0.0318 - val_rmse: 0.3362 - val_smape: 117.6735\n",
      "Epoch 110/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 103ms/step - loss: 0.4128 - mae: 0.6953 - mse: 51.9040 - r2_score: 0.5524 - rmse: 1.6877 - smape: 99.3608 - val_loss: 0.0843 - val_mae: 0.2022 - val_mse: 0.1127 - val_r2_score: 0.0348 - val_rmse: 0.3356 - val_smape: 111.8642\n",
      "Epoch 111/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 99ms/step - loss: 0.3994 - mae: 0.6788 - mse: 51.4340 - r2_score: 0.5757 - rmse: 1.6661 - smape: 96.9759 - val_loss: 0.0840 - val_mae: 0.2008 - val_mse: 0.1119 - val_r2_score: 0.0408 - val_rmse: 0.3346 - val_smape: 106.8413\n",
      "Epoch 112/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - loss: 0.4128 - mae: 0.6957 - mse: 51.7383 - r2_score: 0.5502 - rmse: 1.6958 - smape: 100.8808 - val_loss: 0.0833 - val_mae: 0.1983 - val_mse: 0.1106 - val_r2_score: 0.0521 - val_rmse: 0.3326 - val_smape: 105.4797\n",
      "Epoch 113/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.4002 - mae: 0.6813 - mse: 51.3929 - r2_score: 0.5793 - rmse: 1.6509 - smape: 97.9895 - val_loss: 0.0840 - val_mae: 0.2030 - val_mse: 0.1118 - val_r2_score: 0.0422 - val_rmse: 0.3343 - val_smape: 115.4659\n",
      "Epoch 114/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - loss: 0.4004 - mae: 0.6813 - mse: 51.6652 - r2_score: 0.5750 - rmse: 1.6541 - smape: 98.5039 - val_loss: 0.0841 - val_mae: 0.2012 - val_mse: 0.1121 - val_r2_score: 0.0398 - val_rmse: 0.3348 - val_smape: 111.7819\n",
      "Epoch 115/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - loss: 0.4053 - mae: 0.6867 - mse: 51.6626 - r2_score: 0.5704 - rmse: 1.6619 - smape: 99.0405 - val_loss: 0.0843 - val_mae: 0.1980 - val_mse: 0.1122 - val_r2_score: 0.0385 - val_rmse: 0.3350 - val_smape: 103.4495\n",
      "Epoch 116/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 0.4017 - mae: 0.6806 - mse: 51.5426 - r2_score: 0.5831 - rmse: 1.6341 - smape: 98.2095 - val_loss: 0.0846 - val_mae: 0.2003 - val_mse: 0.1129 - val_r2_score: 0.0328 - val_rmse: 0.3360 - val_smape: 109.1869\n",
      "Epoch 117/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - loss: 0.3938 - mae: 0.6676 - mse: 51.1706 - r2_score: 0.5792 - rmse: 1.6447 - smape: 97.3255 - val_loss: 0.0844 - val_mae: 0.1982 - val_mse: 0.1123 - val_r2_score: 0.0382 - val_rmse: 0.3350 - val_smape: 102.4232\n",
      "Epoch 118/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 120ms/step - loss: 0.4078 - mae: 0.6892 - mse: 51.6046 - r2_score: 0.5640 - rmse: 1.6725 - smape: 98.3064 - val_loss: 0.0842 - val_mae: 0.1994 - val_mse: 0.1118 - val_r2_score: 0.0418 - val_rmse: 0.3344 - val_smape: 106.4133\n",
      "Epoch 119/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - loss: 0.3981 - mae: 0.6765 - mse: 51.7926 - r2_score: 0.5736 - rmse: 1.6597 - smape: 98.1775 - val_loss: 0.0840 - val_mae: 0.2003 - val_mse: 0.1113 - val_r2_score: 0.0462 - val_rmse: 0.3336 - val_smape: 107.9812\n",
      "Epoch 120/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 127ms/step - loss: 0.3921 - mae: 0.6649 - mse: 51.6530 - r2_score: 0.5873 - rmse: 1.6382 - smape: 96.3711 - val_loss: 0.0829 - val_mae: 0.1957 - val_mse: 0.1088 - val_r2_score: 0.0675 - val_rmse: 0.3299 - val_smape: 103.2490\n",
      "Epoch 121/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 117ms/step - loss: 0.3976 - mae: 0.6779 - mse: 51.7517 - r2_score: 0.5817 - rmse: 1.6450 - smape: 97.7719 - val_loss: 0.0847 - val_mae: 0.1961 - val_mse: 0.1126 - val_r2_score: 0.0352 - val_rmse: 0.3356 - val_smape: 99.8125\n",
      "Epoch 122/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - loss: 0.3934 - mae: 0.6701 - mse: 51.3569 - r2_score: 0.5918 - rmse: 1.6257 - smape: 96.6035 - val_loss: 0.0848 - val_mae: 0.2068 - val_mse: 0.1129 - val_r2_score: 0.0327 - val_rmse: 0.3360 - val_smape: 125.2510\n",
      "Epoch 123/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 0.4066 - mae: 0.6900 - mse: 51.9757 - r2_score: 0.5587 - rmse: 1.6806 - smape: 100.9218 - val_loss: 0.0840 - val_mae: 0.1940 - val_mse: 0.1112 - val_r2_score: 0.0474 - val_rmse: 0.3334 - val_smape: 97.6130\n",
      "Epoch 124/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 0.4034 - mae: 0.6820 - mse: 51.5251 - r2_score: 0.5761 - rmse: 1.6604 - smape: 99.2000 - val_loss: 0.0845 - val_mae: 0.1950 - val_mse: 0.1119 - val_r2_score: 0.0409 - val_rmse: 0.3346 - val_smape: 98.6705\n",
      "Epoch 125/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - loss: 0.3997 - mae: 0.6784 - mse: 51.7810 - r2_score: 0.5694 - rmse: 1.6648 - smape: 97.9295 - val_loss: 0.0845 - val_mae: 0.1920 - val_mse: 0.1119 - val_r2_score: 0.0414 - val_rmse: 0.3345 - val_smape: 91.9455\n",
      "Epoch 126/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 0.3948 - mae: 0.6726 - mse: 51.1738 - r2_score: 0.5830 - rmse: 1.6421 - smape: 97.9644 - val_loss: 0.0851 - val_mae: 0.1936 - val_mse: 0.1132 - val_r2_score: 0.0299 - val_rmse: 0.3365 - val_smape: 93.4406\n",
      "Epoch 127/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.3965 - mae: 0.6742 - mse: 51.5177 - r2_score: 0.5899 - rmse: 1.6395 - smape: 97.8679 - val_loss: 0.0844 - val_mae: 0.1892 - val_mse: 0.1115 - val_r2_score: 0.0449 - val_rmse: 0.3339 - val_smape: 88.6044\n",
      "Epoch 128/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.3922 - mae: 0.6716 - mse: 51.5315 - r2_score: 0.5931 - rmse: 1.6335 - smape: 97.9206 - val_loss: 0.0850 - val_mae: 0.1946 - val_mse: 0.1126 - val_r2_score: 0.0350 - val_rmse: 0.3356 - val_smape: 98.6712\n",
      "Epoch 129/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.3979 - mae: 0.6773 - mse: 51.1645 - r2_score: 0.5847 - rmse: 1.6402 - smape: 97.3618 - val_loss: 0.0849 - val_mae: 0.1938 - val_mse: 0.1121 - val_r2_score: 0.0392 - val_rmse: 0.3349 - val_smape: 95.0009\n",
      "Epoch 130/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.3936 - mae: 0.6665 - mse: 51.3156 - r2_score: 0.5724 - rmse: 1.6539 - smape: 97.1365 - val_loss: 0.0849 - val_mae: 0.1917 - val_mse: 0.1123 - val_r2_score: 0.0378 - val_rmse: 0.3351 - val_smape: 90.9460\n",
      "Epoch 131/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 0.3894 - mae: 0.6651 - mse: 50.6723 - r2_score: 0.5894 - rmse: 1.6257 - smape: 95.9482 - val_loss: 0.0858 - val_mae: 0.1930 - val_mse: 0.1141 - val_r2_score: 0.0224 - val_rmse: 0.3378 - val_smape: 90.7256\n",
      "Epoch 132/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - loss: 0.3965 - mae: 0.6746 - mse: 51.5583 - r2_score: 0.5784 - rmse: 1.6459 - smape: 97.8261 - val_loss: 0.0861 - val_mae: 0.1974 - val_mse: 0.1147 - val_r2_score: 0.0176 - val_rmse: 0.3386 - val_smape: 99.7715\n",
      "Epoch 133/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - loss: 0.4052 - mae: 0.6864 - mse: 51.3417 - r2_score: 0.5720 - rmse: 1.6600 - smape: 99.7850 - val_loss: 0.0860 - val_mae: 0.1933 - val_mse: 0.1145 - val_r2_score: 0.0186 - val_rmse: 0.3384 - val_smape: 94.9619\n",
      "Epoch 134/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - loss: 0.3964 - mae: 0.6768 - mse: 51.9687 - r2_score: 0.5869 - rmse: 1.6449 - smape: 98.3118 - val_loss: 0.0856 - val_mae: 0.1936 - val_mse: 0.1132 - val_r2_score: 0.0299 - val_rmse: 0.3365 - val_smape: 93.0092\n",
      "Epoch 135/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 0.3967 - mae: 0.6784 - mse: 51.6313 - r2_score: 0.5859 - rmse: 1.6395 - smape: 100.0832 - val_loss: 0.0863 - val_mae: 0.1956 - val_mse: 0.1147 - val_r2_score: 0.0177 - val_rmse: 0.3386 - val_smape: 95.7391\n",
      "Epoch 136/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 0.3883 - mae: 0.6631 - mse: 51.8735 - r2_score: 0.5899 - rmse: 1.6417 - smape: 96.7316 - val_loss: 0.0857 - val_mae: 0.1911 - val_mse: 0.1133 - val_r2_score: 0.0290 - val_rmse: 0.3366 - val_smape: 86.2995\n",
      "Epoch 137/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.3901 - mae: 0.6631 - mse: 51.3986 - r2_score: 0.5801 - rmse: 1.6398 - smape: 95.5827 - val_loss: 0.0858 - val_mae: 0.1933 - val_mse: 0.1136 - val_r2_score: 0.0264 - val_rmse: 0.3371 - val_smape: 89.6179\n",
      "Epoch 138/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - loss: 0.3943 - mae: 0.6739 - mse: 51.8296 - r2_score: 0.5838 - rmse: 1.6485 - smape: 97.1544 - val_loss: 0.0864 - val_mae: 0.1987 - val_mse: 0.1145 - val_r2_score: 0.0192 - val_rmse: 0.3383 - val_smape: 104.8057\n",
      "Epoch 139/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - loss: 0.3845 - mae: 0.6630 - mse: 51.2803 - r2_score: 0.6099 - rmse: 1.6142 - smape: 96.0923 - val_loss: 0.0853 - val_mae: 0.1978 - val_mse: 0.1123 - val_r2_score: 0.0376 - val_rmse: 0.3351 - val_smape: 107.5259\n",
      "Epoch 140/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 0.3907 - mae: 0.6660 - mse: 51.4809 - r2_score: 0.5989 - rmse: 1.6265 - smape: 96.9954 - val_loss: 0.0854 - val_mae: 0.1961 - val_mse: 0.1124 - val_r2_score: 0.0372 - val_rmse: 0.3352 - val_smape: 100.4411\n",
      "Epoch 141/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - loss: 0.3951 - mae: 0.6707 - mse: 51.4340 - r2_score: 0.5881 - rmse: 1.6339 - smape: 96.3044 - val_loss: 0.0850 - val_mae: 0.1945 - val_mse: 0.1114 - val_r2_score: 0.0454 - val_rmse: 0.3338 - val_smape: 98.0253\n",
      "Epoch 142/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - loss: 0.3916 - mae: 0.6681 - mse: 51.2077 - r2_score: 0.5956 - rmse: 1.6243 - smape: 98.3561 - val_loss: 0.0847 - val_mae: 0.1949 - val_mse: 0.1107 - val_r2_score: 0.0513 - val_rmse: 0.3328 - val_smape: 100.4219\n",
      "Epoch 143/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.3882 - mae: 0.6658 - mse: 51.4355 - r2_score: 0.6021 - rmse: 1.6130 - smape: 96.9141 - val_loss: 0.0860 - val_mae: 0.1989 - val_mse: 0.1133 - val_r2_score: 0.0291 - val_rmse: 0.3366 - val_smape: 102.9586\n",
      "Epoch 144/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.3922 - mae: 0.6647 - mse: 51.4916 - r2_score: 0.5884 - rmse: 1.6501 - smape: 95.9947 - val_loss: 0.0849 - val_mae: 0.1976 - val_mse: 0.1110 - val_r2_score: 0.0491 - val_rmse: 0.3331 - val_smape: 101.2261\n",
      "Epoch 145/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.3864 - mae: 0.6605 - mse: 50.8344 - r2_score: 0.5903 - rmse: 1.6284 - smape: 96.6260 - val_loss: 0.0857 - val_mae: 0.1976 - val_mse: 0.1126 - val_r2_score: 0.0355 - val_rmse: 0.3355 - val_smape: 98.4331\n",
      "Epoch 146/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.3881 - mae: 0.6630 - mse: 50.7915 - r2_score: 0.6001 - rmse: 1.6158 - smape: 96.2582 - val_loss: 0.0852 - val_mae: 0.1977 - val_mse: 0.1113 - val_r2_score: 0.0465 - val_rmse: 0.3336 - val_smape: 101.8757\n",
      "Epoch 147/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.3883 - mae: 0.6673 - mse: 51.2723 - r2_score: 0.6021 - rmse: 1.6226 - smape: 96.5196 - val_loss: 0.0857 - val_mae: 0.1987 - val_mse: 0.1127 - val_r2_score: 0.0347 - val_rmse: 0.3357 - val_smape: 103.4795\n",
      "Epoch 148/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.3978 - mae: 0.6753 - mse: 51.5464 - r2_score: 0.5819 - rmse: 1.6504 - smape: 97.5867 - val_loss: 0.0852 - val_mae: 0.1979 - val_mse: 0.1114 - val_r2_score: 0.0451 - val_rmse: 0.3338 - val_smape: 101.6998\n",
      "Epoch 149/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - loss: 0.3916 - mae: 0.6617 - mse: 51.1669 - r2_score: 0.5893 - rmse: 1.6376 - smape: 96.6114 - val_loss: 0.0861 - val_mae: 0.2047 - val_mse: 0.1131 - val_r2_score: 0.0308 - val_rmse: 0.3363 - val_smape: 116.8068\n",
      "Epoch 150/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.3764 - mae: 0.6474 - mse: 51.6583 - r2_score: 0.6299 - rmse: 1.5957 - smape: 92.9866 - val_loss: 0.0859 - val_mae: 0.2058 - val_mse: 0.1128 - val_r2_score: 0.0339 - val_rmse: 0.3358 - val_smape: 119.0835\n",
      "Epoch 151/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.3825 - mae: 0.6587 - mse: 51.2813 - r2_score: 0.6080 - rmse: 1.6079 - smape: 97.1363 - val_loss: 0.0852 - val_mae: 0.2028 - val_mse: 0.1112 - val_r2_score: 0.0472 - val_rmse: 0.3335 - val_smape: 115.2820\n",
      "Epoch 152/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - loss: 0.3795 - mae: 0.6553 - mse: 51.1615 - r2_score: 0.6140 - rmse: 1.6088 - smape: 95.0585 - val_loss: 0.0854 - val_mae: 0.1949 - val_mse: 0.1115 - val_r2_score: 0.0450 - val_rmse: 0.3339 - val_smape: 98.9251\n",
      "Epoch 153/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - loss: 0.3805 - mae: 0.6523 - mse: 51.4478 - r2_score: 0.6093 - rmse: 1.5981 - smape: 95.2066 - val_loss: 0.0856 - val_mae: 0.1975 - val_mse: 0.1119 - val_r2_score: 0.0411 - val_rmse: 0.3345 - val_smape: 103.7592\n",
      "Epoch 154/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - loss: 0.3847 - mae: 0.6551 - mse: 51.4363 - r2_score: 0.5950 - rmse: 1.6268 - smape: 95.4900 - val_loss: 0.0858 - val_mae: 0.1978 - val_mse: 0.1125 - val_r2_score: 0.0365 - val_rmse: 0.3353 - val_smape: 104.3045\n",
      "Epoch 155/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.3823 - mae: 0.6523 - mse: 51.0691 - r2_score: 0.6033 - rmse: 1.6207 - smape: 94.2114 - val_loss: 0.0863 - val_mae: 0.2100 - val_mse: 0.1132 - val_r2_score: 0.0303 - val_rmse: 0.3364 - val_smape: 128.2027\n",
      "Epoch 156/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - loss: 0.3787 - mae: 0.6504 - mse: 51.4515 - r2_score: 0.6101 - rmse: 1.6151 - smape: 95.0535 - val_loss: 0.0855 - val_mae: 0.1999 - val_mse: 0.1116 - val_r2_score: 0.0436 - val_rmse: 0.3341 - val_smape: 108.2715\n",
      "Epoch 157/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.3895 - mae: 0.6598 - mse: 51.1610 - r2_score: 0.5823 - rmse: 1.6522 - smape: 95.2653 - val_loss: 0.0864 - val_mae: 0.2042 - val_mse: 0.1133 - val_r2_score: 0.0295 - val_rmse: 0.3366 - val_smape: 115.0533\n",
      "Epoch 158/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.3849 - mae: 0.6616 - mse: 51.1989 - r2_score: 0.6047 - rmse: 1.6140 - smape: 97.3979 - val_loss: 0.0873 - val_mae: 0.1979 - val_mse: 0.1150 - val_r2_score: 0.0146 - val_rmse: 0.3391 - val_smape: 98.0528\n",
      "Epoch 159/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 80ms/step - loss: 0.3898 - mae: 0.6639 - mse: 51.2429 - r2_score: 0.6006 - rmse: 1.6232 - smape: 96.7759 - val_loss: 0.0880 - val_mae: 0.2046 - val_mse: 0.1165 - val_r2_score: 0.0020 - val_rmse: 0.3413 - val_smape: 113.3419\n",
      "Epoch 160/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - loss: 0.3807 - mae: 0.6485 - mse: 51.3043 - r2_score: 0.6078 - rmse: 1.6177 - smape: 93.9741 - val_loss: 0.0866 - val_mae: 0.1989 - val_mse: 0.1133 - val_r2_score: 0.0293 - val_rmse: 0.3366 - val_smape: 104.8773\n",
      "Epoch 161/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 0.3928 - mae: 0.6721 - mse: 50.9309 - r2_score: 0.5898 - rmse: 1.6245 - smape: 98.0986 - val_loss: 0.0877 - val_mae: 0.2048 - val_mse: 0.1156 - val_r2_score: 0.0099 - val_rmse: 0.3399 - val_smape: 113.6721\n",
      "Epoch 162/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.3835 - mae: 0.6565 - mse: 51.1228 - r2_score: 0.6001 - rmse: 1.6173 - smape: 95.9023 - val_loss: 0.0868 - val_mae: 0.1975 - val_mse: 0.1136 - val_r2_score: 0.0265 - val_rmse: 0.3371 - val_smape: 99.2452\n",
      "Epoch 163/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.3996 - mae: 0.6787 - mse: 51.0043 - r2_score: 0.5794 - rmse: 1.6488 - smape: 98.0846 - val_loss: 0.0862 - val_mae: 0.1961 - val_mse: 0.1125 - val_r2_score: 0.0362 - val_rmse: 0.3354 - val_smape: 100.8187\n",
      "Epoch 164/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.3780 - mae: 0.6521 - mse: 51.4193 - r2_score: 0.6216 - rmse: 1.5927 - smape: 95.5060 - val_loss: 0.0857 - val_mae: 0.1958 - val_mse: 0.1113 - val_r2_score: 0.0467 - val_rmse: 0.3336 - val_smape: 102.0914\n",
      "Epoch 165/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - loss: 0.3836 - mae: 0.6585 - mse: 51.1753 - r2_score: 0.6098 - rmse: 1.6075 - smape: 95.1702 - val_loss: 0.0843 - val_mae: 0.1978 - val_mse: 0.1084 - val_r2_score: 0.0711 - val_rmse: 0.3293 - val_smape: 110.8472\n",
      "Epoch 166/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 0.3802 - mae: 0.6560 - mse: 51.3440 - r2_score: 0.6215 - rmse: 1.5897 - smape: 97.0914 - val_loss: 0.0851 - val_mae: 0.1992 - val_mse: 0.1102 - val_r2_score: 0.0559 - val_rmse: 0.3319 - val_smape: 108.9728\n",
      "Epoch 167/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 119ms/step - loss: 0.3898 - mae: 0.6666 - mse: 51.1959 - r2_score: 0.5956 - rmse: 1.6343 - smape: 97.1601 - val_loss: 0.0856 - val_mae: 0.1937 - val_mse: 0.1110 - val_r2_score: 0.0487 - val_rmse: 0.3332 - val_smape: 92.1162\n",
      "Epoch 168/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - loss: 0.3894 - mae: 0.6666 - mse: 51.4452 - r2_score: 0.5974 - rmse: 1.6229 - smape: 97.0966 - val_loss: 0.0858 - val_mae: 0.1942 - val_mse: 0.1112 - val_r2_score: 0.0472 - val_rmse: 0.3335 - val_smape: 96.0022\n",
      "Epoch 169/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.3892 - mae: 0.6633 - mse: 51.4988 - r2_score: 0.6040 - rmse: 1.6250 - smape: 95.3208 - val_loss: 0.0867 - val_mae: 0.1937 - val_mse: 0.1130 - val_r2_score: 0.0316 - val_rmse: 0.3362 - val_smape: 92.6805\n",
      "Epoch 170/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.3790 - mae: 0.6556 - mse: 51.5245 - r2_score: 0.6185 - rmse: 1.5931 - smape: 96.1299 - val_loss: 0.0856 - val_mae: 0.1956 - val_mse: 0.1105 - val_r2_score: 0.0531 - val_rmse: 0.3324 - val_smape: 102.9445\n",
      "Epoch 171/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 117ms/step - loss: 0.3756 - mae: 0.6477 - mse: 51.2556 - r2_score: 0.6137 - rmse: 1.6037 - smape: 95.0567 - val_loss: 0.0849 - val_mae: 0.1894 - val_mse: 0.1091 - val_r2_score: 0.0655 - val_rmse: 0.3303 - val_smape: 90.6538\n",
      "Epoch 172/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 116ms/step - loss: 0.3821 - mae: 0.6547 - mse: 51.3704 - r2_score: 0.6121 - rmse: 1.5942 - smape: 94.7434 - val_loss: 0.0842 - val_mae: 0.1900 - val_mse: 0.1073 - val_r2_score: 0.0804 - val_rmse: 0.3276 - val_smape: 92.8818\n",
      "Epoch 173/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - loss: 0.3902 - mae: 0.6658 - mse: 51.2880 - r2_score: 0.5947 - rmse: 1.6192 - smape: 95.1045 - val_loss: 0.0844 - val_mae: 0.1894 - val_mse: 0.1075 - val_r2_score: 0.0786 - val_rmse: 0.3279 - val_smape: 90.4578\n",
      "Epoch 174/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 117ms/step - loss: 0.3900 - mae: 0.6636 - mse: 51.4693 - r2_score: 0.5988 - rmse: 1.6215 - smape: 95.8281 - val_loss: 0.0850 - val_mae: 0.1877 - val_mse: 0.1089 - val_r2_score: 0.0667 - val_rmse: 0.3300 - val_smape: 88.9497\n",
      "Epoch 175/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - loss: 0.3765 - mae: 0.6482 - mse: 50.8522 - r2_score: 0.6298 - rmse: 1.5754 - smape: 94.5156 - val_loss: 0.0854 - val_mae: 0.1886 - val_mse: 0.1098 - val_r2_score: 0.0596 - val_rmse: 0.3313 - val_smape: 94.7881\n",
      "Epoch 176/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 0.3927 - mae: 0.6672 - mse: 51.4618 - r2_score: 0.5944 - rmse: 1.6285 - smape: 96.0008 - val_loss: 0.0852 - val_mae: 0.1883 - val_mse: 0.1094 - val_r2_score: 0.0629 - val_rmse: 0.3307 - val_smape: 93.3871\n",
      "Epoch 177/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - loss: 0.3815 - mae: 0.6541 - mse: 51.3953 - r2_score: 0.6215 - rmse: 1.5998 - smape: 95.5798 - val_loss: 0.0851 - val_mae: 0.1908 - val_mse: 0.1090 - val_r2_score: 0.0661 - val_rmse: 0.3302 - val_smape: 96.5336\n",
      "Epoch 178/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 142ms/step - loss: 0.3800 - mae: 0.6510 - mse: 51.1278 - r2_score: 0.6112 - rmse: 1.6063 - smape: 94.5899 - val_loss: 0.0870 - val_mae: 0.1942 - val_mse: 0.1132 - val_r2_score: 0.0301 - val_rmse: 0.3365 - val_smape: 103.8419\n",
      "Epoch 179/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - loss: 0.3736 - mae: 0.6437 - mse: 50.4490 - r2_score: 0.6256 - rmse: 1.5954 - smape: 93.3294 - val_loss: 0.0858 - val_mae: 0.1882 - val_mse: 0.1108 - val_r2_score: 0.0508 - val_rmse: 0.3328 - val_smape: 92.6003\n",
      "Epoch 180/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 146ms/step - loss: 0.3838 - mae: 0.6567 - mse: 51.2779 - r2_score: 0.6191 - rmse: 1.5920 - smape: 95.0607 - val_loss: 0.0862 - val_mae: 0.1860 - val_mse: 0.1116 - val_r2_score: 0.0442 - val_rmse: 0.3340 - val_smape: 87.8396\n",
      "Epoch 181/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 144ms/step - loss: 0.3766 - mae: 0.6442 - mse: 51.5026 - r2_score: 0.6150 - rmse: 1.6122 - smape: 93.6100 - val_loss: 0.0849 - val_mae: 0.1884 - val_mse: 0.1086 - val_r2_score: 0.0697 - val_rmse: 0.3295 - val_smape: 98.0729\n",
      "Epoch 182/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - loss: 0.3808 - mae: 0.6527 - mse: 50.7408 - r2_score: 0.6158 - rmse: 1.5963 - smape: 93.6597 - val_loss: 0.0862 - val_mae: 0.1866 - val_mse: 0.1113 - val_r2_score: 0.0464 - val_rmse: 0.3336 - val_smape: 90.2829\n",
      "Epoch 183/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - loss: 0.3817 - mae: 0.6539 - mse: 51.1726 - r2_score: 0.6181 - rmse: 1.5908 - smape: 95.3129 - val_loss: 0.0847 - val_mae: 0.1869 - val_mse: 0.1082 - val_r2_score: 0.0729 - val_rmse: 0.3290 - val_smape: 95.7391\n",
      "Epoch 184/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 133ms/step - loss: 0.3781 - mae: 0.6504 - mse: 51.3105 - r2_score: 0.6279 - rmse: 1.5920 - smape: 95.4770 - val_loss: 0.0868 - val_mae: 0.1912 - val_mse: 0.1123 - val_r2_score: 0.0379 - val_rmse: 0.3351 - val_smape: 92.7063\n",
      "Epoch 185/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 136ms/step - loss: 0.3694 - mae: 0.6381 - mse: 51.5392 - r2_score: 0.6338 - rmse: 1.5836 - smape: 94.2429 - val_loss: 0.0881 - val_mae: 0.1948 - val_mse: 0.1151 - val_r2_score: 0.0141 - val_rmse: 0.3392 - val_smape: 91.3973\n",
      "Epoch 186/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - loss: 0.3659 - mae: 0.6293 - mse: 51.3214 - r2_score: 0.6353 - rmse: 1.5906 - smape: 92.9944 - val_loss: 0.0863 - val_mae: 0.1931 - val_mse: 0.1109 - val_r2_score: 0.0497 - val_rmse: 0.3330 - val_smape: 101.5693\n",
      "Epoch 187/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 158ms/step - loss: 0.3700 - mae: 0.6376 - mse: 50.9007 - r2_score: 0.6361 - rmse: 1.5675 - smape: 93.6063 - val_loss: 0.0903 - val_mae: 0.1989 - val_mse: 0.1210 - val_r2_score: -0.0368 - val_rmse: 0.3479 - val_smape: 99.5393\n",
      "Epoch 188/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 120ms/step - loss: 0.3848 - mae: 0.6588 - mse: 50.8794 - r2_score: 0.6025 - rmse: 1.6236 - smape: 96.2247 - val_loss: 0.0905 - val_mae: 0.1995 - val_mse: 0.1201 - val_r2_score: -0.0291 - val_rmse: 0.3466 - val_smape: 97.7714\n",
      "Epoch 189/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step - loss: 0.3765 - mae: 0.6440 - mse: 51.5294 - r2_score: 0.6247 - rmse: 1.5966 - smape: 93.3291 - val_loss: 0.0861 - val_mae: 0.1919 - val_mse: 0.1105 - val_r2_score: 0.0532 - val_rmse: 0.3324 - val_smape: 97.3856\n",
      "Epoch 190/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 128ms/step - loss: 0.3696 - mae: 0.6364 - mse: 51.2067 - r2_score: 0.6285 - rmse: 1.5875 - smape: 92.2034 - val_loss: 0.0875 - val_mae: 0.1921 - val_mse: 0.1136 - val_r2_score: 0.0268 - val_rmse: 0.3370 - val_smape: 90.0506\n",
      "Epoch 191/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 143ms/step - loss: 0.3749 - mae: 0.6444 - mse: 51.1965 - r2_score: 0.6273 - rmse: 1.5945 - smape: 95.4881 - val_loss: 0.0866 - val_mae: 0.1899 - val_mse: 0.1112 - val_r2_score: 0.0472 - val_rmse: 0.3335 - val_smape: 89.4581\n",
      "Epoch 192/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - loss: 0.3690 - mae: 0.6360 - mse: 51.4140 - r2_score: 0.6419 - rmse: 1.5785 - smape: 93.2813 - val_loss: 0.0868 - val_mae: 0.1922 - val_mse: 0.1117 - val_r2_score: 0.0428 - val_rmse: 0.3342 - val_smape: 90.8763\n",
      "Epoch 193/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - loss: 0.3726 - mae: 0.6398 - mse: 51.5672 - r2_score: 0.6296 - rmse: 1.5849 - smape: 93.7326 - val_loss: 0.0870 - val_mae: 0.1919 - val_mse: 0.1119 - val_r2_score: 0.0413 - val_rmse: 0.3345 - val_smape: 88.7521\n",
      "Epoch 194/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 96ms/step - loss: 0.3856 - mae: 0.6589 - mse: 51.0720 - r2_score: 0.6140 - rmse: 1.6006 - smape: 95.6751 - val_loss: 0.0863 - val_mae: 0.1867 - val_mse: 0.1105 - val_r2_score: 0.0530 - val_rmse: 0.3325 - val_smape: 82.2279\n",
      "Epoch 195/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - loss: 0.3617 - mae: 0.6320 - mse: 50.9004 - r2_score: 0.6492 - rmse: 1.5498 - smape: 93.4932 - val_loss: 0.0860 - val_mae: 0.1939 - val_mse: 0.1097 - val_r2_score: 0.0605 - val_rmse: 0.3311 - val_smape: 101.3041\n",
      "Epoch 196/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - loss: 0.3691 - mae: 0.6352 - mse: 50.7054 - r2_score: 0.6425 - rmse: 1.5601 - smape: 93.2260 - val_loss: 0.0872 - val_mae: 0.1930 - val_mse: 0.1123 - val_r2_score: 0.0380 - val_rmse: 0.3351 - val_smape: 92.1039\n",
      "Epoch 197/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - loss: 0.3757 - mae: 0.6468 - mse: 51.0418 - r2_score: 0.6321 - rmse: 1.5734 - smape: 94.8019 - val_loss: 0.0865 - val_mae: 0.1919 - val_mse: 0.1105 - val_r2_score: 0.0529 - val_rmse: 0.3325 - val_smape: 92.3728\n",
      "Epoch 198/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - loss: 0.3695 - mae: 0.6401 - mse: 50.6293 - r2_score: 0.6315 - rmse: 1.5758 - smape: 93.9710 - val_loss: 0.0853 - val_mae: 0.1883 - val_mse: 0.1079 - val_r2_score: 0.0753 - val_rmse: 0.3285 - val_smape: 86.2836\n",
      "Epoch 199/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 144ms/step - loss: 0.3701 - mae: 0.6363 - mse: 51.2012 - r2_score: 0.6338 - rmse: 1.5817 - smape: 92.1724 - val_loss: 0.0894 - val_mae: 0.1960 - val_mse: 0.1168 - val_r2_score: -0.0010 - val_rmse: 0.3418 - val_smape: 90.5932\n",
      "Epoch 200/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 142ms/step - loss: 0.3645 - mae: 0.6315 - mse: 50.9592 - r2_score: 0.6461 - rmse: 1.5571 - smape: 91.5271 - val_loss: 0.0880 - val_mae: 0.1938 - val_mse: 0.1137 - val_r2_score: 0.0257 - val_rmse: 0.3372 - val_smape: 89.8649\n",
      "Epoch 201/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - loss: 0.3694 - mae: 0.6346 - mse: 50.9084 - r2_score: 0.6290 - rmse: 1.5712 - smape: 94.2570 - val_loss: 0.0866 - val_mae: 0.1973 - val_mse: 0.1110 - val_r2_score: 0.0491 - val_rmse: 0.3331 - val_smape: 97.8305\n",
      "Epoch 202/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - loss: 0.3778 - mae: 0.6493 - mse: 51.0792 - r2_score: 0.6231 - rmse: 1.5855 - smape: 93.9459 - val_loss: 0.0897 - val_mae: 0.2103 - val_mse: 0.1175 - val_r2_score: -0.0066 - val_rmse: 0.3428 - val_smape: 119.4461\n",
      "Epoch 203/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 122ms/step - loss: 0.3620 - mae: 0.6292 - mse: 50.8963 - r2_score: 0.6527 - rmse: 1.5502 - smape: 91.7632 - val_loss: 0.0931 - val_mae: 0.2148 - val_mse: 0.1241 - val_r2_score: -0.0629 - val_rmse: 0.3522 - val_smape: 113.7720\n",
      "Epoch 204/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 0.3688 - mae: 0.6361 - mse: 50.6613 - r2_score: 0.6425 - rmse: 1.5514 - smape: 92.4330 - val_loss: 0.0915 - val_mae: 0.2049 - val_mse: 0.1208 - val_r2_score: -0.0347 - val_rmse: 0.3475 - val_smape: 97.6144\n",
      "Epoch 205/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 137ms/step - loss: 0.3606 - mae: 0.6248 - mse: 51.0955 - r2_score: 0.6593 - rmse: 1.5442 - smape: 90.8658 - val_loss: 0.0920 - val_mae: 0.2154 - val_mse: 0.1215 - val_r2_score: -0.0407 - val_rmse: 0.3485 - val_smape: 116.9279\n",
      "Epoch 206/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 116ms/step - loss: 0.3697 - mae: 0.6322 - mse: 50.8648 - r2_score: 0.6321 - rmse: 1.5757 - smape: 92.0818 - val_loss: 0.0905 - val_mae: 0.2150 - val_mse: 0.1180 - val_r2_score: -0.0113 - val_rmse: 0.3436 - val_smape: 118.3433\n",
      "Epoch 207/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 136ms/step - loss: 0.3684 - mae: 0.6377 - mse: 51.2314 - r2_score: 0.6402 - rmse: 1.5809 - smape: 93.3914 - val_loss: 0.0896 - val_mae: 0.2059 - val_mse: 0.1168 - val_r2_score: -3.5405e-04 - val_rmse: 0.3417 - val_smape: 112.2821\n",
      "Epoch 208/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - loss: 0.3696 - mae: 0.6371 - mse: 51.3127 - r2_score: 0.6300 - rmse: 1.5829 - smape: 93.9047 - val_loss: 0.0909 - val_mae: 0.2141 - val_mse: 0.1197 - val_r2_score: -0.0252 - val_rmse: 0.3459 - val_smape: 120.2709\n",
      "Epoch 209/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - loss: 0.3699 - mae: 0.6458 - mse: 50.5924 - r2_score: 0.6413 - rmse: 1.5624 - smape: 95.1691 - val_loss: 0.0889 - val_mae: 0.2012 - val_mse: 0.1152 - val_r2_score: 0.0126 - val_rmse: 0.3395 - val_smape: 100.0151\n",
      "Epoch 210/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 146ms/step - loss: 0.3760 - mae: 0.6434 - mse: 50.9318 - r2_score: 0.6203 - rmse: 1.5884 - smape: 92.5912 - val_loss: 0.0897 - val_mae: 0.2093 - val_mse: 0.1170 - val_r2_score: -0.0020 - val_rmse: 0.3420 - val_smape: 111.2625\n",
      "Epoch 211/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 127ms/step - loss: 0.3644 - mae: 0.6330 - mse: 50.8371 - r2_score: 0.6493 - rmse: 1.5498 - smape: 93.9040 - val_loss: 0.0953 - val_mae: 0.2263 - val_mse: 0.1287 - val_r2_score: -0.1026 - val_rmse: 0.3587 - val_smape: 124.7284\n",
      "Epoch 212/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - loss: 0.3678 - mae: 0.6386 - mse: 50.7233 - r2_score: 0.6509 - rmse: 1.5504 - smape: 94.4307 - val_loss: 0.0942 - val_mae: 0.2204 - val_mse: 0.1258 - val_r2_score: -0.0777 - val_rmse: 0.3547 - val_smape: 115.3006\n",
      "Epoch 213/1000\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - loss: 0.3760 - mae: 0.6441 - mse: 51.5646 - r2_score: 0.6299 - rmse: 1.5893 - smape: 92.8143 - val_loss: 0.0935 - val_mae: 0.2191 - val_mse: 0.1243 - val_r2_score: -0.0650 - val_rmse: 0.3526 - val_smape: 116.9380\n",
      "Epoch 214/1000\n",
      "\u001b[1m24/68\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - loss: 0.2641 - mae: 0.5305 - mse: 1.0120 - r2_score: 0.6861 - rmse: 0.8462 - smape: 86.6508"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "from src.modeling import train\n",
    "\n",
    "train.main(\n",
    "    # ---- REPLACE DEFAULT PATHS AS APPROPRIATE ----\n",
    "    X_path = config.PROCESSED_DATA_DIR / \"X_train.npy\",\n",
    "    y_path = config.PROCESSED_DATA_DIR / \"y_train.npy\",\n",
    "    # -----------------------------------------\n",
    "    optimizer =  None,  # Use default optimizer\n",
    "    loss = None,  # Use default loss\n",
    "    metrics = None,  # Use default metrics\n",
    "    # -----------------------------------------\n",
    "    batch_size = 32,\n",
    "    epochs = 1000,\n",
    "    validation_len = 30,\n",
    "    # -----------------------------------------\n",
    "    experiment_name = \"default_experiment\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6162b6",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "In the prediction stage, the trained model is loaded along with the input data. The model then performs inference, generating predictions based on the provided data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f922aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-25 13:28:53.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.predict\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mPerforming inference for model...\u001b[0m\n",
      "\u001b[32m2025-06-25 13:28:53.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modeling.predict\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mInput data shape: (51, 15)\u001b[0m\n",
      "\u001b[32m2025-06-25 13:28:53.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils.features.generator_strategy\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mGenerating Timeseries from dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repositories\\ds-lstm-ibov\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "            Close_^BVSP       type\n",
      "2025-06-23    -0.004121       True\n",
      "2025-06-24     0.004496       True\n",
      "2025-06-25    -0.000232  Predicted\n",
      "\u001b[32m2025-06-25 13:28:55.044\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36msrc.modeling.predict\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m76\u001b[0m - \u001b[32m\u001b[1mInference complete.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "from src.modeling import predict\n",
    "\n",
    "predict.main(\n",
    "    # ---- REPLACE DEFAULT PATHS AS APPROPRIATE ----\n",
    "    input_path = config.PROCESSED_DATA_DIR / \"dataset.csv\",\n",
    "    preprocessor_path = config.PROCESSED_DATA_DIR / \"preprocessor.pkl\",\n",
    "    model_path = config.MODELS_DIR / \"Sequential_epoch47_loss0.2119.keras\",  # Select the best model  \n",
    "    postprocessor_path = config.PROCESSED_DATA_DIR / \"postprocessor.pkl\",\n",
    "    output_path = config.PROCESSED_DATA_DIR / \"dataset_report.csv\",\n",
    "    length = 50\n",
    "    # -----------------------------------------\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ef876",
   "metadata": {},
   "source": [
    "## Plot\n",
    "\n",
    "Open the [Power BI Report]((../reports/pbi/amp-fynance.pbip)) and refresh data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
