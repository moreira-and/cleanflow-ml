{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import yaml\n",
    "\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-25 20:24:31.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Repositories\\ds-lstm-ibov\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.config import CONFIG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo informações de 2015-04-28 até 2025-04-25\n"
     ]
    }
   ],
   "source": [
    "years = 10\n",
    "dt_start = (dt.datetime.now() - dt.timedelta(days=years*365)).date()\n",
    "dt_end=dt.datetime.now().date()\n",
    "\n",
    "print('Extraindo informações de {} até {}'.format(dt_start, dt_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Caminho do seu arquivo\\nyaml_path = CONFIG_DIR / 'dataset.yaml'\\n\\n# Lê o arquivo YAML\\nwith open(yaml_path, 'r') as file:\\n    config = yaml.safe_load(file)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Caminho do seu arquivo\n",
    "yaml_path = CONFIG_DIR / 'dataset.yaml'\n",
    "\n",
    "# Lê o arquivo YAML\n",
    "with open(yaml_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Baixa os dados do yfinance\\nyf_data = {}\\nfor nome, ticker in config['yfinance']['tickers_code'].items():\\n    print(f'Baixando {nome} ({ticker}) via yfinance...')\\n    df = yf.download(ticker, start=start_date, end=end_date)\\n    yf_data[nome] = df\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Baixa os dados do yfinance\n",
    "yf_data = {}\n",
    "for nome, ticker in config['yfinance']['tickers_code'].items():\n",
    "    print(f'Baixando {nome} ({ticker}) via yfinance...')\n",
    "    df = yf.download(ticker, start=start_date, end=end_date)\n",
    "    yf_data[nome] = df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.dataset_loader import YfinanceLoader\n",
    "# Create an instance of YfinanceLoader with the start and end dates\n",
    "yf_loader = YfinanceLoader(start_date=str(dt_start), end_date=str(dt_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading BOVESPA (^BVSP) from yfinance...\n",
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading ^BVSP: 'function' object has no attribute 'empty'\n",
      "Downloading S&P500 (^GSPC) from yfinance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading ^GSPC: 'function' object has no attribute 'empty'\n",
      "Downloading BITCOIN (BTC-USD) from yfinance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading BTC-USD: 'function' object has no attribute 'empty'\n",
      "Downloading OURO (GC=F) from yfinance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading GC=F: 'function' object has no attribute 'empty'\n",
      "Downloading PETROLEO (CL=F) from yfinance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading CL=F: 'function' object has no attribute 'empty'\n",
      "Downloading ACUCAR (SB=F) from yfinance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading SB=F: 'function' object has no attribute 'empty'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pandas_datareader as  pdr\\n\\n# 5Baixa os dados do DataReader (ex: FRED)\\ndr_data = {}\\nfor codigo, nome in config['DataReader']['reader_code'].items():\\n    print(f'Baixando {nome} ({codigo}) via DataReader...')\\n    df = pdr.DataReader(codigo, 'fred', start=start_date, end=end_date)\\n    dr_data[nome] = df\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandas_datareader as  pdr\n",
    "\n",
    "# 5Baixa os dados do DataReader (ex: FRED)\n",
    "dr_data = {}\n",
    "for codigo, nome in config['DataReader']['reader_code'].items():\n",
    "    print(f'Baixando {nome} ({codigo}) via DataReader...')\n",
    "    df = pdr.DataReader(codigo, 'fred', start=start_date, end=end_date)\n",
    "    dr_data[nome] = df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.dataset_loader import DataReaderLoader\n",
    "\n",
    "# Create an instance of YfinanceLoader with the start and end dates\n",
    "dr_loader = DataReaderLoader(start_date=str(dt_start), end_date=str(dt_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading BRL_USD (DEXBZUS) from DataReader...\n",
      "Downloading CPI_USA (CPIAUCSL) from DataReader...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BRL_USD':             DEXBZUS\n",
       " DATE               \n",
       " 2015-04-28   2.9002\n",
       " 2015-04-29   2.9393\n",
       " 2015-04-30   3.0121\n",
       " 2015-05-01   3.0145\n",
       " 2015-05-04   3.0720\n",
       " ...             ...\n",
       " 2025-04-14   5.8649\n",
       " 2025-04-15   5.8809\n",
       " 2025-04-16   5.8610\n",
       " 2025-04-17   5.8308\n",
       " 2025-04-18   5.8067\n",
       " \n",
       " [2604 rows x 1 columns],\n",
       " 'CPI_USA':             CPIAUCSL\n",
       " DATE                \n",
       " 2015-05-01   237.001\n",
       " 2015-06-01   237.657\n",
       " 2015-07-01   238.034\n",
       " 2015-08-01   238.033\n",
       " 2015-09-01   237.498\n",
       " ...              ...\n",
       " 2024-11-01   316.449\n",
       " 2024-12-01   317.603\n",
       " 2025-01-01   319.086\n",
       " 2025-02-01   319.775\n",
       " 2025-03-01   319.615\n",
       " \n",
       " [119 rows x 1 columns]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Função para buscar uma série do SGS\\ndef get_bcb_series(sgs_code, start,end):\\n    url = f\\'https://api.bcb.gov.br/dados/serie/bcdata.sgs.{sgs_code}/dados\\'\\n\\n    # Monta os parâmetros corretamente no formato da API\\n    params = {\\n        \\'formato\\': \\'json\\',\\n        \\'dataInicial\\': start.strftime(\\'%d/%m/%Y\\'),  # Formato dd/mm/yyyy\\n        \\'dataFinal\\': end.strftime(\\'%d/%m/%Y\\'),      # Formato dd/mm/yyyy\\n    }\\n\\n    # Requisição\\n    response = requests.get(url, params=params)\\n    data = response.json()\\n\\n    # Verifica se a resposta está vazia\\n    if not data:\\n        print(f\"Warning: No data found for SGS code {sgs_code} between {start} and {end}.\")\\n        return data\\n\\n    return data'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Função para buscar uma série do SGS\n",
    "def get_bcb_series(sgs_code, start,end):\n",
    "    url = f'https://api.bcb.gov.br/dados/serie/bcdata.sgs.{sgs_code}/dados'\n",
    "    \n",
    "    # Monta os parâmetros corretamente no formato da API\n",
    "    params = {\n",
    "        'formato': 'json',\n",
    "        'dataInicial': start.strftime('%d/%m/%Y'),  # Formato dd/mm/yyyy\n",
    "        'dataFinal': end.strftime('%d/%m/%Y'),      # Formato dd/mm/yyyy\n",
    "    }\n",
    "\n",
    "    # Requisição\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    # Verifica se a resposta está vazia\n",
    "    if not data:\n",
    "        print(f\"Warning: No data found for SGS code {sgs_code} between {start} and {end}.\")\n",
    "        return data\n",
    "    \n",
    "    return data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bcb_data = {}\\nfor nome, codigo in config['bcb']['sgs_code'].items():\\n    print(f'Baixando {nome} ({codigo}) via API bcb...')\\n    df = get_bcb_series(codigo, start=start_date,end=end_date)\\n    bcb_data[nome] = df\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''bcb_data = {}\n",
    "for nome, codigo in config['bcb']['sgs_code'].items():\n",
    "    print(f'Baixando {nome} ({codigo}) via API bcb...')\n",
    "    df = get_bcb_series(codigo, start=start_date,end=end_date)\n",
    "    bcb_data[nome] = df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.dataset_loader import BcbLoader\n",
    "\n",
    "# Create an instance of YfinanceLoader with the start and end dates\n",
    "bcb_loader = BcbLoader(start_date=str(dt_start), end_date=str(dt_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SELIC (11) from the Central Bank of Brazil API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Repositories\\ds-lstm-ibov\\src\\utils\\dataset_loader.py:92: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_ticker['data'] = pd.to_datetime(df_ticker['data'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CDI (12) from the Central Bank of Brazil API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Repositories\\ds-lstm-ibov\\src\\utils\\dataset_loader.py:92: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_ticker['data'] = pd.to_datetime(df_ticker['data'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SELIC_Anual (1178) from the Central Bank of Brazil API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Repositories\\ds-lstm-ibov\\src\\utils\\dataset_loader.py:92: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_ticker['data'] = pd.to_datetime(df_ticker['data'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SELIC_Meta_Anual (432) from the Central Bank of Brazil API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Repositories\\ds-lstm-ibov\\src\\utils\\dataset_loader.py:92: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_ticker['data'] = pd.to_datetime(df_ticker['data'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading IPCA_Mensal (433) from the Central Bank of Brazil API...\n",
      "Downloading IGP_M_Mensal (189) from the Central Bank of Brazil API...\n",
      "Downloading INCC_Mensal (192) from the Central Bank of Brazil API...\n",
      "Downloading Indice_Condicoes_Econ_BR (27574) from the Central Bank of Brazil API...\n",
      "Downloading Indice_Condicoes_Econ_BR_USD (29042) from the Central Bank of Brazil API...\n",
      "Downloading Salario_Minimo (1619) from the Central Bank of Brazil API...\n",
      "Downloading IBC_BR (24363) from the Central Bank of Brazil API...\n",
      "Downloading Populacao_BR (21774) from the Central Bank of Brazil API...\n",
      "Downloading PIB_Trimestral_Real (4380) from the Central Bank of Brazil API...\n",
      "Downloading PIB_Anual_Corrente (7326) from the Central Bank of Brazil API...\n",
      "Downloading Deflator_Implicito_PIB (1211) from the Central Bank of Brazil API...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SELIC':                valor\n",
       " data                \n",
       " 2015-04-28  0.047350\n",
       " 2015-04-29  0.047350\n",
       " 2015-04-30  0.049037\n",
       " 2015-05-04  0.049037\n",
       " 2015-05-05  0.049037\n",
       " ...              ...\n",
       " 2025-04-17  0.052531\n",
       " 2025-04-22  0.052531\n",
       " 2025-04-23  0.052531\n",
       " 2025-04-24  0.052531\n",
       " 2025-04-25  0.052531\n",
       " \n",
       " [2508 rows x 1 columns],\n",
       " 'CDI':                valor\n",
       " data                \n",
       " 2015-04-28  0.047173\n",
       " 2015-04-29  0.047173\n",
       " 2015-04-30  0.048897\n",
       " 2015-05-04  0.048897\n",
       " 2015-05-05  0.048967\n",
       " ...              ...\n",
       " 2025-04-16  0.052531\n",
       " 2025-04-17  0.052531\n",
       " 2025-04-22  0.052531\n",
       " 2025-04-23  0.052531\n",
       " 2025-04-24  0.052531\n",
       " \n",
       " [2507 rows x 1 columns],\n",
       " 'SELIC_Anual':             valor\n",
       " data             \n",
       " 2015-04-28  12.67\n",
       " 2015-04-29  12.67\n",
       " 2015-04-30  13.15\n",
       " 2015-05-04  13.15\n",
       " 2015-05-05  13.15\n",
       " ...           ...\n",
       " 2025-04-17  14.15\n",
       " 2025-04-22  14.15\n",
       " 2025-04-23  14.15\n",
       " 2025-04-24  14.15\n",
       " 2025-04-25  14.15\n",
       " \n",
       " [2508 rows x 1 columns],\n",
       " 'SELIC_Meta_Anual':             valor\n",
       " data             \n",
       " 2015-04-28  12.75\n",
       " 2015-04-29  12.75\n",
       " 2015-04-30  13.25\n",
       " 2015-05-01  13.25\n",
       " 2015-05-02  13.25\n",
       " ...           ...\n",
       " 2025-04-21  14.25\n",
       " 2025-04-22  14.25\n",
       " 2025-04-23  14.25\n",
       " 2025-04-24  14.25\n",
       " 2025-04-25  14.25\n",
       " \n",
       " [3651 rows x 1 columns],\n",
       " 'IPCA_Mensal':            valor\n",
       " data            \n",
       " 2015-01-04  0.71\n",
       " 2015-01-05  0.74\n",
       " 2015-01-06  0.79\n",
       " 2015-01-07  0.62\n",
       " 2015-01-08  0.22\n",
       " ...          ...\n",
       " 2024-01-11  0.39\n",
       " 2024-01-12  0.52\n",
       " 2025-01-01  0.16\n",
       " 2025-01-02  1.31\n",
       " 2025-01-03  0.56\n",
       " \n",
       " [120 rows x 1 columns],\n",
       " 'IGP_M_Mensal':             valor\n",
       " data             \n",
       " 2015-01-04   1.17\n",
       " 2015-01-05   0.41\n",
       " 2015-01-06   0.67\n",
       " 2015-01-07   0.69\n",
       " 2015-01-08   0.28\n",
       " ...           ...\n",
       " 2024-01-11   1.30\n",
       " 2024-01-12   0.94\n",
       " 2025-01-01   0.27\n",
       " 2025-01-02   1.06\n",
       " 2025-01-03  -0.34\n",
       " \n",
       " [120 rows x 1 columns],\n",
       " 'INCC_Mensal':            valor\n",
       " data            \n",
       " 2015-01-04  0.46\n",
       " 2015-01-05  0.95\n",
       " 2015-01-06  1.84\n",
       " 2015-01-07  0.55\n",
       " 2015-01-08  0.59\n",
       " ...          ...\n",
       " 2024-01-11  0.40\n",
       " 2024-01-12  0.50\n",
       " 2025-01-01  0.83\n",
       " 2025-01-02  0.40\n",
       " 2025-01-03  0.39\n",
       " \n",
       " [120 rows x 1 columns],\n",
       " 'Indice_Condicoes_Econ_BR':              valor\n",
       " data              \n",
       " 2015-01-04  151.96\n",
       " 2015-01-05  153.70\n",
       " 2015-01-06  155.07\n",
       " 2015-01-07  160.33\n",
       " 2015-01-08  168.00\n",
       " ...            ...\n",
       " 2024-01-11  447.00\n",
       " 2024-01-12  477.11\n",
       " 2025-01-01  482.57\n",
       " 2025-01-02  461.10\n",
       " 2025-01-03  447.04\n",
       " \n",
       " [120 rows x 1 columns],\n",
       " 'Indice_Condicoes_Econ_BR_USD':              valor\n",
       " data              \n",
       " 2015-01-04  113.96\n",
       " 2015-01-05  114.88\n",
       " 2015-01-06  113.90\n",
       " 2015-01-07  113.75\n",
       " 2015-01-08  109.28\n",
       " ...            ...\n",
       " 2024-01-11  175.99\n",
       " 2024-01-12  178.78\n",
       " 2025-01-01  182.97\n",
       " 2025-01-02  182.79\n",
       " 2025-01-03  177.50\n",
       " \n",
       " [120 rows x 1 columns],\n",
       " 'Salario_Minimo':               valor\n",
       " data               \n",
       " 2015-01-04   788.00\n",
       " 2015-01-05   788.00\n",
       " 2015-01-06   788.00\n",
       " 2015-01-07   788.00\n",
       " 2015-01-08   788.00\n",
       " ...             ...\n",
       " 2024-01-11  1412.00\n",
       " 2024-01-12  1412.00\n",
       " 2025-01-01  1518.00\n",
       " 2025-01-02  1518.00\n",
       " 2025-01-03  1518.00\n",
       " \n",
       " [120 rows x 1 columns],\n",
       " 'IBC_BR':                 valor\n",
       " data                 \n",
       " 2015-01-04   99.94554\n",
       " 2015-01-05   98.04694\n",
       " 2015-01-06   97.13174\n",
       " 2015-01-07  100.41241\n",
       " 2015-01-08   98.74273\n",
       " ...               ...\n",
       " 2024-01-10  109.49845\n",
       " 2024-01-11  105.76017\n",
       " 2024-01-12  104.44111\n",
       " 2025-01-01  103.05176\n",
       " 2025-01-02  106.61259\n",
       " \n",
       " [119 rows x 1 columns],\n",
       " 'Populacao_BR':              valor\n",
       " data              \n",
       " 2015-01-01  202404\n",
       " 2016-01-01  203872\n",
       " 2017-01-01  205212\n",
       " 2018-01-01  206529\n",
       " 2019-01-01  207900\n",
       " 2020-01-01  209165\n",
       " 2021-01-01  210104\n",
       " 2022-01-01  210863\n",
       " 2023-01-01  211695\n",
       " 2024-01-01  212584,\n",
       " 'PIB_Trimestral_Real':                 valor\n",
       " data                 \n",
       " 2015-01-04   497159.2\n",
       " 2015-01-05   492230.7\n",
       " 2015-01-06   490580.0\n",
       " 2015-01-07   507320.0\n",
       " 2015-01-08   501232.2\n",
       " ...               ...\n",
       " 2024-01-10  1046392.1\n",
       " 2024-01-11  1025651.9\n",
       " 2024-01-12  1008323.5\n",
       " 2025-01-01   953972.1\n",
       " 2025-01-02   966150.6\n",
       " \n",
       " [119 rows x 1 columns],\n",
       " 'PIB_Anual_Corrente':             valor\n",
       " data             \n",
       " 2015-01-01  -3.55\n",
       " 2016-01-01  -3.28\n",
       " 2017-01-01   1.32\n",
       " 2018-01-01   1.78\n",
       " 2019-01-01   1.22\n",
       " 2020-01-01  -3.28\n",
       " 2021-01-01   4.76\n",
       " 2022-01-01   3.02\n",
       " 2023-01-01   3.24\n",
       " 2024-01-01   3.40,\n",
       " 'Deflator_Implicito_PIB':             valor\n",
       " data             \n",
       " 2015-01-01   7.57\n",
       " 2016-01-01   8.10\n",
       " 2017-01-01   3.67\n",
       " 2018-01-01   4.49\n",
       " 2019-01-01   4.22\n",
       " 2020-01-01   6.47\n",
       " 2021-01-01  13.05\n",
       " 2022-01-01   8.57\n",
       " 2023-01-01   5.16\n",
       " 2024-01-01   3.80}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcb_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import RAW_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yf_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# (Opcional) Salva em CSV\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nome, df \u001b[38;5;129;01min\u001b[39;00m \u001b[43myf_data\u001b[49m.items():\n\u001b[32m      3\u001b[39m     df.to_csv(RAW_DATA_DIR / \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdados_yf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnome\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nome, df \u001b[38;5;129;01min\u001b[39;00m bcb_data.items():\n",
      "\u001b[31mNameError\u001b[39m: name 'yf_data' is not defined"
     ]
    }
   ],
   "source": [
    "# (Opcional) Salva em CSV\n",
    "for nome, df in yf_data.items():\n",
    "    df.to_csv(RAW_DATA_DIR / f'dados_yf_{nome}.csv')\n",
    "\n",
    "for nome, df in bcb_data.items():\n",
    "    df.to_csv(RAW_DATA_DIR / f'dados_bcb_{nome}.csv')\n",
    "\n",
    "for nome, df in dr_data.items():\n",
    "    df.to_csv(RAW_DATA_DIR / f'dados_dr_{nome}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Indicator**        | **Ticker (Yahoo Finance)** | **Description** |\n",
    "|---------------------|--------------------------|-------------|\n",
    "| **IBOVESPA**       | `^BVSP`                   | Brazil Stock Market Index |\n",
    "| **Commodities**     | `GC=F`, `CL=F`, `SB=F`, `ZC=F` | Gold, Crude Oil, Sugar, Corn |\n",
    "| **Stock Market Index (S&P 500)** | `^GSPC` | Standard & Poor’s 500 (S&P 500) Index |\n",
    "| **Cryptocurrency (Bitcoin)** | `BTC-USD` | Bitcoin price in USD |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the IBOVESPA ticker symbol used on Yahoo Finance\n",
    "tickers = [\"^BVSP\",\"^GSPC\",\"BTC-USD\", \"GC=F\", \"CL=F\", \"SB=F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download historical data (default is daily interval)\n",
    "# You can adjust the period (e.g., '1y', '5y', 'max') or set specific dates\n",
    "df_yf = yf.download(tickers, start=dt_start, end=dt_end).ffill()\n",
    "\n",
    "# Ensure the 'Date' column exists and is in datetime format before setting it as the index\n",
    "if 'Date' in df_yf.columns:\n",
    "    df_yf['Date'] = pd.to_datetime(df_yf['Date'])\n",
    "    df_yf.set_index('Date', inplace=True)\n",
    "else:\n",
    "    print(\"The 'Date' column is not present in the dataset.\")\n",
    "\n",
    "# Display the first few rows\n",
    "df_yf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Exchange Rate (Forex)** | `USDBRL=X`, `EURBRL=X` | USD/BRL (Dollar to Real), EUR/BRL (Euro to Real) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the multi-level column index\n",
    "df_yf.columns = ['_'.join(col).strip() for col in df_yf.columns.values]\n",
    "\n",
    "# Display the first few rows of the updated dataset\n",
    "df_yf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bcb - Banco Central do Brasil\n",
    "\n",
    "https://www3.bcb.gov.br/sgspub/localizarseries/localizarSeries.do?method=prepararTelaLocalizarSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_br = {\n",
    "    'SELIC':11,\n",
    "    'CDI':12,\n",
    "    'SELIC_Anual': 1178,\n",
    "    'SELIC_Meta_Anual': 432,\n",
    "    'IPCA_Mensal': 433,\n",
    "    'IGP_M_Mensal': 189,\n",
    "    'INCC_Mensal': 192,\n",
    "    'Indice_Condicoes_Econ_BR': 27574,\n",
    "    'Indice_Condicoes_Econ_BR_USD': 29042,\n",
    "    'Salario_Minimo': 1619,\n",
    "    'IBC_BR': 24363,\n",
    "    'Populacao_BR': 21774,\n",
    "    'PIB_Trimestral_Real': 4380,\n",
    "    'PIB_Anual_Corrente': 7326,\n",
    "    'Deflator_Implicito_PIB': 1211\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para buscar uma série do SGS\n",
    "def get_bcb_series(sgs_code, start,end):\n",
    "    url = f'https://api.bcb.gov.br/dados/serie/bcdata.sgs.{sgs_code}/dados'\n",
    "    \n",
    "    # Monta os parâmetros corretamente no formato da API\n",
    "    params = {\n",
    "        'formato': 'json',\n",
    "        'dataInicial': start.strftime('%d/%m/%Y'),  # Formato dd/mm/yyyy\n",
    "        'dataFinal': end.strftime('%d/%m/%Y'),      # Formato dd/mm/yyyy\n",
    "    }\n",
    "\n",
    "    # Requisição\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    # Verifica se a resposta está vazia\n",
    "    if not data:\n",
    "        print(f\"Warning: No data found for SGS code {sgs_code} between {start} and {end}.\")\n",
    "        return data\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar todas as séries e armazenar num dicionário\n",
    "br_dataframes = {}\n",
    "for name, code in series_br.items():\n",
    "    print(f'Baixando {name} (código {code})...')\n",
    "    try:\n",
    "        br_dataframes[name] = pd.DataFrame(get_bcb_series(code, start=dt_start,end=dt_end))\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao baixar a série {name} (código {code}): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all DataFrames in the dictionary into a single DataFrame\n",
    "df_br = pd.concat(\n",
    "    {key: df.assign(data=pd.to_datetime(df['data'], format='%d/%m/%Y'))\n",
    "          .set_index('data')['valor']\n",
    "     for key, df in br_dataframes.items()},\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by index (date)\n",
    "df_br.sort_index(inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df_br.ffill().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário com os códigos do FRED e nomes mais amigáveis\n",
    "series_usa = {\n",
    "    'DEXBZUS': 'BRL_USD',\n",
    "    'CPIAUCSL': 'CPI_USA',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puxar todas as séries e juntar num único DataFrame\n",
    "df_usa = pd.concat(\n",
    "    [web.DataReader(code, 'fred', dt_start, dt_end).rename(columns={code: name})\n",
    "     for code, name in series_usa.items()],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usa.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar os três DataFrames com base no índice\n",
    "dataset = df_yf.join([df_br, df_usa], how='left')\n",
    "\n",
    "dataset.ffill(inplace=True) # Preencher valores ausentes com o último valor conhecido\n",
    "dataset.bfill(inplace=True) # Preencher valores ausentes com o último valor conhecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir as primeiras linhas do DataFrame resultante\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir as primeiras linhas do DataFrame resultante\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc['2025-01-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a CSV file\n",
    "dataset.to_csv('../data/raw/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('../data/raw/dataset.csv', index_col=0, parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_target = {}\n",
    "for index in dataset.columns[dataset.columns.str.contains('BVSP')]:\n",
    "    dict_target[index] = dataset.columns.get_loc(index)\n",
    "\n",
    "print(dict_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ColumnTransformer usando make_column_selector\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Pipeline final\n",
    "pipeline_process = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit and transform the pipeline on the selected data\n",
    "X_all = pipeline_process.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from scipy.sparse import issparse\n",
    "\n",
    "if issparse(X_all):\n",
    "    X_all = X_all.toarray()\n",
    "\n",
    "X_all.astype(np.float64)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict_target.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar os pares (X, y) para todo o histórico\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "sequence_length = 200  # Número de dias para prever o fechamento do ibovespa\n",
    "target_column_index = list(dict_target.values())  # o fechamento do ibovespa está no íncide 4 de X_all\n",
    "\n",
    "generator = TimeseriesGenerator(\n",
    "    X_all, X_all[:, target_column_index],\n",
    "    length=sequence_length, batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generator[0][0].shape)\n",
    "print(generator.data.shape)\n",
    "print(generator.targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator[0][0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator[0][0].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'checkpoint.keras',           # nome do arquivo salvo\n",
    "    save_best_only=False,         # se quiser salvar sempre, não só o melhor\n",
    "    save_weights_only=False,      # se quiser salvar o modelo completo\n",
    "    save_freq='epoch'             # salva a cada época\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(MODELS_DIR / 'checkpoint.keras')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from src.config import MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "# EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    MODELS_DIR / 'checkpoint.keras',           # nome do arquivo salvo\n",
    "    save_best_only=False,         # se quiser salvar sempre, não só o melhor\n",
    "    save_weights_only=False,      # se quiser salvar o modelo completo\n",
    "    save_freq='epoch'             # salva a cada época\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Bidirectional, LSTM, Dropout, Dense\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Define o formato de entrada\n",
    "input_shape = (generator[0][0].shape[1], generator[0][0].shape[2])\n",
    "\n",
    "# Define e compila o modelo LSTM\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Bidirectional(LSTM(70, return_sequences=True, recurrent_dropout=0.2, kernel_regularizer=l2(0.001))),\n",
    "    Dropout(0.3),\n",
    "    LSTM(50, return_sequences=True, recurrent_dropout=0.2, kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.3),\n",
    "    LSTM(30, return_sequences=False, recurrent_dropout=0.2, kernel_regularizer=l2(0.001)),\n",
    "    Dense(5)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(generator, epochs=30,callbacks=[checkpoint,early_stopping],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Últimos 7 dias de X\n",
    "last_window = X_all[-sequence_length:]  # shape (7, features)\n",
    "last_window = last_window.reshape((1, sequence_length, X_all.shape[1]))  # (1, 7, features)\n",
    "\n",
    "# Previsão do próximo dia\n",
    "next_prediction = model.predict(last_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_prediction[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pipeline_process.named_steps['preprocessor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ct.transformers_[0][2]  # Pega os nomes/índices das colunas usadas no primeiro transformador\n",
    "scaler = ct.transformers_[0][1]        # Pega o StandardScaler associado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the integer index of the target column in numeric_cols\n",
    "target_in_scaler_index = 4\n",
    "\n",
    "dummy_input = np.zeros((1, len(numeric_cols)))\n",
    "dummy_input[0, target_in_scaler_index] = next_prediction[0, 0]\n",
    "\n",
    "inv = scaler.inverse_transform(dummy_input)\n",
    "next_prediction_real = inv[0, target_in_scaler_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape para 2D: (7, features)\n",
    "last_window_2d = last_window.reshape(-1, X_all.shape[1])\n",
    "\n",
    "# Selecionar apenas as colunas numéricas correspondentes a numeric_cols\n",
    "last_window_2d_numeric = last_window_2d[:, :len(numeric_cols)]\n",
    "\n",
    "# Inverter a transformação\n",
    "last_window_real_numeric = scaler.inverse_transform(last_window_2d_numeric)\n",
    "\n",
    "# Recriar o array completo com os valores invertidos\n",
    "last_window_real = last_window.copy()\n",
    "last_window_real[:, :, :len(numeric_cols)] = last_window_real_numeric\n",
    "\n",
    "# Se quiser, pode voltar ao shape 3D depois\n",
    "last_window_real = last_window_real.reshape(1, 7, X_all.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_window_real_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Eixo X para a janela de entrada (últimos 7 dias)\n",
    "x_input_dates = pd.date_range(end=dt_end, periods=sequence_length).strftime('%Y-%m-%d')\n",
    "\n",
    "# Eixo X para a predição (logo após a janela)\n",
    "x_pred_dates = [x_input_dates[-1], (pd.to_datetime(x_input_dates[-1]) + pd.Timedelta(days=1)).strftime('%Y-%m-%d')]\n",
    "\n",
    "# Último valor real + predição real\n",
    "y_pred_real = [last_window_real[0, -1, target_column_index], next_prediction_real]\n",
    "\n",
    "# Calcular a diferença percentual entre o predito e o último real\n",
    "diff_percent = ((y_pred_real[1] - y_pred_real[0]) / y_pred_real[0]) * 100\n",
    "\n",
    "# Formatar os valores para exibição\n",
    "y_pred_real_formatted = [f\"{int(y):,}\".replace(\",\", \".\") for y in y_pred_real]\n",
    "diff_percent_formatted = f\"{diff_percent:.2f}%\"\n",
    "\n",
    "# Plot da janela de dados reais\n",
    "plt.plot(x_input_dates, last_window_real[0, :, target_column_index], label='Últimos dados reais')\n",
    "\n",
    "# Plot da predição real como linha pontilhada conectando ao último ponto real\n",
    "plt.plot(x_pred_dates, y_pred_real, 'r--', label='Predição real')\n",
    "\n",
    "# Adicionar rótulo ao último ponto real\n",
    "plt.annotate(f'{y_pred_real_formatted[0]}', \n",
    "             (x_input_dates[-1], y_pred_real[0]), \n",
    "             textcoords=\"offset points\", \n",
    "             xytext=(-10, 10), \n",
    "             ha='center', \n",
    "             fontsize=9, \n",
    "             color='blue')\n",
    "\n",
    "# Adicionar rótulo ao ponto predito com a diferença percentual\n",
    "plt.annotate(f'{y_pred_real_formatted[1]} ({diff_percent_formatted})', \n",
    "             (x_pred_dates[-1], y_pred_real[1]), \n",
    "             textcoords=\"offset points\", \n",
    "             xytext=(-10, 10), \n",
    "             ha='center', \n",
    "             fontsize=9, \n",
    "             color='red')\n",
    "\n",
    "# Legenda e rótulos\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.title('Predição do modelo vs Últimos dados reais')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
